<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<title>PCI passthrough via OVMF (简体中文) - ArchWiki</title>
<link rel="stylesheet" href="../ArchWikiOffline.css">
<meta name="ResourceLoaderDynamicStyles" content="">
<meta name="generator" content="MediaWiki 1.35.0">
<meta name="robots" content="noindex,follow">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="shortcut icon" href="/favicon.ico">
<link rel="search" type="application/opensearchdescription+xml" href="/opensearch_desc.php" title="ArchWiki (en)">
<link rel="EditURI" type="application/rsd+xml" href="https://wiki.archlinux.org/api.php?action=rsd">
<link rel="license" href="http://www.gnu.org/copyleft/fdl.html">
<link rel="alternate" type="application/atom+xml" title="ArchWiki Atom feed" href="/index.php?title=Special:RecentChanges&amp;feed=atom">
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-PCI_passthrough_via_OVMF_简体中文 rootpage-PCI_passthrough_via_OVMF_简体中文 skin-vector action-view skin-vector-legacy">
<div id="content" class="mw-body" role="main" style="margin: 0">
	<a id="top"></a>
	<div id="siteNotice" class="mw-body-content"></div>
	<div class="mw-indicators mw-body-content">
	</div>
	<h1 id="firstHeading" class="firstHeading" lang="en">PCI passthrough via OVMF (简体中文)</h1>
	<div id="bodyContent" class="mw-body-content">
		<div id="siteSub" class="noprint">From ArchWiki</div>
		<div id="contentSub"></div>
		<div id="contentSub2"></div>
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#searchInput">Jump to search</a>
		<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr">
<div class="warningbox">The printable version is no longer supported and may have rendering errors. Please update your browser bookmarks and please use the default browser print function instead.</div>
<div class="mw-parser-output">
<div class="archwiki-template-box archwiki-template-box-note">
<strong>翻译状态：</strong>本文是 <a href="../en/PCI_passthrough_via_OVMF.html" title="PCI passthrough via OVMF">PCI passthrough via OVMF</a> 的<a href="../zh-CN/ArchWiki:Translation_Team.html" title="ArchWiki:Translation Team (简体中文)">翻译</a>。上次翻译日期：2018-08-03。如果英文版本有所<a rel="nofollow" class="external text" href="https://wiki.archlinux.org/index.php?title=PCI_passthrough_via_OVMF&amp;diff=0&amp;oldid=532316">更改</a>，则您可以帮助同步翻译。</div>
<p>开放虚拟机固件（Open Virtual Machine Firmware, <a rel="nofollow" class="external text" href="https://github.com/tianocore/tianocore.github.io/wiki/OVMF">OVMF</a>)是一个为虚拟机启用 UEFI 支持的项目。Linux 内核 3.9 之后的版本 和近期版本的 <a href="../en/QEMU.html" title="QEMU">QEMU</a> ，支持将显卡直通给虚拟机，让虚拟机在执行图形密集型任务的时候有接近实体机的图形性能。
</p>
<p>如果你可以为宿主机准备一张备用的显卡（无论是集成显卡还是独立显卡，还是旧的 OEM 卡都可以，品牌不需要一致），并且你的硬件支持 PCI 直通（参见 <a href="#%E7%A1%AC%E4%BB%B6%E8%A6%81%E6%B1%82">#硬件要求</a>），那么任何操作系统的虚拟机都可以使用一张专用显卡并得到接近于原生的图形性能。请参阅<a rel="nofollow" class="external text" href="https://www.linux-kvm.org/images/b/b3/01x09b-VFIOandYou-small.pdf">这篇演讲(PDF)</a>了解有关技术的更多信息。
</p>
<div id="toc" class="toc" role="navigation" aria-labelledby="mw-toc-heading">
<input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none"><div class="toctitle" lang="en" dir="ltr">
<h2 id="mw-toc-heading">Contents</h2>
<span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span>
</div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#%E7%A1%AC%E4%BB%B6%E8%A6%81%E6%B1%82"><span class="tocnumber">1</span> <span class="toctext">硬件要求</span></a></li>
<li class="toclevel-1 tocsection-2">
<a href="#%E8%AE%BE%E7%BD%AEIOMMU"><span class="tocnumber">2</span> <span class="toctext">设置IOMMU</span></a>
<ul>
<li class="toclevel-2 tocsection-3"><a href="#%E5%90%AF%E7%94%A8IOMMU"><span class="tocnumber">2.1</span> <span class="toctext">启用IOMMU</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#%E7%A1%AE%E4%BF%9D%E7%BB%84%E6%9C%89%E6%95%88"><span class="tocnumber">2.2</span> <span class="toctext">确保组有效</span></a></li>
<li class="toclevel-2 tocsection-5">
<a href="#%E6%B3%A8%E6%84%8F"><span class="tocnumber">2.3</span> <span class="toctext">注意</span></a>
<ul>
<li class="toclevel-3 tocsection-6"><a href="#%E5%A6%82%E6%9E%9C%E5%AE%A2%E6%88%B7%E6%9C%BA%E6%89%80%E7%94%A8%E6%98%BE%E5%8D%A1%E6%8F%92%E5%9C%A8_CPU_%E6%8F%90%E4%BE%9B%E7%9A%84_PCI-E_%E6%8F%92%E6%A7%BD%E4%B8%AD"><span class="tocnumber">2.3.1</span> <span class="toctext">如果客户机所用显卡插在 CPU 提供的 PCI-E 插槽中</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-7"><a href="#%E9%9A%94%E7%A6%BBGPU"><span class="tocnumber">3</span> <span class="toctext">隔离GPU</span></a></li>
<li class="toclevel-1 tocsection-8">
<a href="#%E8%AE%BE%E7%BD%AE_OVMF_%E8%99%9A%E6%8B%9F%E6%9C%BA"><span class="tocnumber">4</span> <span class="toctext">设置 OVMF 虚拟机</span></a>
<ul>
<li class="toclevel-2 tocsection-9"><a href="#%E9%85%8D%E7%BD%AElibvirt"><span class="tocnumber">4.1</span> <span class="toctext">配置libvirt</span></a></li>
<li class="toclevel-2 tocsection-10"><a href="#%E5%AE%89%E8%A3%85%E5%AE%A2%E6%88%B7%E6%9C%BA%E7%B3%BB%E7%BB%9F"><span class="tocnumber">4.2</span> <span class="toctext">安装客户机系统</span></a></li>
<li class="toclevel-2 tocsection-11"><a href="#%E9%99%84%E5%8A%A0PCI%E8%AE%BE%E5%A4%87"><span class="tocnumber">4.3</span> <span class="toctext">附加PCI设备</span></a></li>
<li class="toclevel-2 tocsection-12">
<a href="#%E6%B3%A8%E6%84%8F_2"><span class="tocnumber">4.4</span> <span class="toctext">注意</span></a>
<ul>
<li class="toclevel-3 tocsection-13"><a href="#OVMF%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%8D%E8%83%BD%E5%BC%95%E5%AF%BC%E9%9D%9EEFI%E9%95%9C%E5%83%8F"><span class="tocnumber">4.4.1</span> <span class="toctext">OVMF虚拟机不能引导非EFI镜像</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-14">
<a href="#%E6%80%A7%E8%83%BD%E8%B0%83%E6%95%B4"><span class="tocnumber">5</span> <span class="toctext">性能调整</span></a>
<ul>
<li class="toclevel-2 tocsection-15">
<a href="#CPU%E6%A0%B8%E5%BF%83%E5%9B%BA%E5%AE%9A"><span class="tocnumber">5.1</span> <span class="toctext">CPU核心固定</span></a>
<ul>
<li class="toclevel-3 tocsection-16"><a href="#CPU_%E6%8B%93%E6%89%91"><span class="tocnumber">5.1.1</span> <span class="toctext">CPU 拓扑</span></a></li>
<li class="toclevel-3 tocsection-17">
<a href="#XML_%E7%A4%BA%E4%BE%8B"><span class="tocnumber">5.1.2</span> <span class="toctext">XML 示例</span></a>
<ul>
<li class="toclevel-4 tocsection-18"><a href="#4c/1t_%E6%97%A0%E8%B6%85%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="tocnumber">5.1.2.1</span> <span class="toctext">4c/1t 无超线程的例子</span></a></li>
<li class="toclevel-4 tocsection-19"><a href="#6c/2t_Intel_CPU_%E5%9B%BA%E5%AE%9A%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="tocnumber">5.1.2.2</span> <span class="toctext">6c/2t Intel CPU 固定的例子</span></a></li>
<li class="toclevel-4 tocsection-20"><a href="#4c/2t_AMD_CPU_%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="tocnumber">5.1.2.3</span> <span class="toctext">4c/2t AMD CPU 的例子</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-2 tocsection-21">
<a href="#%E5%86%85%E5%AD%98%E5%A4%A7%E5%88%86%E9%A1%B5"><span class="tocnumber">5.2</span> <span class="toctext">内存大分页</span></a>
<ul>
<li class="toclevel-3 tocsection-22"><a href="#%E9%80%8F%E6%98%8E%E5%A4%A7%E5%88%86%E9%A1%B5"><span class="tocnumber">5.2.1</span> <span class="toctext">透明大分页</span></a></li>
<li class="toclevel-3 tocsection-23"><a href="#Static_huge_pages"><span class="tocnumber">5.2.2</span> <span class="toctext">Static huge pages</span></a></li>
<li class="toclevel-3 tocsection-24"><a href="#Dynamic_huge_pages"><span class="tocnumber">5.2.3</span> <span class="toctext">Dynamic huge pages</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-25"><a href="#CPU%E8%B0%83%E9%80%9F%E5%99%A8"><span class="tocnumber">5.3</span> <span class="toctext">CPU调速器</span></a></li>
<li class="toclevel-2 tocsection-26">
<a href="#%E9%AB%98DPC%E5%BB%B6%E8%BF%9F"><span class="tocnumber">5.4</span> <span class="toctext">高DPC延迟</span></a>
<ul>
<li class="toclevel-3 tocsection-27"><a href="#%E4%BD%BF%E7%94%A8isolcpus%E5%9B%BA%E5%AE%9ACPU%E6%A0%B8%E5%BF%83"><span class="tocnumber">5.4.1</span> <span class="toctext">使用isolcpus固定CPU核心</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-28"><a href="#%E6%8F%90%E9%AB%98AMD_CPU%E7%9A%84%E6%80%A7%E8%83%BD"><span class="tocnumber">5.5</span> <span class="toctext">提高AMD CPU的性能</span></a></li>
<li class="toclevel-2 tocsection-29"><a href="#%E8%BF%9B%E4%B8%80%E6%AD%A5%E8%B0%83%E6%95%B4"><span class="tocnumber">5.6</span> <span class="toctext">进一步调整</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-30">
<a href="#%E7%89%B9%E6%AE%8A%E6%AD%A5%E9%AA%A4"><span class="tocnumber">6</span> <span class="toctext">特殊步骤</span></a>
<ul>
<li class="toclevel-2 tocsection-31">
<a href="#%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%92%8C%E5%AE%A2%E6%88%B7%E6%9C%BA%E4%BD%BF%E7%94%A8%E7%9B%B8%E5%90%8C%E7%9A%84GPU"><span class="tocnumber">6.1</span> <span class="toctext">宿主机和客户机使用相同的GPU</span></a>
<ul>
<li class="toclevel-3 tocsection-32">
<a href="#%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B"><span class="tocnumber">6.1.1</span> <span class="toctext">脚本示例</span></a>
<ul>
<li class="toclevel-4 tocsection-33"><a href="#%E7%9B%B4%E9%80%9A%E9%99%A4%E4%BA%86%E5%90%AF%E5%8A%A8%E6%97%B6%E6%89%80%E7%94%A8GPU%E4%B9%8B%E5%A4%96%E7%9A%84%E6%89%80%E6%9C%89GPU"><span class="tocnumber">6.1.1.1</span> <span class="toctext">直通除了启动时所用GPU之外的所有GPU</span></a></li>
<li class="toclevel-4 tocsection-34"><a href="#%E7%9B%B4%E9%80%9A%E9%80%89%E5%AE%9A%E7%9A%84GPU"><span class="tocnumber">6.1.1.2</span> <span class="toctext">直通选定的GPU</span></a></li>
</ul>
</li>
<li class="toclevel-3 tocsection-35"><a href="#%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85"><span class="tocnumber">6.1.2</span> <span class="toctext">脚本安装</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-36"><a href="#%E7%9B%B4%E9%80%9A%E5%90%AF%E5%8A%A8%E6%97%B6%E6%89%80%E7%94%A8%E7%9A%84GPU"><span class="tocnumber">6.2</span> <span class="toctext">直通启动时所用的GPU</span></a></li>
<li class="toclevel-2 tocsection-37">
<a href="#%E4%BD%BF%E7%94%A8Looking_Glass%E5%B0%86%E5%AE%A2%E6%88%B7%E6%9C%BA%E7%94%BB%E9%9D%A2%E6%B5%81%E5%BC%8F%E4%BC%A0%E8%BE%93%E5%88%B0%E5%AE%BF%E4%B8%BB%E6%9C%BA"><span class="tocnumber">6.3</span> <span class="toctext">使用Looking Glass将客户机画面流式传输到宿主机</span></a>
<ul>
<li class="toclevel-3 tocsection-38"><a href="#%E5%B0%86IVSHMEM%E8%AE%BE%E5%A4%87%E6%B7%BB%E5%8A%A0%E5%88%B0%E8%99%9A%E6%8B%9F%E6%9C%BA"><span class="tocnumber">6.3.1</span> <span class="toctext">将IVSHMEM设备添加到虚拟机</span></a></li>
<li class="toclevel-3 tocsection-39"><a href="#%E5%B0%86IVSHMEM%E4%B8%BB%E6%9C%BA%E5%AE%89%E8%A3%85%E5%88%B0Windows%E5%AE%A2%E6%88%B7%E6%9C%BA"><span class="tocnumber">6.3.2</span> <span class="toctext">将IVSHMEM主机安装到Windows客户机</span></a></li>
<li class="toclevel-3 tocsection-40"><a href="#%E5%AE%89%E8%A3%85%E5%AE%A2%E6%88%B7%E7%AB%AF"><span class="tocnumber">6.3.3</span> <span class="toctext">安装客户端</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-41"><a href="#%E7%83%AD%E5%88%87%E6%8D%A2%E5%A4%96%E5%9B%B4%E8%AE%BE%E5%A4%87"><span class="tocnumber">6.4</span> <span class="toctext">热切换外围设备</span></a></li>
<li class="toclevel-2 tocsection-42"><a href="#%E5%88%86%E7%A6%BBIOMMU%E7%BB%84(ACS%E8%A1%A5%E4%B8%81)"><span class="tocnumber">6.5</span> <span class="toctext">分离IOMMU组(ACS补丁)</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-43"><a href="#%E4%BB%85%E4%BD%BF%E7%94%A8QEMU%E4%B8%8D%E4%BD%BF%E7%94%A8libvirt"><span class="tocnumber">7</span> <span class="toctext">仅使用QEMU不使用libvirt</span></a></li>
<li class="toclevel-1 tocsection-44">
<a href="#%E7%9B%B4%E9%80%9A%E5%85%B6%E5%AE%83%E8%AE%BE%E5%A4%87"><span class="tocnumber">8</span> <span class="toctext">直通其它设备</span></a>
<ul>
<li class="toclevel-2 tocsection-45"><a href="#USB%E6%8E%A7%E5%88%B6%E5%99%A8"><span class="tocnumber">8.1</span> <span class="toctext">USB控制器</span></a></li>
<li class="toclevel-2 tocsection-46"><a href="#%E4%BD%BF%E7%94%A8PulseAudio%E5%B0%86%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%9F%B3%E9%A2%91%E4%BC%A0%E9%80%92%E7%BB%99%E5%AE%BF%E4%B8%BB%E6%9C%BA"><span class="tocnumber">8.2</span> <span class="toctext">使用PulseAudio将虚拟机音频传递给宿主机</span></a></li>
<li class="toclevel-2 tocsection-47"><a href="#%E7%89%A9%E7%90%86%E7%A3%81%E7%9B%98/%E5%88%86%E5%8C%BA"><span class="tocnumber">8.3</span> <span class="toctext">物理磁盘/分区</span></a></li>
<li class="toclevel-2 tocsection-48">
<a href="#%E6%B3%A8%E6%84%8F_3"><span class="tocnumber">8.4</span> <span class="toctext">注意</span></a>
<ul>
<li class="toclevel-3 tocsection-49"><a href="#%E7%9B%B4%E9%80%9A%E4%B8%8D%E6%94%AF%E6%8C%81Reset%E7%9A%84%E8%AE%BE%E5%A4%87"><span class="tocnumber">8.4.1</span> <span class="toctext">直通不支持Reset的设备</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-50"><a href="#%E5%AE%8C%E6%95%B4%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="tocnumber">9</span> <span class="toctext">完整的例子</span></a></li>
<li class="toclevel-1 tocsection-51">
<a href="#%E7%96%91%E9%9A%BE%E8%A7%A3%E7%AD%94"><span class="tocnumber">10</span> <span class="toctext">疑难解答</span></a>
<ul>
<li class="toclevel-2 tocsection-52"><a href="#Nvidia_GPU%E7%9B%B4%E9%80%9A%E5%88%B0Windows_%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%97%B6%E5%8F%91%E7%94%9F%22%E9%94%99%E8%AF%AF43:%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F%E5%8A%A0%E8%BD%BD%E5%A4%B1%E8%B4%A5%E2%80%9D"><span class="tocnumber">10.1</span> <span class="toctext">Nvidia GPU直通到Windows 虚拟机时发生"错误43:驱动程序加载失败”</span></a></li>
<li class="toclevel-2 tocsection-53"><a href="#%E5%9C%A8%E5%90%AF%E5%8A%A8%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%90%8E%E5%9C%A8dmesg%E4%B8%AD%E7%9C%8B%E5%88%B0%22BAR_3:_cannot_reserve_%5Bmem%5D%22%E9%94%99%E8%AF%AF"><span class="tocnumber">10.2</span> <span class="toctext">在启动虚拟机后在dmesg中看到"BAR 3: cannot reserve [mem]"错误</span></a></li>
<li class="toclevel-2 tocsection-54"><a href="#VBIOS%E7%9A%84UEFI_(OVMF)_%E5%85%BC%E5%AE%B9"><span class="tocnumber">10.3</span> <span class="toctext">VBIOS的UEFI (OVMF) 兼容</span></a></li>
<li class="toclevel-2 tocsection-55"><a href="#HDMI%E9%9F%B3%E9%A2%91%E4%B8%8D%E5%90%8C%E6%AD%A5%E6%88%96%E6%98%AF%E6%9C%89%E5%99%BC%E5%95%AA%E5%A3%B0"><span class="tocnumber">10.4</span> <span class="toctext">HDMI音频不同步或是有噼啪声</span></a></li>
<li class="toclevel-2 tocsection-56"><a href="#intel_iommu%E5%90%AF%E7%94%A8%E4%B9%8B%E5%90%8E%E4%B8%BB%E6%9C%BA%E6%B2%A1%E6%9C%89HDMI%E9%9F%B3%E9%A2%91%E8%BE%93%E5%87%BA"><span class="tocnumber">10.5</span> <span class="toctext">intel_iommu启用之后主机没有HDMI音频输出</span></a></li>
<li class="toclevel-2 tocsection-57"><a href="#%E5%90%AF%E7%94%A8vfio_pci%E5%90%8EX%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8"><span class="tocnumber">10.6</span> <span class="toctext">启用vfio_pci后X无法启动</span></a></li>
<li class="toclevel-2 tocsection-58"><a href="#Chromium%E5%BF%BD%E7%95%A5%E9%9B%86%E6%88%90%E5%9B%BE%E5%BD%A2%E5%8A%A0%E9%80%9F"><span class="tocnumber">10.7</span> <span class="toctext">Chromium忽略集成图形加速</span></a></li>
<li class="toclevel-2 tocsection-59"><a href="#%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8F%AA%E4%BD%BF%E7%94%A8%E4%B8%80%E4%B8%AA%E6%A0%B8%E5%BF%83"><span class="tocnumber">10.8</span> <span class="toctext">虚拟机只使用一个核心</span></a></li>
<li class="toclevel-2 tocsection-60"><a href="#%E7%9B%B4%E9%80%9A%E8%B2%8C%E4%BC%BC%E5%B7%A5%E4%BD%9C%E4%BD%86%E6%B2%A1%E6%9C%89%E8%BE%93%E5%87%BA"><span class="tocnumber">10.9</span> <span class="toctext">直通貌似工作但没有输出</span></a></li>
<li class="toclevel-2 tocsection-61"><a href="#virt-manager_%E9%81%87%E5%88%B0%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98"><span class="tocnumber">10.10</span> <span class="toctext">virt-manager 遇到权限问题</span></a></li>
<li class="toclevel-2 tocsection-62"><a href="#%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%85%B3%E9%97%AD%E4%B9%8B%E5%90%8E%E5%AE%BF%E4%B8%BB%E6%9C%BA%E6%A0%B8%E5%BF%83%E6%97%A0%E5%93%8D%E5%BA%94"><span class="tocnumber">10.11</span> <span class="toctext">虚拟机关闭之后宿主机核心无响应</span></a></li>
<li class="toclevel-2 tocsection-63"><a href="#%E5%AE%A2%E6%88%B7%E6%9C%BA%E5%9C%A8%E5%AE%BF%E4%B8%BB%E6%9C%BA%E4%BC%91%E7%9C%A0%E7%9C%A0%E6%83%85%E5%86%B5%E4%B8%8B%E8%BF%90%E8%A1%8C%E5%AF%BC%E8%87%B4%E6%AD%BB%E6%9C%BA"><span class="tocnumber">10.12</span> <span class="toctext">客户机在宿主机休眠眠情况下运行导致死机</span></a></li>
<li class="toclevel-2 tocsection-64"><a href="#AMD%E6%98%BE%E5%8D%A1%E7%9B%B4%E9%80%9A%E5%90%8E%E6%97%A0%E6%B3%95%E9%87%8D%E5%90%AF%E8%99%9A%E6%8B%9F%E6%9C%BA"><span class="tocnumber">10.13</span> <span class="toctext">AMD显卡直通后无法重启虚拟机</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-65"><a href="#%E5%8F%A6%E8%AF%B7%E5%8F%82%E9%98%85"><span class="tocnumber">11</span> <span class="toctext">另请参阅</span></a></li>
</ul>
</div>

<h2>
<span id=".E7.A1.AC.E4.BB.B6.E8.A6.81.E6.B1.82"></span><span class="mw-headline" id="硬件要求">硬件要求</span>
</h2>
<p>VGA直通依赖许多功能。这些功能尚未成为所有硬件的标配，所以您的硬件可能并不支持。如果要使用VGA直通，您的硬件必须满足如下条件：
</p>
<ul>
<li>您的CPU必须支持硬件虚拟化（为了使用 kvm）和 IOMMU（为了使用 VGA 直通）。
<ul>
<li><a rel="nofollow" class="external text" href="https://ark.intel.com/Search/FeatureFilter?productType=processors&amp;VTD=true">Intel CPU 支持列表（VT-x 和 VT-d）</a></li>
<li>推土机架构及以后的所有的AMD CPU（包括 Zen）都应支持。
<ul><li>K10架构（2007）的 CPU 不具备 IOMMU，你需要一张<a rel="nofollow" class="external text" href="https://support.amd.com/TechDocs/43403.pdf#page=18">890FX</a>或者<a rel="nofollow" class="external text" href="https://support.amd.com/TechDocs/48691.pdf#page=21">990FX</a>芯片组的主板来使用 IOMMU（这些主板有自己的IOMMU支持）。</li></ul>
</li>
</ul>
</li>
<li>您的主板必须支持 IOMMU
<ul><li>芯片组和BIOS必须都支持IOMMU。确定是否支持可能不是十分容易（比如，主板说明书一般不会提到这些），但是在 <a rel="nofollow" class="external text" href="https://wiki.xen.org/wiki/VTd_HowTo">Xen wiki</a> 和 <a href="https://en.wikipedia.org/wiki/List_of_IOMMU-supporting_hardware" class="extiw" title="wikipedia:List of IOMMU-supporting hardware">Wikipedia:List of IOMMU-supporting hardware</a> 上有一个相当全面的支持列表。</li></ul>
</li>
<li>分配给客户机的 GPU 的 ROM 必须支持 UEFI
<ul><li>如果你可以在这个<a rel="nofollow" class="external text" href="https://www.techpowerup.com/vgabios/">列表</a>中找到适用您显卡的 ROM，就代表您的显卡可以支持 UEFI。所有2012年之后的显卡都应该支持 UEFI，因为微软将 UEFI 支持作为 Windows 8 兼容认证的必须条件。</li></ul>
</li>
</ul>
<p>您可能需要一台备用或者支持多个输入的显示器连接到显卡。如果没有连接显示器，那么直通的显卡不会有任何输出，并且使用 Spcie 或是 VNC 连接到虚拟机并不会让直通的显卡工作，换言之，没有任何使用 VGA 直通所带来的性能提升。您可能还需要准备一套备用的键鼠或是能通过 SSH 连接到宿主机的设备，如果虚拟机的配置出现了什么问题，您至少还可以控制宿主机。
</p>
<h2>
<span id=".E8.AE.BE.E7.BD.AEIOMMU"></span><span class="mw-headline" id="设置IOMMU">设置IOMMU</span>
</h2>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 
<ul>
<li>IOMMU 是 Intel VT-d 和 AMD-Vi 的通用名称。</li>
<li>VT-d 指的是直接输入/输出虚拟化(Intel Virtualization Technology for Directed I/O)，不应与VT-x(x86平台下的Intel虚拟化技术，Intel Virtualization Technology)混淆。VT-x 可以让一个硬件平台作为多个“虚拟”平台，而 VT-d 提高了虚拟化的安全性、可靠性和 I/O 性能。</li>
</ul>
</div>
<p>打开IOMMU之后可以使用 PCI Passthrough 和对于故障和恶意行为的内存保护。参见：<a href="https://en.wikipedia.org/wiki/Input-output_memory_management_unit#Advantages" class="extiw" title="wikipedia:Input-output memory management unit">wikipedia:Input-output memory management unit#Advantages</a> 以及 <a rel="nofollow" class="external text" href="https://www.quora.com/Memory-Management-computer-programming/Could-you-explain-IOMMU-in-plain-English">Memory Management (computer programming): Could you explain IOMMU in plain English?</a>。
</p>
<h3>
<span id=".E5.90.AF.E7.94.A8IOMMU"></span><span class="mw-headline" id="启用IOMMU">启用IOMMU</span>
</h3>
<p>确保您的 CPU 支持 AMD-Vi/Intel Vt-d 并且已经在 BIOS 中打开。通常这个选项会在类似“其他 CPU 特性”的菜单里，也有可能隐藏在超频选项之中。选项可能就叫做 “VT-d” 或者 “AMD-Vi” ，也有可能是更通用的名称，比如“虚拟化技术”之类。有可能您主板的手册并不会解释这些。
</p>
<p>设置<a href="../en/Kernel_parameters.html" title="Kernel parameters">内核参数</a>以启用 IOMMU，注意不同品牌的 CPU 所需的内核参数并不同。
</p>
<ul>
<li>对于 Intel CPU(VT-d)，使用 <code>intel_iommu=on</code>。</li>
<li>对于 AMD CPU(AMD-Vi)，使用 <code>amd_iommu=on</code>。</li>
</ul>
<p>您同时需要设置<code>iommu=pt</code>，这将防止Linux试图接触(touching)无法直通的设备。
</p>
<p>在重启之后，检查 dmesg 以确认 IOMMU 已经被正确启用：
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">dmesg | grep -e DMAR -e IOMMU</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">[    0.000000] ACPI: DMAR 0x00000000BDCB1CB0 0000B8 (v01 INTEL  BDW      00000001 INTL 00000001)
[    0.000000] Intel-IOMMU: enabled
[    0.028879] dmar: IOMMU 0: reg_base_addr fed90000 ver 1:0 cap c0000020660462 ecap f0101a
[    0.028883] dmar: IOMMU 1: reg_base_addr fed91000 ver 1:0 cap d2008c20660462 ecap f010da
[    0.028950] IOAPIC id 8 under DRHD base  0xfed91000 IOMMU 1
[    0.536212] DMAR: No ATSR found
[    0.536229] IOMMU 0 0xfed90000: using Queued invalidation
[    0.536230] IOMMU 1 0xfed91000: using Queued invalidation
[    0.536231] IOMMU: Setting RMRR:
[    0.536241] IOMMU: Setting identity map for device 0000:00:02.0 [0xbf000000 - 0xcf1fffff]
[    0.537490] IOMMU: Setting identity map for device 0000:00:14.0 [0xbdea8000 - 0xbdeb6fff]
[    0.537512] IOMMU: Setting identity map for device 0000:00:1a.0 [0xbdea8000 - 0xbdeb6fff]
[    0.537530] IOMMU: Setting identity map for device 0000:00:1d.0 [0xbdea8000 - 0xbdeb6fff]
[    0.537543] IOMMU: Prepare 0-16MiB unity mapping for LPC
[    0.537549] IOMMU: Setting identity map for device 0000:00:1f.0 [0x0 - 0xffffff]
[    2.182790] [drm] DMAR active, disabling use of stolen memory
</pre>
<h3>
<span id=".E7.A1.AE.E4.BF.9D.E7.BB.84.E6.9C.89.E6.95.88"></span><span class="mw-headline" id="确保组有效">确保组有效</span>
</h3>
<p>这个脚本将输出您的 PCI 设备是如何被分配到 IOMMU 组之中的。如果这个脚本没有输出任何东西，这代表您并没有启用 IOMMU 支持或者是您的硬件不支持 IOMMU。
</p>
<pre>#!/bin/bash
shopt -s nullglob
for d in /sys/kernel/iommu_groups/*/devices/*; do 
    n=${d#*/iommu_groups/*}; n=${n%%/*}
    printf 'IOMMU Group %s ' "$n"
    lspci -nns "${d##*/}"
done;
</pre>
<p>例子：
</p>
<pre>IOMMU Group 0 00:00.0 Host bridge [0600]: Intel Corporation 2nd Generation Core Processor Family DRAM Controller [8086:0104] (rev 09)
IOMMU Group 1 00:16.0 Communication controller [0780]: Intel Corporation 6 Series/C200 Series Chipset Family MEI Controller #1 [8086:1c3a] (rev 04)
IOMMU Group 2 00:19.0 Ethernet controller [0200]: Intel Corporation 82579LM Gigabit Network Connection [8086:1502] (rev 04)
IOMMU Group 3 00:1a.0 USB controller [0c03]: Intel Corporation 6 Series/C200 Series Chipset Family USB Enhanced Host Controller #2 [8086:1c2d] (rev  
...
</pre>
<p>一个 IOMMU 组是将物理设备直通给虚拟机的最小单位（这不意味着您必须直通整个 USB 控制器，单独的 USB 设备，如键盘鼠标，可以单独设置直通）。例如，在上面的例子中，在 06:00.0 上的显卡和在6:00.1上的音频控制器被分配到13组，它们必须一起直通给虚拟机。前置 USB 控制器被分在了单独的一组（第2组），并不和 USB 扩展控制器（第10组）和后置USB控制器（第4组）分在一组，这意味着它们都可以在<a href="#USB%E6%8E%A7%E5%88%B6%E5%99%A8">不影响其它设备的情况下直通给虚拟机</a>。
</p>
<h3>
<span id=".E6.B3.A8.E6.84.8F"></span><span class="mw-headline" id="注意">注意</span>
</h3>
<h4>
<span id=".E5.A6.82.E6.9E.9C.E5.AE.A2.E6.88.B7.E6.9C.BA.E6.89.80.E7.94.A8.E6.98.BE.E5.8D.A1.E6.8F.92.E5.9C.A8_CPU_.E6.8F.90.E4.BE.9B.E7.9A.84_PCI-E_.E6.8F.92.E6.A7.BD.E4.B8.AD"></span><span class="mw-headline" id="如果客户机所用显卡插在_CPU_提供的_PCI-E_插槽中">如果客户机所用显卡插在 CPU 提供的 PCI-E 插槽中</span>
</h4>
<p>并非所有的PCI-E插槽均相同。许多主板同时具有 CPU 提供和 PCH 提供的 PCI-E 插槽。根据 CPU 不同，可能您 CPU 提供的 PCI-E 插槽并不能正确隔离。在这种情况下，PCI-E 插槽本身和所连接设备将分在同一组。
</p>
<pre>IOMMU Group 1 00:01.0 PCI bridge: Intel Corporation Xeon E3-1200 v2/3rd Gen Core processor PCI Express Root Port (rev 09)
IOMMU Group 1 01:00.0 VGA compatible controller: NVIDIA Corporation GM107 [GeForce GTX 750] (rev a2)
IOMMU Group 1 01:00.1 Audio device: NVIDIA Corporation Device 0fbc (rev a1)
</pre>
<p>如果上一节的脚本输出类似这样，那么您的 PCI-E 插槽就属于上面所述的情况。根据您在 PCI-E 插槽上连接的设备和PCI-E插槽是由PCH还是CPU提供的，您可能发现在需要被直通的组中还有其它的设备，您必须将整个组中的设备全部直通给虚拟机。如果您愿意这样做的话，那么就可以继续。否则，您需要尝试将显卡插入其他的 PCI-E 插槽（如果有的话）并查看这些插槽是否能正确隔离。您也可以安装 ACS 补丁来绕过这个限制，不过这也有相应的缺点。要获得关于 ACS 补丁的更多信息，请参阅<a href="#%E5%88%86%E7%A6%BBIOMMU%E7%BB%84(ACS%E8%A1%A5%E4%B8%81)">#分离IOMMU组(ACS补丁)</a>
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 如果您需要直通的设备像这样和其他的设备分在一组，那么PCI根设备 （pci root ports） 和 PCI Bridge <b>不</b>应在启动时绑定到vfio，也<b>不</b>应添加到虚拟机。</div>
<h2>
<span id=".E9.9A.94.E7.A6.BBGPU"></span><span class="mw-headline" id="隔离GPU">隔离GPU</span>
</h2>
<p>为了将设备分配给虚拟机，此设备和同在一个IOMMU组的所有设备必须将驱动程序更换为 stub 或是 vfio ，以防止宿主机尝试与其交互。对于大多数设备，在虚拟机启动时就可以完成这项工作。
</p>
<p>但是，由于它们的大小和复杂性，GPU 驱动程序并不倾向于支持动态的重新绑定。所以一般您不能将宿主机所使用的显卡直通给虚拟机，这会导致驱动程序之间的冲突。因此，通常情况下建议在启动虚拟机之前手动绑定这些占位 (placeholder) 驱动，防止其他驱动程序尝试认领 (claim) 设备。
</p>
<p>以下部分详细地介绍了如何配置GPU，以便在启动过程中尽早绑定这些占位 (placeholder) 驱动程序，这会使设备处于非活动状态，直到虚拟机认领 (claim) 设备或是切换到其他驱动程序。这是首选方法，因为相比于系统完全启动之后再切换驱动程序，这种方法要简单许多。
</p>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>警告：</strong> 在配置完成并重新启动之后，无论您配置的 GPU 是什么，它都将无法在宿主机上使用，直到您取消配置。在执行操作之前，确保您要在宿主机上使用的GPU 已经被正确配置，并且您也应该在BIOS中将宿主机所使用的GPU设为主要GPU。</div>
<p>从 Linux 4.1 开始，内核包括了 <code>vfio-pci</code> 。这是一个 VFIO 驱动程序，与 <code>pci-stub</code> 的作用相同。但它可以在一定程度上控制设备，例如在不使用设备的时候将它们切换到 D3 状态。
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ modinfo vfio-pci</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">filename:       /lib/modules/4.4.5-1-ARCH/kernel/drivers/vfio/pci/vfio-pci.ko.gz
description:    VFIO PCI - User Level meta-driver
author:         Alex Williamson &lt;alex.williamson@redhat.com&gt;
...
</pre>
<p><code>vfio-pci</code>通常通过 ID 来定位 PCI 设备，这意味着您只需要指定设备的ID就可以完成绑定。对于下面的 IOMMU 组，您可能希望将<code>vfio-pci</code>与 <code>10de:13c2</code> 和 <code>10de:0fbb</code> 绑定，这将作为本章节其余部分的示例值。
</p>
<pre>IOMMU Group 13 06:00.0 VGA compatible controller: NVIDIA Corporation GM204 [GeForce GTX 970] [10de:13c2] (rev a1)
IOMMU Group 13 06:00.1 Audio device: NVIDIA Corporation GM204 High Definition Audio Controller [10de:0fbb] (rev a1)}}
</pre>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 如果宿主机和客户机所使用的GPU设备ID相同（例如是同一型号）那么就不能使用供应商-设备ID来指定需要隔离的设备。如果是这种情况，参见 <a href="#%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%92%8C%E5%AE%A2%E6%88%B7%E6%9C%BA%E4%BD%BF%E7%94%A8%E7%9B%B8%E5%90%8C%E7%9A%84GPU">#宿主机和客户机使用相同的GPU</a>。</div>
<p>您需要加载<code>vfio-pci</code>，并将设备-供应商ID参数传递给内核。
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/modprobe.d/vfio.conf</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">options vfio-pci ids=10de:13c2,10de:0fbb</pre>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 像上面提到过的一样，<a href="#%E5%A6%82%E6%9E%9C%E5%AE%A2%E6%88%B7%E6%9C%BA%E6%89%80%E7%94%A8%E6%98%BE%E5%8D%A1%E6%8F%92%E5%9C%A8_CPU_%E6%8F%90%E4%BE%9B%E7%9A%84_PCI-E_%E6%8F%92%E6%A7%BD%E4%B8%AD">#如果客户机所用显卡插在 CPU 提供的 PCI-E 插槽中</a>，并且 PCI 根设备是 IOMMU 组的一部分，<b>不</b>要将根设备的 ID 传递给<code>vfio-pci</code>，因为他需要连接到宿主机以保持正常运行。但是，该组中的任何其它设备都应该绑定到<code>vfio-pci</code>。</div>
<p>但是，这并不能保证<code>vfio-pci</code>会在其它图形驱动之前加载。为了确保这一点，我们需要在initramfs中静态绑定它和它的依赖项。按照<code>vfio_pci</code>，<code>vfio</code>，<code>vfio_iommu_type1</code>，<code>vfio_virqfd</code> 的顺序添加到<a href="../en/Mkinitcpio.html" title="Mkinitcpio">mkinitcpio</a>：
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/mkinitcpio.conf</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">MODULES=(... vfio_pci vfio vfio_iommu_type1 vfio_virqfd ...)</pre>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 如果您还有另一个驱动程序以这种方式进行<a href="../en/Kernel_mode_setting.html#Early_KMS_start" title="Kernel mode setting">Early modesetting</a>，例如<code>nouveau</code>，<code>radeon</code>，<code>amdgpu</code>，<code>i915</code>等等，则上述的所有 vfio 模块都必须在它们之前。</div>
<p>另外，确保 modconf hook 在<code>mkinitcpio.conf</code>的 HOOKS 列表中：
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/mkinitcpio.conf</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">HOOKS=(... modconf ...)</pre>
<p>由于新模块已添加到 initramfs 配置中，因此必须<a href="../en/Mkinitcpio.html#Image_creation_and_activation" class="mw-redirect" title="Regenerate the initramfs">重新生成initramfs</a>。如果您在<code>/etc/modprobe.d/vfio.conf</code>修改了设备ID，您同样需要重新生成它。以便在早期启动过程得知需要隔离的设备。
</p>
<p>重启并验证<code>vfio-pci</code>是否已经正确加载并绑定到正确的设备：
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ dmesg | grep -i vfio</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">[    0.329224] VFIO - User Level meta-driver version: 0.3
[    0.341372] vfio_pci: add [10de:13c2[ffff:ffff]] class 0x000000/00000000
[    0.354704] vfio_pci: add [10de:0fbb[ffff:ffff]] class 0x000000/00000000
[    2.061326] vfio-pci 0000:06:00.0: enabling device (0100 -&gt; 0103)
</pre>
<p><code>vfio.conf</code>中所绑定的设备（甚至是需要直通的设备）并不一定会出现在 dmesg 的输出之中。有时尽管设备没有出现在 dmesg 的输出中，但实际上在虚拟机中可以被使用。
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ lspci -nnk -d 10de:13c2</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">06:00.0 VGA compatible controller: NVIDIA Corporation GM204 [GeForce GTX 970] [10de:13c2] (rev a1)
	Kernel driver in use: vfio-pci
	Kernel modules: nouveau nvidia
</pre>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ lspci -nnk -d 10de:0fbb</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">06:00.1 Audio device: NVIDIA Corporation GM204 High Definition Audio Controller [10de:0fbb] (rev a1)
	Kernel driver in use: vfio-pci
	Kernel modules: snd_hda_intel
</pre>
<h2>
<span id=".E8.AE.BE.E7.BD.AE_OVMF_.E8.99.9A.E6.8B.9F.E6.9C.BA"></span><span class="mw-headline" id="设置_OVMF_虚拟机">设置 OVMF 虚拟机</span>
</h2>
<p>OVMF是一个为QEMU虚拟机开发的开源UEFI固件，虽然您可以使用 SeaBIOS 来获得和 PCI 直通类似的结果，但设置过程并不相同。如果您的硬件支持，则最好使用EFI方法。
</p>
<h3>
<span id=".E9.85.8D.E7.BD.AElibvirt"></span><span class="mw-headline" id="配置libvirt">配置libvirt</span>
</h3>
<p><a href="../en/Libvirt.html" title="Libvirt">Libvirt</a> 是许多虚拟化实用程序的包装，可以极大的简化虚拟机的配置和部署过程。对于 KVM 和 QEMU ，它提供的前端让我们避免处理 QEMU 的权限，并使得在现有的虚拟机上添加和删除设备更加容易。但是，作为一个包装，它可能并不总是支持最新的 QEMU 功能，最终可能需要一些提供的脚本为 QEMU 传递一些额外的参数。
</p>
<p>安装<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=qemu">qemu</a></span>、<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=libvirt">libvirt</a></span>、<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=ovmf">ovmf</a></span><sup>[<a href="../en/Help:Procedures.html#Fix_broken_package_links" title="Help:Procedures">断开的链接</a>：replaced by <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=edk2-ovmf">edk2-ovmf</a></span>]</sup>和<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=virt-manager">virt-manager</a></span>之后，将您的 OVMF 固件映像和运行时变量模板添加到 libvirt 配置中，以便让 <code>virt-install</code>或是<code>virt-manager</code> 可以找到它们。
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/libvirt/qemu.conf</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">nvram = [
	"/usr/share/ovmf/x64/OVMF_CODE.fd:/usr/share/ovmf/x64/OVMF_VARS.fd"
]</pre>
<p>您现在可以<a href="../en/Systemd.html#Using_units" class="mw-redirect" title="Enable">启用</a>并<a href="../en/Systemd.html#Using_units" class="mw-redirect" title="Start">启动</a><code>libvirtd.service</code>和它的日志记录组件<code>virtlogd.socket</code>。
</p>
<h3>
<span id=".E5.AE.89.E8.A3.85.E5.AE.A2.E6.88.B7.E6.9C.BA.E7.B3.BB.E7.BB.9F"></span><span class="mw-headline" id="安装客户机系统">安装客户机系统</span>
</h3>
<p>使用 <code>virt-manager</code> 配置虚拟机的大部分过程都无需指导，只要按照屏幕上的提示即可。
</p>
<p>如果使用<code>virt-manager</code>，则必须将用户添加到 <code>libvirt</code> <a href="../en/Users_and_groups.html#Group_management" class="mw-redirect" title="User group">组</a>。
</p>
<p>但是，您仍应该特别注意如下步骤：
</p>
<ul>
<li>在虚拟机创建向导要求您命名虚拟机时（点击“完成”前的最后一步），勾选“在安装前自定义配置”。</li>
<li>在“概况”屏幕，将“固件”选为<a rel="nofollow" class="external text" href="https://i.imgur.com/73r2ctM.png">"UEFI"</a>，如果您不能选择它，检查是否在<code>/etc/libvirt/qemu.conf</code>正确配置了固件的路径并且<a href="../en/Systemd.html#Using_units" class="mw-redirect" title="Restart">重新启动</a>了<code>libvirtd.service</code>。</li>
</ul>
<ul>
<li>在“CPUs”屏幕，将CPU型号改为"<code>host-passthrough</code>"。如果它不在列表中，则您必须手动输入。这确保您的CPU会被正确检测，从而能使 libvirt 完全暴露您 CPU 的功能，而不是仅仅是它所识别到的那些（这会让 CPU 按默认行为运作）。如果不进行这项设置，某些程序可能会抱怨说您的 CPU 型号是未知的。</li>
<li>如果要最小化IO开销，请点击“添加硬件”，并在“控制器：中选择“SCSI”类型，型号为 "VirtIO SCSI"。你可以将默认的 IDE 磁盘改为 SCSI 磁盘，并绑定到上述的控制器。
<ul><li>Windows 不包含VirtIO驱动程序，所以你需要从<a rel="nofollow" class="external text" href="https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/latest-virtio/">这里</a>下载包含驱动程序的 ISO 并且添加一个IDE CDROM（Windows 8.1之后可以使用SATA）并且连接到刚才的 ISO 。否则在安装过程中 Windows 无法识别 VirtIO 控制器。当 Windows 安装程序要求您选择要安装的磁盘时，加载 CD-ROM 下 visscsi 目录下的驱动程序。</li></ul>
</li>
</ul>
<p>其余的安装过程将使用在窗口中运行的标准QXL图形适配器进行。此时，无需为其余虚拟设备安装驱动程序，因为一些虚拟设备将被删除。客户机操作系统安装完成之后，只需要关闭虚拟机即可。您还可能会直接进入UEFI菜单，而不是自动从安装程序引导。客户机在启动的时候可能并未检测到正确的ISO文件，您需要手动指定引导顺序。点击“exit”并选择“boot manager”，您将会进入一个选择引导设备的菜单。
</p>
<h3>
<span id=".E9.99.84.E5.8A.A0PCI.E8.AE.BE.E5.A4.87"></span><span class="mw-headline" id="附加PCI设备">附加PCI设备</span>
</h3>
<p>当安装完成之后，就可以编辑libvirt中的硬件详情并且删除一些虚拟设备。例如spcie通道和虚拟显示器，QXL图形适配器，虚拟鼠标键盘以及数位板设备。由于您没有可用的输入设备，您可能还想将几个主机上的USB设备附加到虚拟机。但请记住，<b>至少为宿主机留下一个鼠标和/或键盘</b>，防止客户机出现问题的时候无法操作宿主机。此时，可以添加先前隔离的PCI设备。只需单击“添加硬件”然后选择需要使用的PCI主机设备。如果一切顺利，连接到GPU的显示器上应该会显示OVMF启动画面，并可以正常启动。您可以在这时安装其他的驱动程序。
</p>
<h3>
<span id=".E6.B3.A8.E6.84.8F_2"></span><span class="mw-headline" id="注意_2">注意</span>
</h3>
<h4>
<span id="OVMF.E8.99.9A.E6.8B.9F.E6.9C.BA.E4.B8.8D.E8.83.BD.E5.BC.95.E5.AF.BC.E9.9D.9EEFI.E9.95.9C.E5.83.8F"></span><span class="mw-headline" id="OVMF虚拟机不能引导非EFI镜像">OVMF虚拟机不能引导非EFI镜像</span>
</h4>
<p>OVMF固件不支持启动非EFI介质。如果启动虚拟机之后您直接看到了UEFI Shell，可能是您的引导介质无效。尝试使用其他的引导映像来确定问题。
</p>
<h2>
<span id=".E6.80.A7.E8.83.BD.E8.B0.83.E6.95.B4"></span><span class="mw-headline" id="性能调整">性能调整</span>
</h2>
<p>使用PCI直通多数涉及性能密集型领域，例如游戏或是GPU加速任务。虽然PCI直通本身就是实现原生性能的一步，但宿主机和客户机仍可以通过一些调整来提升性能。
</p>
<h3>
<span id="CPU.E6.A0.B8.E5.BF.83.E5.9B.BA.E5.AE.9A"></span><span class="mw-headline" id="CPU核心固定">CPU核心固定</span>
</h3>
<p>默认情况下，KVM将虚拟机的操作作为虚拟处理器的多个线程运行（The default behavior for KVM guests is to run operations coming from the guest as a number of threads representing virtual processors）。这些线程由Linux调度程序管理，如同其他线程一样。并根据 niceness 和 priority 分配给任何可用的CPU核心。因此，当线程切换到另一个核心时，核心的高速缓存将无法发挥作用，这可能会显著影响虚拟机的性能。CPU核心固定旨在解决这些问题，因为它会忽略Linux的线程调度并确保虚拟机的线程始终在特定的内核上运行。例如客户机的核心 0,1,2,3 分别映射到宿主机的 4,5,6,7 核心。
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 某些启用CPU核心固定的用户可能会遇到卡顿和短暂挂起的问题。尤其是在使用MuQSS调度程序的情况下（存在与linux-ck内核和linux-zen内核）。如果遇到类似的问题，您可能需要首先禁用固定，保证始终具有最大的即时响应性能。</div>
<h4>
<span id="CPU_.E6.8B.93.E6.89.91"></span><span class="mw-headline" id="CPU_拓扑">CPU 拓扑</span>
</h4>
<p>大多数现代CPU都支持硬件多任务处理，即 Intel CPU 上的超线程或 AMD CPU 上的 SMT。 超线程/SMT 让一个物理核心具有两个虚拟线程。您需要根据虚拟机和宿主机的用途来设置 CPU 核心固定。
</p>
<p>要查看您的 CPU 拓扑，运行 <code>lscpu -e</code>：
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 需要特别注意 <b>"CORE"</b> 栏，它表明了虚拟核心和物理核心的对应关系。</div>
<p>6c/12t Ryzen 5 1600 上的 <code>lscpu -e</code> 输出：
</p>
<pre>CPU NODE SOCKET CORE L1d:L1i:L2:L3 ONLINE MAXMHZ    MINMHZ
0   0    0      0    0:0:0:0       yes    3800.0000 1550.0000
1   0    0      0    0:0:0:0       yes    3800.0000 1550.0000
2   0    0      1    1:1:1:0       yes    3800.0000 1550.0000
3   0    0      1    1:1:1:0       yes    3800.0000 1550.0000
4   0    0      2    2:2:2:0       yes    3800.0000 1550.0000
5   0    0      2    2:2:2:0       yes    3800.0000 1550.0000
6   0    0      3    3:3:3:1       yes    3800.0000 1550.0000
7   0    0      3    3:3:3:1       yes    3800.0000 1550.0000
8   0    0      4    4:4:4:1       yes    3800.0000 1550.0000
9   0    0      4    4:4:4:1       yes    3800.0000 1550.0000
10  0    0      5    5:5:5:1       yes    3800.0000 1550.0000
11  0    0      5    5:5:5:1       yes    3800.0000 1550.0000
</pre>
<p>6c/12t Intel 8700k 上的 <code>lscpu -e</code> 输出：
</p>
<pre>CPU NODE SOCKET CORE L1d:L1i:L2:L3 ONLINE MAXMHZ    MINMHZ
0   0    0      0    0:0:0:0       yes    4600.0000 800.0000
1   0    0      1    1:1:1:0       yes    4600.0000 800.0000
2   0    0      2    2:2:2:0       yes    4600.0000 800.0000
3   0    0      3    3:3:3:0       yes    4600.0000 800.0000
4   0    0      4    4:4:4:0       yes    4600.0000 800.0000
5   0    0      5    5:5:5:0       yes    4600.0000 800.0000
6   0    0      0    0:0:0:0       yes    4600.0000 800.0000
7   0    0      1    1:1:1:0       yes    4600.0000 800.0000
8   0    0      2    2:2:2:0       yes    4600.0000 800.0000
9   0    0      3    3:3:3:0       yes    4600.0000 800.0000
10  0    0      4    4:4:4:0       yes    4600.0000 800.0000
11  0    0      5    5:5:5:0       yes    4600.0000 800.0000
</pre>
<p>如上所示，对于上面的 AMD CPU，CPU 0 和 CPU 1 对应 CORE 0，对于上面的英特尔 CPU，CPU 0 和 CPU 6 对应 CORE 0。
</p>
<p>如果您不需要虚拟机使用所有核心，那么最好给宿主机留下一个核心。选择要用于宿主机或虚拟机的核心应该基于CPU的特定硬件特性，但在大多数情况下，“CORE0”是宿主机的不错选择。如果为宿主机保留了任何核心，建议将模拟器和 iothreads（如果使用）固定到宿主机核心而不是虚拟 CPU 上。这可以提高性能并减少虚拟机的延迟，因为这些线程不会污染缓存或争抢虚拟 CPU 线程调度。如果虚拟机需要使用所有核心，那么固定模拟器或 iothreads 是没有必要的。
</p>
<h4>
<span id="XML_.E7.A4.BA.E4.BE.8B"></span><span class="mw-headline" id="XML_示例">XML 示例</span>
</h4>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 如果你的磁盘控制器没有启用 <b>iothread</b>，那就不要使用下面例子中的 <b>iothread</b>。<b>iothread</b>只在<b>virtio-scsi</b> 或是 <b>virtio-blk</b> 设备上工作。</div>
<h5>
<span id="4c.2F1t_.E6.97.A0.E8.B6.85.E7.BA.BF.E7.A8.8B.E7.9A.84.E4.BE.8B.E5.AD.90"></span><span class="mw-headline" id="4c/1t_无超线程的例子">4c/1t 无超线程的例子</span>
</h5>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
&lt;vcpu placement='static'&gt;4&lt;/vcpu&gt;
&lt;cputune&gt;
    &lt;vcpupin vcpu='0' cpuset='0'/&gt;
    &lt;vcpupin vcpu='1' cpuset='1'/&gt;
    &lt;vcpupin vcpu='2' cpuset='2'/&gt;
    &lt;vcpupin vcpu='3' cpuset='3'/&gt;
&lt;/cputune&gt;
...
</pre>
<h5>
<span id="6c.2F2t_Intel_CPU_.E5.9B.BA.E5.AE.9A.E7.9A.84.E4.BE.8B.E5.AD.90"></span><span class="mw-headline" id="6c/2t_Intel_CPU_固定的例子">6c/2t Intel CPU 固定的例子</span>
</h5>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
&lt;vcpu placement='static'&gt;8&lt;/vcpu&gt;
&lt;iothreads&gt;1&lt;/iothreads&gt;
&lt;cputune&gt;
    &lt;vcpupin vcpu='0' cpuset='2'/&gt;
    &lt;vcpupin vcpu='1' cpuset='8'/&gt;
    &lt;vcpupin vcpu='2' cpuset='3'/&gt;
    &lt;vcpupin vcpu='3' cpuset='9'/&gt;
    &lt;vcpupin vcpu='4' cpuset='4'/&gt;
    &lt;vcpupin vcpu='5' cpuset='10'/&gt;
    &lt;vcpupin vcpu='6' cpuset='5'/&gt;
    &lt;vcpupin vcpu='7' cpuset='11'/&gt;
    &lt;emulatorpin cpuset='0,6'/&gt;
    &lt;iothreadpin iothread='1' cpuset='0,6'/&gt;
&lt;/cputune&gt;
    ...
    &lt;topology sockets='1' cores='4' threads='2'/&gt;
    ...
</pre>
<h5>
<span id="4c.2F2t_AMD_CPU_.E7.9A.84.E4.BE.8B.E5.AD.90"></span><span class="mw-headline" id="4c/2t_AMD_CPU_的例子">4c/2t AMD CPU 的例子</span>
</h5>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
&lt;vcpu placement='static'&gt;8&lt;/vcpu&gt;
&lt;iothreads&gt;1&lt;/iothreads&gt;
&lt;cputune&gt;
  &lt;vcpupin vcpu='0' cpuset='2'/&gt;
  &lt;vcpupin vcpu='1' cpuset='3'/&gt;
  &lt;vcpupin vcpu='2' cpuset='4'/&gt;
  &lt;vcpupin vcpu='3' cpuset='5'/&gt;
  &lt;vcpupin vcpu='4' cpuset='6'/&gt;
  &lt;vcpupin vcpu='5' cpuset='7'/&gt;
  &lt;vcpupin vcpu='6' cpuset='8'/&gt;
  &lt;vcpupin vcpu='7' cpuset='9'/&gt;
  &lt;emulatorpin cpuset='0-1'/&gt;
  &lt;iothreadpin iothread='1' cpuset='0-1'/&gt;
&lt;/cputune&gt;
    ...
    &lt;topology sockets='1' cores='4' threads='2'/&gt;
    ...
</pre>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 如果你需要进一步的 CPU 隔离，考虑在未使用的物理/虚拟核心上使用 <b>isolcpus</b> 内核选项。</div>
<p>如果您不打算在使用虚拟机时在宿主机上进行计算繁重的工作（或是根本不打算在宿主机上做任何事情），您可以将虚拟线程固定在所有核心上以便充分使用 CPU 时间。不过，固定所有物理和虚拟核心可能会导致虚拟机出现延迟。
</p>
<h3>
<span id=".E5.86.85.E5.AD.98.E5.A4.A7.E5.88.86.E9.A1.B5"></span><span class="mw-headline" id="内存大分页">内存大分页</span>
</h3>
<p>在处理需要大量内存的应用程序时，内存延迟可能会是一个问题，因为使用的内存分页越多，程序尝试跨分页访问信息的可能性就越高（页是基本的内存分配单位）。将分页解析为实际的内存地址需要多个步骤，因此CPU通常将信息缓存在最近使用的分页上，以加快后续的内存使用。使用大量内存的应用程序可能会遇到内存性能问题：例如，虚拟机使用 4GB 内存，分页大小为 4KB（这是普通分页的默认大小），总共104万页，这意味着缓存命中率可能会大幅降低并大幅增加内存延迟。大分页通过向应用程序提供更大的单个分页来缓解这个问题，从而增加了多个操作中连续位于同一分页的几率。
</p>
<h4>
<span id=".E9.80.8F.E6.98.8E.E5.A4.A7.E5.88.86.E9.A1.B5"></span><span class="mw-headline" id="透明大分页">透明大分页</span>
</h4>
<p>QEMU 将在 QEMU 或 Libvirt 中自动使用 2 MiB 大小的透明大分页，但这可能并不那么顺利，在使用 VFIO 时，页面会在启动时锁定，并且在虚拟机首次启动时会预先分配透明的大分页。如果内存高度碎片化，或者虚拟机正在使用大部分剩余内存，则内核可能没有足够的2 MiB 页面来完全满足分配。在这种情况下，将会混合使用使用 2 MiB 和 4 KiB 分页，从而无法得到足够的性能提升。由于分页在 VFIO 模式下被锁定，因此内核无法在虚拟机启动后将这些 4 KiB 分页转换为大分页。THP（透明大分页）可用的 2 MiB 大页面数量与通过以下各节中描述的<a href="#%E5%86%85%E5%AD%98%E5%A4%A7%E5%88%86%E9%A1%B5">#内存大分页</a>机制相同。
</p>
<p>要查看全局使用的 THP 内存量：
</p>
<pre>$ grep AnonHugePages /proc/meminfo
AnonHugePages:   8091648 kB
</pre>
<p>要查看特定 QEMU 实例所使用的 THP ，需要指定 QEMU 的 PID：
</p>
<pre>$ grep -P 'AnonHugePages:\s+(?!0)\d+' /proc/[PID]/smaps
AnonHugePages:   8087552 kB
</pre>
<p>在这个例子中，虚拟机分配了 8388608 KiB 的内存，但只有 8087552 KiB 可通过 THP 获得。 剩下的301056KiB被分配为 4 KiB 分页。没有任何警告提示使用了 4 KiB 分页。因此，THP 的有效性在很大程度上取决于虚拟机启动时宿主机系统的内存碎片。如果这是不可接受的，建议使用<a href="#%E5%86%85%E5%AD%98%E5%A4%A7%E5%88%86%E9%A1%B5">#内存大分页</a>。
</p>
<p>Arch 内核已经编译并默认启用了 THP，默认为 <code>madvise</code> 模式。可在 <code>/sys/kernel/mm/transparent_hugepage/enabled</code> 查看。
</p>
<h4><span class="mw-headline" id="Static_huge_pages">Static huge pages</span></h4>
<p>While transparent huge pages should work in the vast majority of cases, they can also be allocated statically during boot. This should only be needed to make use 1 GiB hugepages on machines that support it, since transparent huge pages normally only go up to 2 MiB.
</p>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>Warning:</strong> Static huge pages lock down the allocated amount of memory, making it unavailable for applications that are not configured to use them. Allocating 4 GiBs worth of huge pages on a machine with 8 GiB of memory will only leave you with 4 GiB of available memory on the host <b>even when the VM is not running</b>.</div>
<p>To allocate huge pages at boot, one must simply specify the desired amount on their kernel command line with <code>hugepages=<i>x</i></code>. For instance, reserving 1024 pages with <code>hugepages=1024</code> and the default size of 2048 KiB per huge page creates 2 GiB worth of memory for the virtual machine to use.
</p>
<p>If supported by CPU page size could be set manually. 1 GiB huge page support could be verified by <code>grep pdpe1gb /proc/cpuinfo</code>. Setting 1 GiB huge page size via kernel parameters : <code>default_hugepagesz=1G hugepagesz=1G hugepages=X</code>.
</p>
<p>Also, since static huge pages can only be used by applications that specifically request it, you must add this section in your libvirt domain configuration to allow kvm to benefit from them :
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
&lt;memoryBacking&gt;
	&lt;hugepages/&gt;
&lt;/memoryBacking&gt;
...
</pre>
<h4><span class="mw-headline" id="Dynamic_huge_pages">Dynamic huge pages</span></h4>
<div class="noprint archwiki-template-message">
<p><a href="../File:Tango-inaccurate.png" class="image"><img alt="Tango-inaccurate.png" src="../File:Tango-inaccurate.png" decoding="async" width="48" height="48"></a><b>The factual accuracy of this article or section is disputed.</b><a href="../File:Tango-inaccurate.png" class="image"><img alt="Tango-inaccurate.png" src="../File:Tango-inaccurate.png" decoding="async" width="48" height="48"></a></p>
<div>
<b>Reason:</b> Need futher testing if this variant as effective as static one (Discuss in <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/index.php/Talk:PCI_passthrough_via_OVMF_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)">Talk:PCI passthrough via OVMF (简体中文)#</a>)</div>
</div>
<p>Hugepages could be allocated manually via <code>vm.nr_overcommit_hugepages</code> <a href="../en/Sysctl.html" title="Sysctl">sysctl</a> parameter.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/sysctl.d/10-kvm.conf</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">vm.nr_hugepages = 0
vm.nr_overcommit_hugepages = <i>num</i></pre>
<p>Where <code><i>num</i></code> - is the number of huge pages, which default size if 2 MiB.
Pages will be automatically allocated, and freed after VM stops.
</p>
<p>More manual way:
</p>
<pre># echo <i>num</i> &gt; /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages
# echo <i>num</i> &gt; /sys/kernel/mm/hugepages/hugepages-1048576kB/nr_hugepages
</pre>
<p>For 2 MiB and 1 GiB page size respectively.
And they should be manually freed in the same way.
</p>
<p>It is hardly recommended to drop caches, compact memory and wait couple of seconds before starting VM, as there could be not enough free contiguous memory for required huge pages blocks. Especially after some uptime of the host system.
</p>
<pre># echo 3 &gt; /proc/sys/vm/drop_caches
# echo 1 &gt; /proc/sys/vm/compact_memory
</pre>
<p>Theoretically, 1 GiB pages works as 2 MiB. But practically - no guaranteed way was found to get contiguous 1 GiB memory blocks. Each consequent request of 1 GiB blocks lead to lesser and lesser dynamically allocated count.
</p>
<h3>
<span id="CPU.E8.B0.83.E9.80.9F.E5.99.A8"></span><span class="mw-headline" id="CPU调速器">CPU调速器</span>
</h3>
<p>根据您<a href="../en/CPU_frequency_scaling.html" title="CPU frequency scaling">CPU 调速器</a>的配置方式，虚拟机的线程可能无法达到负载阈值以提升频率。实际上，KVM 自身无法更改 CPU 频率，如果 CPU 频率并不能随着虚拟 CPU 的负载使用而提升，这可能是一个严重的性能问题。检查此问题最简单的方法是在虚拟机上运行 CPU 密集型任务的同时在宿主机上运行<code>watch lscpu</code>检查CPU频率是否上升。如果您的 CPU 频率无法正常上升且无法达到所报告的最大值，可能是由于<a rel="nofollow" class="external text" href="https://lime-technology.com/forum/index.php?topic=46664.msg447678#msg447678">主机操作系统限制了 CPU 升频</a>。这种情况下，尝试手动将所有CPU内核设为最大频率查看是否能够提升性能。请注意，如果您使用带有默认pstate驱动程序的现代Intel芯片，则cpupower命令<a href="../en/CPU_frequency_scaling.html#CPU_frequency_driver" title="CPU frequency scaling">无效</a>，因此请监视<code>/proc/cpuinfo</code>确保您的CPU处于最大频率。
</p>
<h3>
<span id=".E9.AB.98DPC.E5.BB.B6.E8.BF.9F"></span><span class="mw-headline" id="高DPC延迟">高DPC延迟</span>
</h3>
<div class="noprint archwiki-template-message">
<p><a href="../File:Tango-inaccurate.png" class="image"><img alt="Tango-inaccurate.png" src="../File:Tango-inaccurate.png" decoding="async" width="48" height="48"></a><b>The factual accuracy of this article or section is disputed.</b><a href="../File:Tango-inaccurate.png" class="image"><img alt="Tango-inaccurate.png" src="../File:Tango-inaccurate.png" decoding="async" width="48" height="48"></a></p>
<div>
<b>Reason:</b> As far as I can tell all virtio modules listed here are for virtual devices used when Linux runs as a guest. Loading them on the host serves no purpose. (Discuss in <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/index.php/Talk:PCI_passthrough_via_OVMF_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)">Talk:PCI passthrough via OVMF (简体中文)#</a>)</div>
</div>
<p>如果您在虚拟中遇到了高DPC和/或中断延迟，请确保已在主机内核上<a href="../en/Kernel_module.html#Manual_module_handling" class="mw-redirect" title="Kernel modules">加载</a>了所需的VirtIO内核模块，可加载的VirtIO内核模块包括：<code>virtio-pci</code>，<code>virtio-net</code>，<code>virtio-blk</code>，<code>virtio-balloon</code>，<code>virtio-ring</code>和<code>virtio</code>。
</p>
<p>加载一个或多个这些模块后，在宿主机上执行<code>lsmod | grep virtio</code>不应返回空。
</p>
<h4>
<span id=".E4.BD.BF.E7.94.A8isolcpus.E5.9B.BA.E5.AE.9ACPU.E6.A0.B8.E5.BF.83"></span><span class="mw-headline" id="使用isolcpus固定CPU核心">使用isolcpus固定CPU核心</span>
</h4>
<p>此外，确保您已正确隔离CPU。 在本例中，我们假设您使用的是CPU 4-7。 
使用内核参数<code>isolcpus nohz_full rcu_nocbs</code>将CPU与内核完全隔离。
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">sudo vim /etc/defaults/grub</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
GRUB_CMDLINE_LINUX="..your other params.. isolcpus=4-7 nohz_full=4-7 rcu_nocbs=4-7"
...
</pre>
<p>然后，用taskset和chrt运行<code>qemu-system-x86_64</code>：
</p>
<pre># chrt -r 1 taskset -c 4-7 qemu-system-x86_64 ...
</pre>
<p><code>chrt</code>命令将确保任务调度程序将循环分配工作（否则它将全部停留在第一个cpu上）。 对于<code>taskset</code>，CPU编号可以用“，”和“/”或"-"分隔，如“0,1,2,3”或“0-4”或“1,7-8,10”等。
</p>
<p>参考reddit上的这篇<a rel="nofollow" class="external text" href="https://www.reddit.com/r/VFIO/comments/6vgtpx/high_dpc_latency_and_audio_stuttering_on_windows/dm0sfto/">帖子</a>了解详情。
</p>
<h3>
<span id=".E6.8F.90.E9.AB.98AMD_CPU.E7.9A.84.E6.80.A7.E8.83.BD"></span><span class="mw-headline" id="提高AMD_CPU的性能">提高AMD CPU的性能</span>
</h3>
<p>以前，由于一个非常老的<a rel="nofollow" class="external text" href="https://sourceforge.net/p/kvm/bugs/230/">bug</a>，必须在运行 KVM 的 AMD 系统上禁用嵌套页表（NPT）以提高 GPU 性能，但这将降低 CPU 性能，导致卡顿。
</p>
<p>有一个<a rel="nofollow" class="external text" href="https://patchwork.kernel.org/patch/10027525/">内核补丁</a>可以解决这个问题，它已经在4.14-stable和4.9-stable 版本被接受了。 如果你正在运行官方的<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=linux">linux</a></span>或<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=linux-lts">linux-lts</a></span>内核，那么该补丁被已经应用了（请确保你使用的是最新内核）。如果您正在运行另一个内核，您可能需要手动应用补丁。
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 几个Ryzen用户（请参阅这个Reddit<a rel="nofollow" class="external text" href="https://www.reddit.com/r/VFIO/comments/78i3jx/possible_fix_for_the_npt_issue_discussed_on_iommu/">帖子</a>）已经测试了该补丁，并且可以确认它有效，使GPU直通性能接近原生性能。</div>
<h3>
<span id=".E8.BF.9B.E4.B8.80.E6.AD.A5.E8.B0.83.E6.95.B4"></span><span class="mw-headline" id="进一步调整">进一步调整</span>
</h3>
<p><a rel="nofollow" class="external text" href="https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/virtualization_tuning_and_optimization_guide/">Red Hat的虚拟化调试和优化指南（中文）</a>中提供了更专业的VM调优技巧。 如果您遇到以下情况，本指南可能特别有用：
</p>
<ul>
<li>在从虚拟中下载/上传期间，主机CPU负载较高，请参阅“桥接零复制传输”了解可能的修复。</li>
<li>尽管使用了virtio-net，但是在下载/上传期间，访客网络速度有限制。请参阅“多队列virtio-net”以获得可能的修复。</li>
<li>在没有达到负载极限的情况下，虚拟机在高I/O下卡顿。请参阅“多队列virtio-scsi”以获得获得可能的修复。</li>
</ul>
<h2>
<span id=".E7.89.B9.E6.AE.8A.E6.AD.A5.E9.AA.A4"></span><span class="mw-headline" id="特殊步骤">特殊步骤</span>
</h2>
<p>某些机器需要特定的配置调整才能正常工作。 如果您在的宿主机或虚拟机不能正常工作，请查看您的系统是否符合以下情况之一，并尝试相应地调整配置。
</p>
<h3>
<span id=".E5.AE.BF.E4.B8.BB.E6.9C.BA.E5.92.8C.E5.AE.A2.E6.88.B7.E6.9C.BA.E4.BD.BF.E7.94.A8.E7.9B.B8.E5.90.8C.E7.9A.84GPU"></span><span class="mw-headline" id="宿主机和客户机使用相同的GPU">宿主机和客户机使用相同的GPU</span>
</h3>
<div class="noprint archwiki-template-message">
<p><a href="../File:Tango-view-fullscreen.png" class="image"><img alt="Tango-view-fullscreen.png" src="../File:Tango-view-fullscreen.png" decoding="async" width="48" height="48"></a><b>This article or section needs expansion.</b><a href="../File:Tango-view-fullscreen.png" class="image"><img alt="Tango-view-fullscreen.png" src="../File:Tango-view-fullscreen.png" decoding="async" width="48" height="48"></a></p>
<div>
<b>Reason:</b> A number of users have been having issues with this, it should probably be adressed by the article. (Discuss in <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/index.php/Talk:PCI_passthrough_via_OVMF#Additionnal_sections">Talk:PCI passthrough via OVMF#Additionnal sections</a>)</div>
</div>
<p>由于<code>vfio-pci</code>如何使用您的供应商和设备ID对来识别需要在启动时绑定哪个设备，如果您的两个GPU 具有相同的ID，您将无法让您的直通驱动程序只与一个绑定。这种情况下必须使用脚本完成配置，无论您使用哪个驱动程序，都需要使用<code>driver_override</code>机制由pci总线地址完成分配。
</p>
<h4>
<span id=".E8.84.9A.E6.9C.AC.E7.A4.BA.E4.BE.8B"></span><span class="mw-headline" id="脚本示例">脚本示例</span>
</h4>
<h5>
<span id=".E7.9B.B4.E9.80.9A.E9.99.A4.E4.BA.86.E5.90.AF.E5.8A.A8.E6.97.B6.E6.89.80.E7.94.A8GPU.E4.B9.8B.E5.A4.96.E7.9A.84.E6.89.80.E6.9C.89GPU"></span><span class="mw-headline" id="直通除了启动时所用GPU之外的所有GPU">直通除了启动时所用GPU之外的所有GPU</span>
</h5>
<p>在<code>/usr/bin/vfio-pci-override.sh</code>，创建一个脚本让<code>vfio-pci</code>绑定除了启动时所用GPU之外的所有GPU。
</p>
<pre>#!/bin/sh

for i in /sys/devices/pci*/*/boot_vga; do
	if [ $(cat "$i") -eq 0 ]; then
		GPU="${i%/boot_vga}"
		AUDIO="$(echo "$GPU" | sed -e "s/0$/1/")"
		echo "vfio-pci" &gt; "$GPU/driver_override"
		if [ -d "$AUDIO" ]; then
			echo "vfio-pci" &gt; "$AUDIO/driver_override"
		fi
	fi
done

modprobe -i vfio-pci
</pre>
<h5>
<span id=".E7.9B.B4.E9.80.9A.E9.80.89.E5.AE.9A.E7.9A.84GPU"></span><span class="mw-headline" id="直通选定的GPU">直通选定的GPU</span>
</h5>
<p>手动指定需要绑定的GPU。
</p>
<pre>#!/bin/sh

GROUP="0000:00:03.0"
DEVS="0000:03:00.0 0000:03:00.1 ."

if [ ! -z "$(ls -A /sys/class/iommu)" ]; then
	for DEV in $DEVS; do
		echo "vfio-pci" &gt; /sys/bus/pci/devices/$GROUP/$DEV/driver_override
	done
fi

modprobe -i vfio-pci
</pre>
<h4>
<span id=".E8.84.9A.E6.9C.AC.E5.AE.89.E8.A3.85"></span><span class="mw-headline" id="脚本安装">脚本安装</span>
</h4>
<p>创建<code>/etc/modprobe.d/vfio.conf</code>，内容如下:
</p>
<pre>install vfio-pci /usr/bin/vfio-pci-override.sh
</pre>
<p>编辑<code>/etc/mkinitcpio.conf</code>:
</p>
<p>从<code>MODULES</code>中移除所有图形驱动程序，并添加<code>vfio-pci</code>和<code>vfio_iommu_type1</code>
</p>
<pre>MODULES=(ext4 vfat vfio-pci vfio_iommu_type1)
</pre>
<p>将<code>/etc/modprobe.d/vfio.conf</code>和<code>/usr/bin/vfio-pci-override.sh</code>添加到<code>FILES</code>
</p>
<pre>FILES=(/etc/modprobe.d/vfio.conf /usr/bin/vfio-pci-override.sh)
</pre>
<p><a href="../en/Mkinitcpio.html#Image_creation_and_activation" class="mw-redirect" title="Regenerate the initramfs">重新生成initramfs</a>并重新启动。
</p>
<h3>
<span id=".E7.9B.B4.E9.80.9A.E5.90.AF.E5.8A.A8.E6.97.B6.E6.89.80.E7.94.A8.E7.9A.84GPU"></span><span class="mw-headline" id="直通启动时所用的GPU">直通启动时所用的GPU</span>
</h3>
<div class="noprint archwiki-template-message">
<p><a href="../File:Tango-view-fullscreen.png" class="image"><img alt="Tango-view-fullscreen.png" src="../File:Tango-view-fullscreen.png" decoding="async" width="48" height="48"></a><b>This article or section needs expansion.</b><a href="../File:Tango-view-fullscreen.png" class="image"><img alt="Tango-view-fullscreen.png" src="../File:Tango-view-fullscreen.png" decoding="async" width="48" height="48"></a></p>
<div>
<b>Reason:</b> This is related to VBIOS issues and should be moved into a separate section regarding VBIOS compatibility. (Discuss in <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/index.php/Talk:PCI_passthrough_via_OVMF_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)#UEFI_(OVMF)_Compatibility_in_VBIOS">Talk:PCI passthrough via OVMF (简体中文)#UEFI (OVMF) Compatibility in VBIOS</a>)</div>
</div>
<p>标记为<code>boot_vga</code>的GPU在进行PCI直通时比较特殊，BIOS需要使用它才能显示启动消息或BIOS配置菜单等内容。为了完成达到这个目的，需要<a rel="nofollow" class="external text" href="https://www.redhat.com/archives/vfio-users/2016-May/msg00224.html">创建一个可以被自由修改的VGA boot ROM 副本</a>。这个副本可以让系统得知，但直通驱动程序可能会认为这是一个非法的版本。如果可能的话，从BIOS设置中调整启动GPU。如果没有相关选项，调换宿主机和客户机GPU的位置。
</p>
<h3>
<span id=".E4.BD.BF.E7.94.A8Looking_Glass.E5.B0.86.E5.AE.A2.E6.88.B7.E6.9C.BA.E7.94.BB.E9.9D.A2.E6.B5.81.E5.BC.8F.E4.BC.A0.E8.BE.93.E5.88.B0.E5.AE.BF.E4.B8.BB.E6.9C.BA"></span><span class="mw-headline" id="使用Looking_Glass将客户机画面流式传输到宿主机">使用Looking Glass将客户机画面流式传输到宿主机</span>
</h3>
<p>通过使用<a rel="nofollow" class="external text" href="https://looking-glass.hostfission.com/">Looking Glass</a>，可以让宿主机和客户机共享显示器，同时将键盘鼠标动作传递给虚拟机。
</p>
<h4>
<span id=".E5.B0.86IVSHMEM.E8.AE.BE.E5.A4.87.E6.B7.BB.E5.8A.A0.E5.88.B0.E8.99.9A.E6.8B.9F.E6.9C.BA"></span><span class="mw-headline" id="将IVSHMEM设备添加到虚拟机">将IVSHMEM设备添加到虚拟机</span>
</h4>
<p>Looking glass通过在主机和来宾之间创建共享内存缓冲区来完成传输。这比通过localhost流式传输帧快得多，但需要额外的设置。
</p>
<p>关闭你的虚拟机，修改配置：
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
&lt;devices&gt;
    ...
  &lt;shmem name='looking-glass'&gt;
    &lt;model type='ivshmem-plain'/&gt;
    &lt;size unit='M'&gt;32&lt;/size&gt;
  &lt;/shmem&gt;
&lt;/devices&gt;
...
</pre>
<p>您应该根据您要传输的分辨率将32替换为您自己所需要的值。计算方法如下：
</p>
<pre>宽 x 高 x 4 x 2 = 总比特数
总比特数 / 1024 / 1024 = 兆比特数 + 2
</pre>
<p>例如，分辨率为1920x1080
</p>
<pre>1920 x 1080 x 4 x 2 = 16,588,800 比特
16,588,800 / 1024 / 1024 = 15.82 MB + 2 = 17.82
</pre>
<p>实际上的数字应该是<b>大于</b>计算的得数的一个<b>2的幂</b>，因为17.82大于16，所以应该选择32。
</p>
<p>接下来使用一个脚本创建共享内存文件。
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/usr/local/bin/looking-glass-init.sh</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">#!/bin/sh

touch /dev/shm/looking-glass
chown <b>user</b>:kvm /dev/shm/looking-glass
chmod 660 /dev/shm/looking-glass</pre>
<p>将<code>user</code>改为你的用户名。
</p>
<p>记得为脚本授予<a href="../en/Help:Reading.html#Make_executable" class="mw-redirect" title="Executable">可执行</a>权限。
</p>
<p>创建一个<a href="../en/Systemd.html" title="Systemd">systemd</a>单元文件，以便在开机时创建这个文件。
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/systemd/system/looking-glass-init.service</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">[Unit]
Description=Create shared memory for looking glass

[Service]
Type=oneshot
ExecStart=/usr/local/bin/looking-glass-init.sh

[Install]
WantedBy=multi-user.target</pre>
<p><a href="../en/Systemd.html#Using_units" class="mw-redirect" title="Start">启动</a>并<a href="../en/Systemd.html#Using_units" class="mw-redirect" title="Enable">启用</a> <code>looking-glass-init.service</code>。
</p>
<h4>
<span id=".E5.B0.86IVSHMEM.E4.B8.BB.E6.9C.BA.E5.AE.89.E8.A3.85.E5.88.B0Windows.E5.AE.A2.E6.88.B7.E6.9C.BA"></span><span class="mw-headline" id="将IVSHMEM主机安装到Windows客户机">将IVSHMEM主机安装到Windows客户机</span>
</h4>
<p>目前Windows不会通知用户发现新的IVSHMEM设备，它会默默安装虚拟驱动程序。要实际启用该设备，您必须进入设备管理器并在“系统设备”下为“PCI标准RAM控制器”更新设备的驱动程序。因为它在其他地方尚未提供，所以必须从<a rel="nofollow" class="external text" href="https://github.com/virtio-win/kvm-guest-drivers-windows/issues/217">issue 217</a>下载签名的驱动程序。
</p>
<p>安装驱动程序后，您必须下载最新的<a rel="nofollow" class="external text" href="https://looking-glass.hostfission.com/downloads">looking-glass-host</a>，然后在您的客户机上启动它。为了运行它，您还需要安装<a rel="nofollow" class="external text" href="https://www.visualstudio.com/downloads/">Microsoft Visual C ++ Redistributable</a>。可以通过编辑<code>HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Run</code>注册表并添加路径来自动启动它。
</p>
<h4>
<span id=".E5.AE.89.E8.A3.85.E5.AE.A2.E6.88.B7.E7.AB.AF"></span><span class="mw-headline" id="安装客户端">安装客户端</span>
</h4>
<p>Looking glass 客户端可以通过 <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/looking-glass/">looking-glass</a></span><sup><small>AUR</small></sup>或<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/looking-glass-git/">looking-glass-git</a></span><sup><small>AUR</small></sup> 安装。
</p>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>警告：</strong> 如果你在使用<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/looking-glass-git/">looking-glass-git</a></span><sup><small>AUR</small></sup>时出现问题，请选择<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/looking-glass/">looking-glass</a></span><sup><small>AUR</small></sup>。git版本并不受上游支持，可能在任何时候破损。只有带有版本号的发布受到支持，并且保证能与Windows客户机上的主机程序一起使用。</div>
<p>当客户机配置完成之后，您可以通过如下方式运行运行客户端：
</p>
<pre>$ looking-glass-client
</pre>
<p>如果您不想通过spcie传递键盘和鼠标的话，你可以禁用它：
</p>
<pre>$ looking-glass-client -s
</pre>
<p>您也可能希望全屏运行客户端，因为图像缩放会导致质量下降：
</p>
<pre>$ looking-glass-client -F
</pre>
<p>使用<code>--help</code>选项查看更多信息。
</p>
<h3>
<span id=".E7.83.AD.E5.88.87.E6.8D.A2.E5.A4.96.E5.9B.B4.E8.AE.BE.E5.A4.87"></span><span class="mw-headline" id="热切换外围设备">热切换外围设备</span>
</h3>
<p>Looking Glass 包含一个spcie客户端，以便控制Windows客户机。然而，对于某些应用程序，例如游戏，可能延迟太高了。另一种方法是直通特定的USB设备以尽可能地降低延迟。可以在主机和客户机之间热切换设备。
</p>
<p>首先为您想要直通的设备创建一个<code>.xml</code>文件，libvirt使用该文件来识别设备。
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/home/$USER/.VFIOinput/input_1.xml</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">&lt;hostdev mode='subsystem' type='usb' managed='no'&gt;
&lt;source&gt;
&lt;vendor id='0x[Before Colon]'/&gt;
&lt;product id='0x[After Colon]'/&gt;
&lt;/source&gt;
&lt;/hostdev&gt;</pre>
<p>将<code>[before / After Colon]</code>替换为<code>lsusb</code>命令的内容，取决于于您要传递的设备。
</p>
<p>例如，我的鼠标是<code>Bus 005 Device 002: ID 1532:0037 Razer USA, Ltd</code>，所以我的<code>vendor id</code> 是 1532，<code>product id</code> 是 1037。
</p>
<p>重复以上步骤以添加所有想要直通的USB设备。如果您的键盘/鼠标在<code>lsusb</code>中有多个条目，那么请为每个条目创建.xml文件。
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 不要忘记更改上方和下方脚本的路径和名称，以匹配您的环境。</div>
<p>接下来需要创建一个bash脚本来告诉libvirt附加/分离设备。
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/home/$USER/.VFIOinput/input_attach.sh</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">#!/bin/bash

virsh attach-device [VM-Name] [USBdevice]</pre>
<p>将<code>[VM-Name]</code>替换为您的虚拟机名称，名称可以在virt-manager下看到。另外，将<code>[USBdevice]</code>替换为您希望传递的设备的.xml文件的<b>完整</b>路径。为多个设备添加额外的行。例如，这是我的脚本：
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/home/ajmar/.VFIOinput/input_attach.sh</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">#!/bin/bash

virsh attach-device win10 /home/ajmar/.VFIOinput/input_mouse.xml
virsh attach-device win10 /home/ajmar/.VFIOinput/input_keyboard.xml</pre>
<p>接下来复制脚本文件并用<code>detach-device</code>替换<code>attach-device</code>。并为每个脚本设置可执行权限。
</p>
<p>现在可以执行这2个脚本，以将USB设备附加/分离到客户机。注意它们可能需要以root身份执行。要从Windows客户机运行脚本，您可以使用<a href="../en/PuTTY.html" title="PuTTY">PuTTY</a> <a href="../en/Secure_Shell.html" class="mw-redirect" title="SSH">SSH</a>连接到主机，然后执行脚本。在Windows上，PuTTY附带了plink.exe，它可以通过SSH执行单一命令，然后自动关闭，而不是打开SSH终端。
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">detach_devices.bat</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">"C:\Program Files\PuTTY\plink.exe" root@$HOST_IP -pw $ROOTPASSWORD /home/$USER/.VFIOinput/input_detach.sh</pre>
<p>用宿主机<a href="../en/Network_configuration.html#IP_addresses" title="Network configuration">IP 地址</a>替换<code>$HOST_IP</code>，用root密码替换<code>$ROOTPASSWORD</code>。
</p>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>警告：</strong> 如果有人可以访问您的虚拟机，则此方法并不安全，因为他们可以打开文件并读取您的ROOT密码。建议使用<a href="../en/SSH_keys.html" title="SSH keys">SSH keys</a>！</div>
<p>您可能还希望使用快捷键来执行脚本文件。在Windows上，您可以使用<a rel="nofollow" class="external text" href="https://autohotkey.com/">Autohotkey</a>，在宿主机上可以使用<a href="../en/Xbindkeys.html" title="Xbindkeys">Xbindkeys</a>，您的桌面环境也可能提供快捷键设置。 由于需要以root身份运行脚本，您可能还需要使用<a href="../en/Polkit.html" title="Polkit">Polkit</a>，从而无需输入密码。
</p>
<div class="archwiki-template-box archwiki-template-box-tip">
<strong>提示：</strong> 
<ul>
<li>（译注）如果您配置了Polkit无密码授权，那么这个脚本也可以使用您自己的用户来执行。参见<a href="../zh-CN/Libvirt.html#%E8%AE%BE%E7%BD%AE%E6%8E%88%E6%9D%83" title="Libvirt (简体中文)">Libvirt (简体中文)#设置授权</a>和<a href="../zh-CN/Polkit.html#%E8%B7%B3%E8%BF%87%E5%8F%A3%E4%BB%A4%E6%8F%90%E7%A4%BA" title="Polkit (简体中文)">Polkit (简体中文)#跳过口令提示</a>.</li>
<li>（译注）您也可以使用Windows 10 自带的 OpenSSH，使用方法和Linux下相同，参见<a href="../en/Secure_Shell.html#OpenSSH" title="Secure Shell">Secure Shell#OpenSSH</a><sup>[<a href="../en/ArchWiki:Requests.html#Broken_section_links" class="mw-redirect" title="ArchWiki:Requests">断开的链接</a>：无效的部分]</sup>。</li>
</ul>
</div>
<h3>
<span id=".E5.88.86.E7.A6.BBIOMMU.E7.BB.84.28ACS.E8.A1.A5.E4.B8.81.29"></span><span class="mw-headline" id="分离IOMMU组(ACS补丁)">分离IOMMU组(ACS补丁)</span>
</h3>
<p>如果您发现您的PCI设备与其他不希望直通的设备分在一组，您可以使用Alex Williamson的ACS补丁将它们分离。使用前请确保了解其中的<a rel="nofollow" class="external text" href="https://vfio.blogspot.com/2014/08/iommu-groups-inside-and-out.html">潜在风险</a>。
</p>
<p>您需要一个应用了这个补丁的内核，最简单的办法就是安装<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/linux-vfio/">linux-vfio</a></span><sup><small>AUR</small></sup>包。
</p>
<p>此外，需要使用内核命令行选项启用ACS补丁。补丁文件添加以下文档：
</p>
<pre>pcie_acs_override =
        [PCIE] Override missing PCIe ACS support for:
    downstream
        All downstream ports - full ACS capabilties
    multifunction
        All multifunction devices - multifunction ACS subset
    id:nnnn:nnnn
        Specfic device - full ACS capabilities
        Specified as vid:did (vendor/device ID) in hex
</pre>
<p>使用选项<code>pcie_acs_override=downstream</code>通常就足够了。
</p>
<p>安装和配置后，设置<a href="../en/Kernel_parameters.html" title="Kernel parameters">内核参数</a>以在启用<code>pcie_acs_override=</code>选项的情况下加载新内核。
</p>
<h2>
<span id=".E4.BB.85.E4.BD.BF.E7.94.A8QEMU.E4.B8.8D.E4.BD.BF.E7.94.A8libvirt"></span><span class="mw-headline" id="仅使用QEMU不使用libvirt">仅使用QEMU不使用libvirt</span>
</h2>
<p>如果不想在libvirt的帮助下设置虚拟机，可以使用具有自定义参数的普通QEMU命令来运行要使用PCI直通的虚拟机，这对于脚本等一些用例来说是十分理想的，可以灵活地搭配其他脚本。
</p>
<p>先完成<a href="#%E8%AE%BE%E7%BD%AEIOMMU">#设置IOMMU</a>和<a href="#%E9%9A%94%E7%A6%BBGPU">#隔离GPU</a>，接着配置好<a href="../en/QEMU.html" title="QEMU">QEMU</a>虚拟化环境,<a href="../en/QEMU.html#Enabling_KVM" title="QEMU">启用KVM</a>并使用<code>-device vfio-pci,host=07:00.0</code>选项，将<code>07:00.0</code>替换为您先前隔离的设备ID。
</p>
<p>要使用OVMF固件，确保已安装<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=ovmf">ovmf</a></span><sup>[<a href="../en/Help:Procedures.html#Fix_broken_package_links" title="Help:Procedures">断开的链接</a>：replaced by <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=edk2-ovmf">edk2-ovmf</a></span>]</sup>，将UEFI固件从<code>/usr/share/ovmf/x64/OVMF_VARS.fd</code>复制到临时位置，如<code>/tmp/MY_VARS.fd</code>。最后指定OVMF路径。使用如下的参数（注意顺序）：
</p>
<ul>
<li>
<code>-drive if=pflash,format=raw,readonly,file=/usr/share/ovmf/x64/OVMF_CODE.fd</code> 指向实际的位置，注意这是只读的</li>
<li>
<code>-drive if=pflash,format=raw,file=/tmp/MY_VARS.fd</code> 指向临时位置</li>
</ul>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 可以使用QEMU的默认SeaBIOS而不是OVMF，但不推荐使用它，因为它可能会导致直通设置出现问题。</div>
<p>建议通过使用<a href="../en/QEMU.html#Installing_virtio_drivers" title="QEMU">virtio驱动程序</a>并进一步配置，以增强性能,参阅<a href="../en/QEMU.html" title="QEMU">QEMU</a>。
</p>
<p>您还可能必须使用<code>-cpu host,kvm=off</code>参数将主机的CPU型号信息转发给虚拟机，并欺骗Nvidia和其他制造商的设备驱动程序使用的虚拟化检测，防止驱动程序拒绝在虚拟机中运行。
</p>
<h2>
<span id=".E7.9B.B4.E9.80.9A.E5.85.B6.E5.AE.83.E8.AE.BE.E5.A4.87"></span><span class="mw-headline" id="直通其它设备">直通其它设备</span>
</h2>
<h3>
<span id="USB.E6.8E.A7.E5.88.B6.E5.99.A8"></span><span class="mw-headline" id="USB控制器">USB控制器</span>
</h3>
<p>如果你的主板具有多个USB控制器并映射到不同的组，则可以直通这些控制器而不是单个USB设备。直通整个控制器有如下的优势：
</p>
<ul>
<li>如果设备在某些操作（例如正在进行更新的手机）的过程中断开或更改ID，虚拟机不会突然丢失设备。</li>
<li>由该控制器管理的任何USB端口都由虚拟机直接处理，并且可以将其设备拔出，重新插入和更改，而无需通知管理程序。</li>
<li>如果启动VM时通常直通给虚拟机的其中一个USB设备丢失，Libvirt将不会抱怨。</li>
</ul>
<p>与GPU不同，大多数USB控制器的驱动程序不需要任何特定配置即可在VM上运行，并且通常可以在主机和客户机系统之间来回传递控制而不会产生任何副作用。
</p>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>警告：</strong> 确保您的USB控制器支持Reset。<a href="#%E7%9B%B4%E9%80%9A%E4%B8%8D%E6%94%AF%E6%8C%81Reset%E7%9A%84%E8%AE%BE%E5%A4%87">#直通不支持Reset的设备</a>
</div>
<p>您可以使用以下命令找出哪个PCI设备对应于哪个控制器以及每个端口和设备对应哪个控制器：
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ for usb_ctrl in $(find /sys/bus/usb/devices/usb* -maxdepth 0 -type l); do pci_path="$(dirname "$(realpath "${usb_ctrl}")")"; echo "Bus $(cat "${usb_ctrl}/busnum") --&gt; $(basename $pci_path) (IOMMU group $(basename $(realpath $pci_path/iommu_group)))"; lsusb -s "$(cat "${usb_ctrl}/busnum"):"; echo; done</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">Bus 1 --&gt; 0000:00:1a.0 (IOMMU group 4)
Bus 001 Device 004: ID 04f2:b217 Chicony Electronics Co., Ltd Lenovo Integrated Camera (0.3MP)
Bus 001 Device 007: ID 0a5c:21e6 Broadcom Corp. BCM20702 Bluetooth 4.0 [ThinkPad]
Bus 001 Device 008: ID 0781:5530 SanDisk Corp. Cruzer
Bus 001 Device 002: ID 8087:0024 Intel Corp. Integrated Rate Matching Hub
Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub

Bus 2 --&gt; 0000:00:1d.0 (IOMMU group 9)
Bus 002 Device 006: ID 0451:e012 Texas Instruments, Inc. TI-Nspire Calculator
Bus 002 Device 002: ID 8087:0024 Intel Corp. Integrated Rate Matching Hub
Bus 002 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub
</pre>
<p>款笔记本电脑有3个USB端口，由2个USB控制器管理，每个控制器都有自己的IOMMU组。 在此示例中，总线001管理单个USB端口（其中插入了SanDisk USB记忆棒，因此它显示在列表中），还有许多内部设备，例如内部网络摄像头和蓝牙卡。 另一方面，除了插入的计算器之外，总线002不会管理其他东西。第三个端口是空的，这就是它没有出现在列表中的原因，但实际上是由总线002管理的。
</p>
<p>确定需要直通的控制器之后，只需将其添加到虚拟机控制的PCI主机设备列表中即可。不需要其他配置。
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 如果您的USB控制器不支持Reset，不在单独的组中，或者无法直通，您仍然可以通过<a href="../en/Udev.html" title="Udev">udev</a>规则达到类似的目的。参见<a rel="nofollow" class="external autonumber" href="https://github.com/olavmrk/usb-libvirt-hotplug">[1]</a>，它允许连接到指定USB端口的任何设备自动连接到虚拟机。</div>
<h3>
<span id=".E4.BD.BF.E7.94.A8PulseAudio.E5.B0.86.E8.99.9A.E6.8B.9F.E6.9C.BA.E9.9F.B3.E9.A2.91.E4.BC.A0.E9.80.92.E7.BB.99.E5.AE.BF.E4.B8.BB.E6.9C.BA"></span><span class="mw-headline" id="使用PulseAudio将虚拟机音频传递给宿主机">使用PulseAudio将虚拟机音频传递给宿主机</span>
</h3>
<p>可以使用libvirt将虚拟机的音频作为应用程序传输到宿主机。 这具有以下优点：多个音频流可传输到一个主机输出，并且与无需考虑音频设备是否支持直通。<a href="../en/PulseAudio.html" title="PulseAudio">PulseAudio</a> 是必需的。
</p>
<p>PulseAudio守护进程通常在你的普通用户下运行，并且只接受来自相同用户的连接。然而libvirt默认使用root运行QEMU。为了让QEMU在普通用户下运行，编辑<code>/etc/libvirt/qemu.conf</code>并将<code>user</code>设置为你的用户名。
</p>
<pre>user = "dave"
</pre>
<p>你同样需要告诉QEMU使用PulseAudio后端并识别要连接的服务器，首先将QEMU命名空间添加到你的域。
编辑域的<code>.xml</code>文件（使用<code>virsh edit domain</code>），将<code>domain type</code>行改为：
</p>
<pre>&lt;domain type='kvm' xmlns:qemu='<a rel="nofollow" class="external free" href="http://libvirt.org/schemas/domain/qemu/1.0'">http://libvirt.org/schemas/domain/qemu/1.0'</a><sup title="最后检查状态：404">[<a href="https://en.wikipedia.org/wiki/Wikipedia:Link_rot" class="extiw" title="wikipedia:Wikipedia:Link rot">失效链接</a> 2020-08-04 ⓘ]</sup>&gt;
</pre>
<p>并且加入如下的配置（在最后一个<code>&lt;/devices&gt;</code>之后，<code>&lt;/domain&gt;</code>之前）：
</p>
<pre> &lt;qemu:commandline&gt;
   &lt;qemu:env name='QEMU_AUDIO_DRV' value='pa'/&gt;
   &lt;qemu:env name='QEMU_PA_SERVER' value='/run/user/1000/pulse/native'/&gt;
 &lt;/qemu:commandline&gt;
</pre>
<p><code>1000</code>是你的用户ID，如果必要的话改为你的用户ID，用户ID可以通过<code>id</code>命令查看。
</p>
<p>请记住在继续之前保存文件并退出编辑器，否则更改将不会保存。如果您看到：“已更改域 [名称] XML配置”或是类似的消息，这表示您的更改已保存。
</p>
<p><a href="../en/Systemd.html#Using_units" class="mw-redirect" title="Restart">重启</a> <code>libvirtd.service</code> 和 <a href="../en/Systemd/User.html" title="Systemd/User">用户服务</a> <code>pulseaudio.service</code>。
</p>
<p>现在，虚拟机音频将作为应用程序传递给宿主机。<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=pavucontrol">pavucontrol</a></span>可用于控制输出设备。请注意，在Windows客户机上，<a href="#HDMI%E9%9F%B3%E9%A2%91%E4%B8%8D%E5%90%8C%E6%AD%A5%E6%88%96%E6%98%AF%E6%9C%89%E5%99%BC%E5%95%AA%E5%A3%B0">不使用消息信号中断可能会导致出现噼啪声</a>。
</p>
<h3>
<span id=".E7.89.A9.E7.90.86.E7.A3.81.E7.9B.98.2F.E5.88.86.E5.8C.BA"></span><span class="mw-headline" id="物理磁盘/分区">物理磁盘/分区</span>
</h3>
<p>可以通过向XML添加条目来使用整个磁盘或分区来提高I/O性能。
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;"> 
&lt;devices&gt;
...
  &lt;disk type='block' device='disk'&gt;
    &lt;driver name='qemu' type='raw' cache='none' io='native'/&gt;
    &lt;source dev='/dev/sdXX'/&gt;
    &lt;target dev='vda' bus='virtio'/&gt;
    &lt;address type='pci' domain='0x0000' bus='0x02' slot='0x0a' function='0x0'/&gt;
  &lt;/disk&gt;
...
&lt;/devices&gt;

</pre>
<p>在Windows客户机上需要安装驱动程序才能工作，请参阅<a href="#%E5%AE%89%E8%A3%85%E5%AE%A2%E6%88%B7%E6%9C%BA%E7%B3%BB%E7%BB%9F">#安装客户机系统</a>。
</p>
<h3>
<span id=".E6.B3.A8.E6.84.8F_3"></span><span class="mw-headline" id="注意_3">注意</span>
</h3>
<h4>
<span id=".E7.9B.B4.E9.80.9A.E4.B8.8D.E6.94.AF.E6.8C.81Reset.E7.9A.84.E8.AE.BE.E5.A4.87"></span><span class="mw-headline" id="直通不支持Reset的设备">直通不支持Reset的设备</span>
</h4>
<p>当虚拟机关闭时，虚拟机使用的所有设备都会被其操作系统取消初始化，以准备关闭。在这种状态下，这些设备不再能使用，必须先重新上电才能恢复正常运行。Linux可以自己处理这种电源循环，但是当设备没有已知的Reset方法时，它将于禁用状态并不再可用。Libvirt和Qemu都希望所有宿主机的PCI设备在完全停止虚拟机之前准备好重新连接到宿主机，当遇到不会重置的设备时，虚拟机将挂起“关闭”状态，并将无法重新启动，除非宿主机系统重新启动。 因此，推荐仅直通支持重置的PCI设备，这可以通过PCI设备sysfs节点中存在<code>reset</code>文件来确定，例如<code>/sys/bus/pci/devices/0000:00:1a.0/reset</code>。
</p>
<p>以下bash命令显示设备是否可以被Reset。
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">for iommu_group in $(find /sys/kernel/iommu_groups/ -maxdepth 1 -mindepth 1 -type d);do echo "IOMMU group $(basename "$iommu_group")"; for device in $(\ls -1 "$iommu_group"/devices/); do if [[ -e "$iommu_group"/devices/"$device"/reset ]]; then echo -n "[RESET]"; fi; echo -n $'\t';lspci -nns "$device"; done; done</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">IOMMU group 0
	00:00.0 Host bridge [0600]: Intel Corporation Xeon E3-1200 v2/Ivy Bridge DRAM Controller [8086:0158] (rev 09)
IOMMU group 1
	00:01.0 PCI bridge [0604]: Intel Corporation Xeon E3-1200 v2/3rd Gen Core processor PCI Express Root Port [8086:0151] (rev 09)
	01:00.0 VGA compatible controller [0300]: NVIDIA Corporation GK208 [GeForce GT 720] [10de:1288] (rev a1)
	01:00.1 Audio device [0403]: NVIDIA Corporation GK208 HDMI/DP Audio Controller [10de:0e0f] (rev a1)
IOMMU group 2
	00:14.0 USB controller [0c03]: Intel Corporation 7 Series/C210 Series Chipset Family USB xHCI Host Controller [8086:1e31] (rev 04)
IOMMU group 4
[RESET]	00:1a.0 USB controller [0c03]: Intel Corporation 7 Series/C210 Series Chipset Family USB Enhanced Host Controller #2 [8086:1e2d] (rev 04)
IOMMU group 5
[RESET]	00:1b.0 Audio device [0403]: Intel Corporation 7 Series/C210 Series Chipset Family High Definition Audio Controller [8086:1e20] (rev 04)
IOMMU group 10
[RESET]	00:1d.0 USB controller [0c03]: Intel Corporation 7 Series/C210 Series Chipset Family USB Enhanced Host Controller #1 [8086:1e26] (rev 04)
IOMMU group 13
	06:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM204 [GeForce GTX 970] [10de:13c2] (rev a1)
	06:00.1 Audio device [0403]: NVIDIA Corporation GM204 High Definition Audio Controller [10de:0fbb] (rev a1)
</pre>
<p>这表示<code>00：14.0</code>中的xHCI USB控制器无法Reset，将导致虚拟机无法正常关闭，而在<code>00：1b.0</code>中的集成声卡和在<code>00：1a.0</code>和<code>00:1d.0</code>中的其他两个控制器没有这个问题，可以毫无问题地直通。
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 如果你的AMD显卡无法正常Reset，参阅<a href="#AMD%E6%98%BE%E5%8D%A1%E7%9B%B4%E9%80%9A%E5%90%8E%E6%97%A0%E6%B3%95%E9%87%8D%E5%90%AF%E8%99%9A%E6%8B%9F%E6%9C%BA">#AMD显卡直通后无法重启虚拟机</a>。</div>
<h2>
<span id=".E5.AE.8C.E6.95.B4.E7.9A.84.E4.BE.8B.E5.AD.90"></span><span class="mw-headline" id="完整的例子">完整的例子</span>
</h2>
<p>如果您在配置的时候遇到了麻烦，您可以参考<a href="../en/PCI_passthrough_via_OVMF/Examples.html" title="PCI passthrough via OVMF/Examples">完整的配置示例</a>。一些用户在那里描述了它们的配置步骤，或许您可以从中发现一些技巧。
</p>
<h2>
<span id=".E7.96.91.E9.9A.BE.E8.A7.A3.E7.AD.94"></span><span class="mw-headline" id="疑难解答">疑难解答</span>
</h2>
<p>如果您遇到的问题并没有在下面列出，您也可以参考<a href="../en/QEMU.html#Troubleshooting" title="QEMU">QEMU#Troubleshooting</a>。
</p>
<h3>
<span id="Nvidia_GPU.E7.9B.B4.E9.80.9A.E5.88.B0Windows_.E8.99.9A.E6.8B.9F.E6.9C.BA.E6.97.B6.E5.8F.91.E7.94.9F.22.E9.94.99.E8.AF.AF43:.E9.A9.B1.E5.8A.A8.E7.A8.8B.E5.BA.8F.E5.8A.A0.E8.BD.BD.E5.A4.B1.E8.B4.A5.E2.80.9D"></span><span class="mw-headline" id='Nvidia_GPU直通到Windows_虚拟机时发生"错误43:驱动程序加载失败”'>Nvidia GPU直通到Windows 虚拟机时发生"错误43:驱动程序加载失败”</span>
</h3>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 
<ul>
<li>这也可能修复与Nvidia驱动程序相关的SYSTEM_THREAD_EXCEPTION_NOT_HANDLED引导失败。</li>
<li>这可能也会修复Linux虚拟机的问题。</li>
</ul>
</div>
<p>从337.88开始，Windows上的Nvidia驱动程序将会检查虚拟机管理程序是否正在运行，如果检测到虚拟机管理程序，则会拒绝加载，这会导致Windows设备管理器出现错误43。从QEMU 2.5.0和libvirt 1.3.3开始，可以设置虚假的vendor_id，这足以欺骗Nvidia驱动程序。所需的步骤是将<code>hv_vendor_id=随便什么的</code>添加到QEMU命令行中的cpu参数，或者将以下行添加到libvirt的域配置中。 ID必须设置为12个字符的字母数字（例如'1234567890ab'）。
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
&lt;features&gt;
	&lt;hyperv&gt;
		...
		&lt;vendor_id state='on' value='whatever'/&gt;
		...
	&lt;/hyperv&gt;
	...
	&lt;kvm&gt;
	&lt;hidden state='on'/&gt;
	&lt;/kvm&gt;
&lt;/features&gt;
...
</pre>
<p>使用旧版QEMU和/或libvirt的用户将必须禁用一些虚拟机管理程序扩展，这会大大降低性能。如果必须这样做的话，请在libvirt域配置文件中执行以下替换。
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ virsh edit [vmname]</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
&lt;features&gt;
	&lt;hyperv&gt;
		&lt;relaxed state='on'/&gt;
		&lt;vapic state='on'/&gt;
		&lt;spinlocks state='on' retries='8191'/&gt;
	&lt;/hyperv&gt;
	...
&lt;/features&gt;
...
&lt;clock offset='localtime'&gt;
	&lt;timer name='hypervclock' present='yes'/&gt;
&lt;/clock&gt;
...
</pre>
<pre>...
&lt;clock offset='localtime'&gt;
	&lt;timer name='hypervclock' present='no'/&gt;
&lt;/clock&gt;
...
&lt;features&gt;
	&lt;kvm&gt;
	&lt;hidden state='on'/&gt;
	&lt;/kvm&gt;
	...
	&lt;hyperv&gt;
		&lt;relaxed state='off'/&gt;
		&lt;vapic state='off'/&gt;
		&lt;spinlocks state='off'/&gt;
	&lt;/hyperv&gt;
	...
&lt;/features&gt;
...
</pre>
<h3>
<span id=".E5.9C.A8.E5.90.AF.E5.8A.A8.E8.99.9A.E6.8B.9F.E6.9C.BA.E5.90.8E.E5.9C.A8dmesg.E4.B8.AD.E7.9C.8B.E5.88.B0.22BAR_3:_cannot_reserve_.5Bmem.5D.22.E9.94.99.E8.AF.AF"></span><span class="mw-headline" id='在启动虚拟机后在dmesg中看到"BAR_3:_cannot_reserve_[mem]"错误'>在启动虚拟机后在dmesg中看到"BAR 3: cannot reserve [mem]"错误</span>
</h3>
<div class="noprint archwiki-template-message">
<p><a href="../File:Tango-view-fullscreen.png" class="image"><img alt="Tango-view-fullscreen.png" src="../File:Tango-view-fullscreen.png" decoding="async" width="48" height="48"></a><b>This article or section needs expansion.</b><a href="../File:Tango-view-fullscreen.png" class="image"><img alt="Tango-view-fullscreen.png" src="../File:Tango-view-fullscreen.png" decoding="async" width="48" height="48"></a></p>
<div>
<b>Reason:</b> This error is actually related to the boot_vgs issue and should be merged together with everything else concerning GPU ROMs. (Discuss in <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/index.php/Talk:PCI_passthrough_via_OVMF_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)#UEFI_(OVMF)_Compatibility_in_VBIOS">Talk:PCI passthrough via OVMF (简体中文)#UEFI (OVMF) Compatibility in VBIOS</a>)</div>
</div>
<p>查看<a rel="nofollow" class="external text" href="https://www.linuxquestions.org/questions/linux-kernel-70/kernel-fails-to-assign-memory-to-pcie-device-4175487043/">这篇文章</a>:
</p>
<p>如果你仍然遇到错误43，请在启动虚拟机后检查dmesg是否存在内存保留错误，如果您有类似消息，则可能是这种情况：
</p>
<pre>vfio-pci 0000:09:00.0: BAR 3: cannot reserve [mem 0xf0000000-0xf1ffffff 64bit pref]
</pre>
<p>找出您的GPU所连接的PCI Bridge。这条命令将给出设备的实际层次结构：
</p>
<pre>$ lspci -t
</pre>
<p>在启动VM之前运行以下命令，将ID替换为来自先前输出的实际ID。
</p>
<pre># echo 1 &gt; /sys/bus/pci/devices/0000\:00\:03.1/remove
# echo 1 &gt; /sys/bus/pci/rescan
</pre>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>注意：</strong> 可能需要同时设置<a href="../en/Kernel_parameters.html" class="mw-redirect" title="Kernel parameter">内核参数</a> <code>video=efifb:off</code>。 <a rel="nofollow" class="external autonumber" href="https://pve.proxmox.com/wiki/Pci_passthrough#BAR_3:_can.27t_reserve_.5Bmem.5D_error">[2]</a>
</div>
<h3>
<span id="VBIOS.E7.9A.84UEFI_.28OVMF.29_.E5.85.BC.E5.AE.B9"></span><span class="mw-headline" id="VBIOS的UEFI_(OVMF)_兼容">VBIOS的UEFI (OVMF) 兼容</span>
</h3>
<div class="noprint archwiki-template-message">
<p><a href="../File:Tango-edit-cut.png" class="image"><img alt="Tango-edit-cut.png" src="../File:Tango-edit-cut.png" decoding="async" width="48" height="48"></a><b>This section is being considered for removal.</b><a href="../File:Tango-edit-cut.png" class="image"><img alt="Tango-edit-cut.png" src="../File:Tango-edit-cut.png" decoding="async" width="48" height="48"></a></p>
<div>
<b>Reason:</b> Flashing you guest GPU for the purpose of a GPU passthrough is <b>never</b> good advice. A full section should be dedicated to VBIOS compatibility. (Discuss in <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/index.php/Talk:PCI_passthrough_via_OVMF_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)#UEFI_(OVMF)_Compatibility_in_VBIOS">Talk:PCI passthrough via OVMF (简体中文)#UEFI (OVMF) Compatibility in VBIOS</a>)</div>
</div>
<p>With respect to <a rel="nofollow" class="external text" href="https://pve.proxmox.com/wiki/Pci_passthrough#How_to_known_if_card_is_UEFI_.28ovmf.29_compatible">this article</a>:
</p>
<p>Error 43 can be caused by the GPU's VBIOS without UEFI support. To check whenever your VBIOS supports it, you will have to use <code>rom-parser</code>:
</p>
<pre>$ git clone <a rel="nofollow" class="external free" href="https://github.com/awilliam/rom-parser">https://github.com/awilliam/rom-parser</a>
$ cd rom-parser &amp;&amp; make
</pre>
<p>Dump the GPU VBIOS:
</p>
<pre># echo 1 &gt; /sys/bus/pci/devices/0000:01:00.0/rom
# cat /sys/bus/pci/devices/0000:01:00.0/rom &gt; /tmp/image.rom
# echo 0 &gt; /sys/bus/pci/devices/0000:01:00.0/rom
</pre>
<p>And test it for compatibility:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ ./rom-parser /tmp/image.rom</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">Valid ROM signature found @600h, PCIR offset 190h
	PCIR: type 0 (x86 PC-AT), vendor: 10de, device: 1184, class: 030000
	PCIR: revision 0, vendor revision: 1
Valid ROM signature found @fa00h, PCIR offset 1ch
	PCIR: type 3 (EFI), vendor: 10de, device: 1184, class: 030000
	PCIR: revision 3, vendor revision: 0
		EFI: Signature Valid, Subsystem: Boot, Machine: X64
	Last image
</pre>
<p>To be UEFI compatible, you need a "type 3 (EFI)" in the result. If it's not there, try updating your GPU VBIOS. GPU manufacturers often share VBIOS upgrades on their support pages. A large database of known compatible and working VBIOSes (along with their UEFI compatibility status!) is available on <a rel="nofollow" class="external text" href="https://www.techpowerup.com/vgabios/">TechPowerUp</a>.
</p>
<p>Updated VBIOS can be used in the VM without flashing. To load it in QEMU:
</p>
<pre>-device vfio-pci,host=07:00.0,......,romfile=/path/to/your/gpu/bios.bin \
</pre>
<p>And in libvirt:
</p>
<pre>&lt;hostdev&gt;
     ...
     &lt;rom file='/path/to/your/gpu/bios.bin'/&gt;
     ...
   &lt;/hostdev&gt;</pre>
<p>One should compare VBIOS versions between host and guest systems using <a rel="nofollow" class="external text" href="https://www.techpowerup.com/download/nvidia-nvflash/">nvflash</a> (Linux versions under <i>Show more versions</i>) or 
<a rel="nofollow" class="external text" href="https://www.techpowerup.com/download/techpowerup-gpu-z/">GPU-Z</a> (in Windows guest). To check the currently loaded VBIOS:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ ./nvflash --version</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
Version               : 80.04.XX.00.97
...
UEFI Support          : No
UEFI Version          : N/A
UEFI Variant Id       : N/A ( Unknown )
UEFI Signer(s)        : Unsigned
...
</pre>
<p>And to check a given VBIOS file:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ ./nvflash --version NV299MH.rom</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
Version               : 80.04.XX.00.95
...
UEFI Support          : Yes
UEFI Version          : 0x10022 (Jul  2 2013 @ 16377903 )
UEFI Variant Id       : 0x0000000000000004 ( GK1xx )
UEFI Signer(s)        : Microsoft Corporation UEFI CA 2011
...
</pre>
<p>If the external ROM did not work as it should in the guest, you will have to flash the newer VBIOS image to the GPU. In some cases it is possible to create your own VBIOS image with UEFI support using <a rel="nofollow" class="external text" href="https://www.win-raid.com/t892f16-AMD-and-Nvidia-GOP-update-No-requests-DIY.html">GOPUpd</a> tool, however this is risky and may result in GPU brick.
</p>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>Warning:</strong> Failure during flashing may "brick" your GPU - recovery may be possible, but rarely easy and often requires additional hardware. <b>DO NOT</b> flash VBIOS images for other GPU models (different boards may use different VBIOSes, clocks, fan configuration). If it breaks, you get to keep all the pieces.</div>
<p>In order to avoid the irreparable damage to your graphics adapter it is necessary to unload the NVIDIA kernel driver first:
</p>
<pre># modprobe -r nvidia_modeset nvidia 
</pre>
<p>Flashing the VBIOS can be done with:
</p>
<pre># ./nvflash romfile.bin
</pre>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>Warning:</strong> <b>DO NOT</b> interrupt the flashing process, even if it looks like it's stuck. Flashing should take about a minute on most GPUs, but may take longer.</div>
<h3>
<span id="HDMI.E9.9F.B3.E9.A2.91.E4.B8.8D.E5.90.8C.E6.AD.A5.E6.88.96.E6.98.AF.E6.9C.89.E5.99.BC.E5.95.AA.E5.A3.B0"></span><span class="mw-headline" id="HDMI音频不同步或是有噼啪声">HDMI音频不同步或是有噼啪声</span>
</h3>
<p>对于一些用户来说，虚拟机的音频会在显卡上通过HDMI输出一段时间后减慢/卡顿。这通常也会降低图形处理速度。可能的解决方案包括启用MSI（基于消息信号的中断）而不是默认（基于线路的中断）。
</p>
<p>要检查是否支持MSI以及是否被启用，请以root身份运行以下命令：
</p>
<pre># lspci -vs $device | grep 'MSI:'
</pre>
<p>`$device`是设备位置 (例如 `01:00.0`)。
</p>
<p>输出应该类似于：
</p>
<pre>Capabilities: [60] MSI: Enable<b>-</b> Count=1/1 Maskable- 64bit+
</pre>
<p><code>Enable</code>后的<code>-</code>代表支持MSI，但虚拟机并没有启用。<code>+</code>代表虚拟机正在使用MSI。
</p>
<p>启用它的过程有些复杂，可以在<a rel="nofollow" class="external text" href="https://forums.guru3d.com/showthread.php?t=378044">此处</a>找到说明。
</p>
<p>其他的提示可以从<a rel="nofollow" class="external text" href="https://lime-technology.com/wiki/index.php/UnRAID_6/VM_Guest_Support#Enable_MSI_for_Interrupts_to_Fix_HDMI_Audio_Support">lime-technology's wiki</a>上找到， 或参考这篇帖子<a rel="nofollow" class="external text" href="https://vfio.blogspot.it/2014/09/vfio-interrupts-and-how-to-coax-windows.html">VFIO tips and tricks</a>。
</p>
<p>网上有一些一些工具，例如 <code>MSI_util</code>，不过它们在 Windows 10 64bit下无效。
</p>
<p>要解决这个问题，仅仅在function 0(<code>01:00.0 VGA compatible controller: NVIDIA Corporation GM206 [GeForce GTX 960] (rev a1) (prog-if 00 [VGA controller])</code>)上启用MSI是不够的，另一个function(<code>01:00.1 Audio device: NVIDIA Corporation Device 0fba (rev a1)</code>)同样需要启用。
</p>
<h3>
<span id="intel_iommu.E5.90.AF.E7.94.A8.E4.B9.8B.E5.90.8E.E4.B8.BB.E6.9C.BA.E6.B2.A1.E6.9C.89HDMI.E9.9F.B3.E9.A2.91.E8.BE.93.E5.87.BA"></span><span class="mw-headline" id="intel_iommu启用之后主机没有HDMI音频输出">intel_iommu启用之后主机没有HDMI音频输出</span>
</h3>
<p>如果启用 <code>intel_iommu</code>后，Intel GPU的HDMI输出设备在宿主机上无法使用，那么设置选项<code>igfx_off</code>（即<code>intel_iommu=on,igfx_off</code>）可能会恢复音频，有关设置<code>igfx_off</code>的详细信息，请阅读<a rel="nofollow" class="external text" href="https://www.kernel.org/doc/Documentation/Intel-IOMMU.txt">Intel-IOMMU.txt</a>中的<i>Graphics Problems?</i>。
</p>
<h3>
<span id=".E5.90.AF.E7.94.A8vfio_pci.E5.90.8EX.E6.97.A0.E6.B3.95.E5.90.AF.E5.8A.A8"></span><span class="mw-headline" id="启用vfio_pci后X无法启动">启用vfio_pci后X无法启动</span>
</h3>
<p>这与主机GPU被检测为额外GPU有关，当它尝试加载虚拟机所用的GPU的驱动程序时，会导致X崩溃。为了避免这种情况，需要一个指定主机GPU的BusID的Xorg配置文件。 可以从lspci或Xorg日志获取正确的BusID。<a rel="nofollow" class="external text" href="https://www.redhat.com/archives/vfio-users/2016-August/msg00025.html">来源 →</a>
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/X11/xorg.conf.d/10-intel.conf</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">Section "Device"
        Identifier "Intel GPU"
        Driver "modesetting"
        BusID  "PCI:0:2:0"
EndSection
</pre>
<h3>
<span id="Chromium.E5.BF.BD.E7.95.A5.E9.9B.86.E6.88.90.E5.9B.BE.E5.BD.A2.E5.8A.A0.E9.80.9F"></span><span class="mw-headline" id="Chromium忽略集成图形加速">Chromium忽略集成图形加速</span>
</h3>
<p>Chromium和它的朋友们将尝试在系统中检测尽可能多的GPU，并选择哪一个作为首选（通常是独立的的NVIDIA/AMD显卡）。它试图通过查看PCI设备来选择GPU，而不是系统中可用的OpenGL渲染器 - 结果是Chromium可能会忽略可用于渲染的集成GPU并尝试使用绑定到无法在宿主机上使用的虚拟机专用GPU。这导致使用软件渲染（导致更高的CPU负载，也可能导致视频播放不稳定，滚动不平滑）。
</p>
<p>这可以通过<a href="../en/Chromium.html#Forcing_specific_GPU" class="mw-redirect" title="Chromium/Tips and tricks">告诉Chromium使用哪个GPU</a>来解决。
</p>
<h3>
<span id=".E8.99.9A.E6.8B.9F.E6.9C.BA.E5.8F.AA.E4.BD.BF.E7.94.A8.E4.B8.80.E4.B8.AA.E6.A0.B8.E5.BF.83"></span><span class="mw-headline" id="虚拟机只使用一个核心">虚拟机只使用一个核心</span>
</h3>
<p>对于某些用户，即使启用了IOMMU并且核心计数设置为大于1，VM仍然只使用一个CPU核心和线程。 要解决此问题，请在<code>virt-manager</code>中启用“手动设置CPU拓扑”，并将其设置为所需的CPU，内核和线程数量。 请记住，“线程”是指每个CPU的线程数，而不是总数。
</p>
<h3>
<span id=".E7.9B.B4.E9.80.9A.E8.B2.8C.E4.BC.BC.E5.B7.A5.E4.BD.9C.E4.BD.86.E6.B2.A1.E6.9C.89.E8.BE.93.E5.87.BA"></span><span class="mw-headline" id="直通貌似工作但没有输出">直通貌似工作但没有输出</span>
</h3>
<p>确保您为您的虚拟机选择了UEFI固件。此外，请确保已将正确的设备直通给虚拟机。
</p>
<h3>
<span id="virt-manager_.E9.81.87.E5.88.B0.E6.9D.83.E9.99.90.E9.97.AE.E9.A2.98"></span><span class="mw-headline" id="virt-manager_遇到权限问题">virt-manager 遇到权限问题</span>
</h3>
<p>如果你在virt-manager中遇到权限问题，将以下内容添加到<code>/etc/libvirt/qemu.conf</code>:
</p>
<pre>group="kvm"
user="<i>user</i>"
</pre>
<p>如果仍然不能工作，确保你的用户已经加入了kvm和libvirt<a href="../en/Users_and_groups.html#Group_management" class="mw-redirect" title="User group">组</a>。
</p>
<h3>
<span id=".E8.99.9A.E6.8B.9F.E6.9C.BA.E5.85.B3.E9.97.AD.E4.B9.8B.E5.90.8E.E5.AE.BF.E4.B8.BB.E6.9C.BA.E6.A0.B8.E5.BF.83.E6.97.A0.E5.93.8D.E5.BA.94"></span><span class="mw-headline" id="虚拟机关闭之后宿主机核心无响应">虚拟机关闭之后宿主机核心无响应</span>
</h3>
<p>此问题似乎主要影响运行Windows 10 guest虚拟机的用户，并且通常在虚拟机运行很长一段时间后发生：主机的多个CPU核心被锁定（请参阅<a rel="nofollow" class="external autonumber" href="https://bbs.archlinux.org/viewtopic.php?id=206050&amp;p=2">[3]</a>）。要解决此问题，请尝试在直通的GPU上启用消息信号中断。有关如何执行此操作的指南，请参见<a rel="nofollow" class="external autonumber" href="https://forums.guru3d.com/threads/windows-line-based-vs-message-signaled-based-interrupts.378044/">[4]</a>。
</p>
<h3>
<span id=".E5.AE.A2.E6.88.B7.E6.9C.BA.E5.9C.A8.E5.AE.BF.E4.B8.BB.E6.9C.BA.E4.BC.91.E7.9C.A0.E7.9C.A0.E6.83.85.E5.86.B5.E4.B8.8B.E8.BF.90.E8.A1.8C.E5.AF.BC.E8.87.B4.E6.AD.BB.E6.9C.BA"></span><span class="mw-headline" id="客户机在宿主机休眠眠情况下运行导致死机">客户机在宿主机休眠眠情况下运行导致死机</span>
</h3>
<p>启用VFIO的虚拟机如果在睡眠/唤醒周期中运行时会变得不稳定，并且在尝试关闭它们时会导致主机死机。为了避免这种情况，可以使用以下libvirt hook脚本和systemd单元在虚拟机运行时阻止主机进入休眠状态。hook文件需要可执行权限才能工作。
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/libvirt/hooks/qemu</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">#!/bin/bash

OBJECT="$1"
OPERATION="$2"
SUBOPERATION="$3"
EXTRA_ARG="$4"

case "$OPERATION" in
        "prepare")
                systemctl start libvirt-nosleep@"$OBJECT"
                ;;
        "release")
                systemctl stop libvirt-nosleep@"$OBJECT"
                ;;
esac
</pre>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/systemd/system/libvirt-nosleep@.service</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">[Unit]
Description=Preventing sleep while libvirt domain "%i" is running

[Service]
Type=simple
ExecStart=/usr/bin/systemd-inhibit --what=sleep --why="Libvirt domain \"%i\" is running" --who=%U --mode=block sleep infinity
</pre>
<h3>
<span id="AMD.E6.98.BE.E5.8D.A1.E7.9B.B4.E9.80.9A.E5.90.8E.E6.97.A0.E6.B3.95.E9.87.8D.E5.90.AF.E8.99.9A.E6.8B.9F.E6.9C.BA"></span><span class="mw-headline" id="AMD显卡直通后无法重启虚拟机">AMD显卡直通后无法重启虚拟机</span>
</h3>
<p>某些AMD显卡在Windows虚拟机中可能无法正常Reset，导致虚拟机无法重新启动。
</p>
<p>您可以通过在关闭虚拟机之前手动安全移除显卡（就像移除U盘那样）来避免这个问题。当您安装VirtIO驱动程序映像中的<code>guest-agent</code>之后，您就可以在安全移除菜单中看到相关的设备。
</p>
<p>如果您希望自动完成这项任务，请参阅<a rel="nofollow" class="external autonumber" href="https://forum.level1techs.com/t/linux-host-windows-guest-gpu-passthrough-reinitialization-fix/121097">[5]</a>。
</p>
<h2>
<span id=".E5.8F.A6.E8.AF.B7.E5.8F.82.E9.98.85"></span><span class="mw-headline" id="另请参阅">另请参阅</span>
</h2>
<ul>
<li>
<a rel="nofollow" class="external text" href="https://bbs.archlinux.org/viewtopic.php?id=162768">Discussion on Arch Linux forums</a> | <a rel="nofollow" class="external text" href="https://archive.is/kZYMt">Archived link</a>
</li>
<li><a rel="nofollow" class="external text" href="https://docs.google.com/spreadsheet/ccc?key=0Aryg5nO-kBebdFozaW9tUWdVd2VHM0lvck95TUlpMlE">User contributed hardware compatibility list</a></li>
<li><a rel="nofollow" class="external text" href="https://pastebin.com/rcnUZCv7">Example script from https://www.youtube.com/watch?v=37D2bRsthfI</a></li>
<li><a rel="nofollow" class="external text" href="https://vfio.blogspot.com/">Complete tutorial for PCI passthrough</a></li>
<li><a rel="nofollow" class="external text" href="https://www.redhat.com/archives/vfio-users/">VFIO users mailing list</a></li>
<li><a rel="nofollow" class="external text" href="https://webchat.freenode.net/?channels=vfio-users">#vfio-users on freenode</a></li>
<li><a rel="nofollow" class="external text" href="https://www.youtube.com/watch?v=aLeWg11ZBn0">YouTube: Level1Linux - GPU Passthrough for Virtualization with Ryzen</a></li>
</ul>
</div>
</div>
<div id="catlinks" class="catlinks" data-mw="interface">
<div id="mw-normal-catlinks" class="mw-normal-catlinks">
<a href="../Special:Categories.html" title="Special:Categories">Category</a>: <ul><li><a href="../zh-CN/Category:Virtualization.html" title="Category:Virtualization (简体中文)">Virtualization (简体中文)</a></li></ul>
</div>
<div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul>
<li><a href="../en/Category:Pages_with_broken_package_links.html" title="Category:Pages with broken package links">Pages with broken package links</a></li>
<li><a href="../en/Category:Pages_or_sections_flagged_with_Template:Accuracy.html" title="Category:Pages or sections flagged with Template:Accuracy">Pages or sections flagged with Template:Accuracy</a></li>
<li><a href="../en/Category:Pages_or_sections_flagged_with_Template:Expansion.html" title="Category:Pages or sections flagged with Template:Expansion">Pages or sections flagged with Template:Expansion</a></li>
<li><a href="../en/Category:Pages_with_broken_section_links.html" title="Category:Pages with broken section links">Pages with broken section links</a></li>
<li><a href="../en/Category:Pages_with_dead_links.html" title="Category:Pages with dead links">Pages with dead links</a></li>
<li><a href="../en/Category:Sections_flagged_with_Template:Remove.html" title="Category:Sections flagged with Template:Remove">Sections flagged with Template:Remove</a></li>
</ul>
</div>
</div>
	</div>
</div>

<footer id="footer" class="mw-footer" role="contentinfo" style="margin: 0">
	<ul id="footer-info">
		<li>Retrieved from "<a dir="ltr" href="https://wiki.archlinux.org/index.php?title=PCI_passthrough_via_OVMF_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)&amp;oldid=629816">https://wiki.archlinux.org/index.php?title=PCI_passthrough_via_OVMF_(简体中文)&amp;oldid=629816</a>"</li>
		<li id="footer-info-lastmod"> This page was last edited on 5 August 2020, at 15:51.</li>
		<li id="footer-info-copyright">Content is available under <a class="external" rel="nofollow" href="http://www.gnu.org/copyleft/fdl.html">GNU Free Documentation License 1.3 or later</a> unless otherwise noted.</li>
	<br>
</ul>
	<ul id="footer-places">
		<li id="footer-places-privacy"><a href="../en/ArchWiki:Privacy_policy.html" title="ArchWiki:Privacy policy">Privacy policy</a></li>
		<li id="footer-places-about"><a href="../en/ArchWiki:About.html" title="ArchWiki:About">About ArchWiki</a></li>
		<li id="footer-places-disclaimer"><a href="../en/ArchWiki:General_disclaimer.html" title="ArchWiki:General disclaimer">Disclaimers</a></li>
	</ul>
	<ul id="footer-icons" class="noprint">
		<li id="footer-copyrightico">
	</ul>
	<div style="clear: both;"></div>
</footer>



</body>
</html>
