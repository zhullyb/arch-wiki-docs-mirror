<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<title>Solid state drive (正體中文) - ArchWiki</title>
<link rel="stylesheet" href="../ArchWikiOffline.css">
<meta name="ResourceLoaderDynamicStyles" content="">
<meta name="generator" content="MediaWiki 1.35.0">
<meta name="referrer" content="no-referrer-when-downgrade">
<meta name="robots" content="noindex,follow">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="shortcut icon" href="/favicon.ico">
<link rel="search" type="application/opensearchdescription+xml" href="/opensearch_desc.php" title="ArchWiki (en)">
<link rel="EditURI" type="application/rsd+xml" href="https://wiki.archlinux.org/api.php?action=rsd">
<link rel="license" href="http://www.gnu.org/copyleft/fdl.html">
<link rel="alternate" type="application/atom+xml" title="ArchWiki Atom feed" href="/index.php?title=Special:RecentChanges&amp;feed=atom">
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-Solid_state_drive_正體中文 rootpage-Solid_state_drive_正體中文 skin-vector action-view skin-vector-legacy">
<div id="content" class="mw-body" role="main" style="margin: 0">
	<a id="top"></a>
	<div id="siteNotice" class="mw-body-content"></div>
	<div class="mw-indicators mw-body-content">
	</div>
	<h1 id="firstHeading" class="firstHeading" lang="en">Solid state drive (正體中文)</h1>
	<div id="bodyContent" class="mw-body-content">
		<div id="siteSub" class="noprint">From ArchWiki</div>
		<div id="contentSub"></div>
		<div id="contentSub2"></div>
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#searchInput">Jump to search</a>
		<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr">
<div class="warningbox">The printable version is no longer supported and may have rendering errors. Please update your browser bookmarks and please use the default browser print function instead.</div>
<div class="mw-parser-output">
<div class="archwiki-template-meta-related-articles-start">
<p>相關文章</p>
<ul>
<li><a href="/title/SSD_Benchmarking" class="mw-redirect" title="SSD Benchmarking">SSD Benchmarking</a></li>
<li><a href="/title/SSD_Memory_Cell_Clearing" class="mw-redirect" title="SSD Memory Cell Clearing">SSD Memory Cell Clearing</a></li>
<li><a href="/title/Profile-sync-daemon" title="Profile-sync-daemon">profile-sync-daemon</a></li>
</ul>
</div>
<div id="toc" class="toc" role="navigation" aria-labelledby="mw-toc-heading">
<input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none"><div class="toctitle" lang="en" dir="ltr">
<h2 id="mw-toc-heading">Contents</h2>
<span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span>
</div>
<ul>
<li class="toclevel-1 tocsection-1">
<a href="#%E6%A6%82%E8%A7%80"><span class="tocnumber">1</span> <span class="toctext">概觀</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#%E4%BB%8B%E7%B4%B9"><span class="tocnumber">1.1</span> <span class="toctext">介紹</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="#%E5%92%8C%E4%B8%80%E8%88%AC%E7%A1%AC%E7%A2%9F%E7%9B%B8%E6%AF%94%E7%9A%84%E5%84%AA%E5%8B%A2"><span class="tocnumber">1.2</span> <span class="toctext">和一般硬碟相比的優勢</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#%E7%9B%AE%E5%89%8D%E7%9A%84%E9%99%90%E5%88%B6"><span class="tocnumber">1.3</span> <span class="toctext">目前的限制</span></a></li>
<li class="toclevel-2 tocsection-5">
<a href="#%E8%B3%BC%E8%B2%B7%E5%89%8D%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A0%85"><span class="tocnumber">1.4</span> <span class="toctext">購買前的注意事項</span></a>
<ul>
<li class="toclevel-3 tocsection-6"><a href="#%E5%8F%83%E8%80%83%E9%80%A3%E7%B5%90"><span class="tocnumber">1.4.1</span> <span class="toctext">參考連結</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-7">
<a href="#Tips_for_Maximizing_SSD_Performance"><span class="tocnumber">2</span> <span class="toctext">Tips for Maximizing SSD Performance</span></a>
<ul>
<li class="toclevel-2 tocsection-8"><a href="#Partition_Alignment"><span class="tocnumber">2.1</span> <span class="toctext">Partition Alignment</span></a></li>
<li class="toclevel-2 tocsection-9">
<a href="#TRIM"><span class="tocnumber">2.2</span> <span class="toctext">TRIM</span></a>
<ul>
<li class="toclevel-3 tocsection-10"><a href="#Verify_TRIM_Support"><span class="tocnumber">2.2.1</span> <span class="toctext">Verify TRIM Support</span></a></li>
<li class="toclevel-3 tocsection-11"><a href="#Enable_TRIM_by_Mount_Flags"><span class="tocnumber">2.2.2</span> <span class="toctext">Enable TRIM by Mount Flags</span></a></li>
<li class="toclevel-3 tocsection-12"><a href="#Apply_TRIM_via_cron"><span class="tocnumber">2.2.3</span> <span class="toctext">Apply TRIM via cron</span></a></li>
<li class="toclevel-3 tocsection-13">
<a href="#Apply_TRIM_via_a_systemd_service"><span class="tocnumber">2.2.4</span> <span class="toctext">Apply TRIM via a systemd service</span></a>
<ul>
<li class="toclevel-4 tocsection-14"><a href="#Enable_TRIM_for_LVM"><span class="tocnumber">2.2.4.1</span> <span class="toctext">Enable TRIM for LVM</span></a></li>
</ul>
</li>
<li class="toclevel-3 tocsection-15"><a href="#Enable_TRIM_With_mkfs.ext4_or_tune2fs_(Discouraged)"><span class="tocnumber">2.2.5</span> <span class="toctext">Enable TRIM With mkfs.ext4 or tune2fs (Discouraged)</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-16">
<a href="#I/O_Scheduler"><span class="tocnumber">2.3</span> <span class="toctext">I/O Scheduler</span></a>
<ul>
<li class="toclevel-3 tocsection-17"><a href="#Kernel_parameter_(for_a_single_device)"><span class="tocnumber">2.3.1</span> <span class="toctext">Kernel parameter (for a single device)</span></a></li>
<li class="toclevel-3 tocsection-18"><a href="#Using_the_sys_virtual_filesystem_(for_multiple_devices)"><span class="tocnumber">2.3.2</span> <span class="toctext">Using the sys virtual filesystem (for multiple devices)</span></a></li>
<li class="toclevel-3 tocsection-19"><a href="#Using_udev_for_one_device_or_HDD/SSD_mixed_environment"><span class="tocnumber">2.3.3</span> <span class="toctext">Using udev for one device or HDD/SSD mixed environment</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-20"><a href="#Swap_Space_on_SSDs"><span class="tocnumber">2.4</span> <span class="toctext">Swap Space on SSDs</span></a></li>
<li class="toclevel-2 tocsection-21"><a href="#SSD_Memory_Cell_Clearing"><span class="tocnumber">2.5</span> <span class="toctext">SSD Memory Cell Clearing</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-22">
<a href="#Tips_for_Minimizing_SSD_Read/Writes"><span class="tocnumber">3</span> <span class="toctext">Tips for Minimizing SSD Read/Writes</span></a>
<ul>
<li class="toclevel-2 tocsection-23"><a href="#Intelligent_Partition_Scheme"><span class="tocnumber">3.1</span> <span class="toctext">Intelligent Partition Scheme</span></a></li>
<li class="toclevel-2 tocsection-24"><a href="#noatime_Mount_Flag"><span class="tocnumber">3.2</span> <span class="toctext">noatime Mount Flag</span></a></li>
<li class="toclevel-2 tocsection-25">
<a href="#Locate_High-Use_Files_to_RAM"><span class="tocnumber">3.3</span> <span class="toctext">Locate High-Use Files to RAM</span></a>
<ul>
<li class="toclevel-3 tocsection-26"><a href="#Browser_Profiles"><span class="tocnumber">3.3.1</span> <span class="toctext">Browser Profiles</span></a></li>
<li class="toclevel-3 tocsection-27"><a href="#Others"><span class="tocnumber">3.3.2</span> <span class="toctext">Others</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-28"><a href="#Compiling_in_tmpfs"><span class="tocnumber">3.4</span> <span class="toctext">Compiling in tmpfs</span></a></li>
<li class="toclevel-2 tocsection-29"><a href="#Disabling_Journaling_on_the_filesystem"><span class="tocnumber">3.5</span> <span class="toctext">Disabling Journaling on the filesystem</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-30">
<a href="#Choice_of_Filesystem"><span class="tocnumber">4</span> <span class="toctext">Choice of Filesystem</span></a>
<ul>
<li class="toclevel-2 tocsection-31"><a href="#Btrfs"><span class="tocnumber">4.1</span> <span class="toctext">Btrfs</span></a></li>
<li class="toclevel-2 tocsection-32"><a href="#Ext4"><span class="tocnumber">4.2</span> <span class="toctext">Ext4</span></a></li>
<li class="toclevel-2 tocsection-33"><a href="#XFS"><span class="tocnumber">4.3</span> <span class="toctext">XFS</span></a></li>
<li class="toclevel-2 tocsection-34"><a href="#JFS"><span class="tocnumber">4.4</span> <span class="toctext">JFS</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-35">
<a href="#Firmware_Updates"><span class="tocnumber">5</span> <span class="toctext">Firmware Updates</span></a>
<ul>
<li class="toclevel-2 tocsection-36"><a href="#ADATA"><span class="tocnumber">5.1</span> <span class="toctext">ADATA</span></a></li>
<li class="toclevel-2 tocsection-37"><a href="#Crucial"><span class="tocnumber">5.2</span> <span class="toctext">Crucial</span></a></li>
<li class="toclevel-2 tocsection-38"><a href="#Kingston"><span class="tocnumber">5.3</span> <span class="toctext">Kingston</span></a></li>
<li class="toclevel-2 tocsection-39"><a href="#Mushkin"><span class="tocnumber">5.4</span> <span class="toctext">Mushkin</span></a></li>
<li class="toclevel-2 tocsection-40"><a href="#OCZ"><span class="tocnumber">5.5</span> <span class="toctext">OCZ</span></a></li>
<li class="toclevel-2 tocsection-41"><a href="#Samsung"><span class="tocnumber">5.6</span> <span class="toctext">Samsung</span></a></li>
<li class="toclevel-2 tocsection-42"><a href="#SanDisk"><span class="tocnumber">5.7</span> <span class="toctext">SanDisk</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-43"><a href="#See_also"><span class="tocnumber">6</span> <span class="toctext">See also</span></a></li>
</ul>
</div>

<h2>
<span id=".E6.A6.82.E8.A7.80"></span><span class="mw-headline" id="概觀">概觀</span>
</h2>
<h3>
<span id=".E4.BB.8B.E7.B4.B9"></span><span class="mw-headline" id="介紹">介紹</span>
</h3>
<p>固態硬碟 (SSD) 並不是一個隨插即用的裝置。在使用 SSD 上我們要特別去考量 partition 的校準，選擇適合的檔案系統，以及是否支援 TRIM 等等。才能將效能最佳化。這篇文章儘量深入淺出來讓使用者學習，如何在 Linux 中設定 SSD。
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> 雖然本篇文章主要的目標使用者是是使用 Linux 的族群，但是文中的內容一樣也是相容於使用其他作業系統的朋友們，像是 BSD, Mac OS X 或 Windows.</div>
<h3>
<span id=".E5.92.8C.E4.B8.80.E8.88.AC.E7.A1.AC.E7.A2.9F.E7.9B.B8.E6.AF.94.E7.9A.84.E5.84.AA.E5.8B.A2"></span><span class="mw-headline" id="和一般硬碟相比的優勢">和一般硬碟相比的優勢</span>
</h3>
<ul>
<li>更快的讀取速度 - 比起現在最新的硬碟，還要快上 2-3 倍 (7,200 RPM 使用 SATA2 介面).</li>
<li>讀取速度連貫且持續 - 因為 SSD 沒有磁頭，所以不會因為要移動磁頭來讀取碟盤上的資料而導致速度慢在磁頭的移動上。</li>
<li>最小的 access time - 大約是硬碟的 100 倍快。舉例來說， 0.1 ms (100 us) vs. 12-20 ms (12,000-20,000 us) for desktop HDDs.</li>
<li>高度的可靠性。</li>
<li>沒有移動部件。</li>
<li>產出的熱能極小。</li>
<li>省電 - 在靜止的狀態時，不到 1 W，在讀寫狀態時則是 1-2 W，而硬碟則根據硬碟轉速需消耗 10-30 W。</li>
<li>輕巧 - 這對筆記型電腦來說很重要。</li>
</ul>
<h3>
<span id=".E7.9B.AE.E5.89.8D.E7.9A.84.E9.99.90.E5.88.B6"></span><span class="mw-headline" id="目前的限制">目前的限制</span>
</h3>
<ul>
<li>價格昂貴，大約是 1 GB 要 1 美金，而一般硬碟每 1 GB 大約是 0.1-0.2 美金。</li>
<li>一般市售得 SSD 的儲存容量，都小於一般硬碟。</li>
<li>Large cells require different filesystem optimizations than rotating media. The flash translation layer hides the raw flash access which a modern OS could use to optimize access.</li>
<li>Partitions and filesystems need some SSD-specific tuning. Page size and erase page size are not autodetected.</li>
<li>Cells wear out. Consumer MLC cells at mature 50nm processes can handle 10000 writes each; 35nm generally handles 5000 writes, and 25nm 3000 (smaller being higher density and cheaper). If writes are properly spread out, are not too small, and align well with cells, this translates into a lifetime write volume for the SSD that is a multiple of its capacity. Daily write volumes have to be balanced against life expectancy.</li>
<li>Firmwares and controllers are complex. They occasionally have bugs. Modern ones consume power comparable with HDDs. They <a rel="nofollow" class="external text" href="https://lwn.net/Articles/353411/">implement</a> the equivalent of a log-structured filesystem with garbage collection. They translate SATA commands traditionally intended for rotating media. Some of them do on the fly compression. They spread out repeated writes across the entire area of the flash, to prevent wearing out some cells prematurely. They also coalesce writes together so that small writes are not amplified into as many erase cycles of large cells. Finally they move cells containing data so that the cell does not lose its contents over time.</li>
<li>Performance can drop as the disk gets filled. Garbage collection is not universally well implemented, meaning freed space is not always collected into entirely free cells.</li>
</ul>
<h3>
<span id=".E8.B3.BC.E8.B2.B7.E5.89.8D.E7.9A.84.E6.B3.A8.E6.84.8F.E4.BA.8B.E9.A0.85"></span><span class="mw-headline" id="購買前的注意事項">購買前的注意事項</span>
</h3>
<p>There are several key features to look for prior to purchasing a contemporary SSD.
</p>
<ul>
<li>Native <a href="https://en.wikipedia.org/wiki/TRIM" class="extiw" title="wikipedia:TRIM">TRIM</a> support is a vital feature that both prolongs SSD lifetime and reduces loss of performance for write operations over time.</li>
<li>Buying the right sized SSD is key. As with all filesystems, target &lt;75 % occupancy for all SSD partitions to ensure efficient use by the kernel.</li>
</ul>
<h4>
<span id=".E5.8F.83.E8.80.83.E9.80.A3.E7.B5.90"></span><span class="mw-headline" id="參考連結">參考連結</span>
</h4>
<p>這些文章並不能包含所有的情況，但是你可以從中學習到一些重點。
</p>
<ul>
<li><a rel="nofollow" class="external text" href="https://www.anandtech.com/show/2738">SSD Anthology (歷史課，有點時間了)</a></li>
<li>
<a rel="nofollow" class="external text" href="https://www.anandtech.com/show/2829">SSD Relapse (較新一點，比較跟的上時代了</a>)</li>
<li>
<a rel="nofollow" class="external text" href="http://forums.anandtech.com/showthread.php?t=2069761">一位使用者的建議</a><sup title="Last check status: 404">[<a href="https://en.wikipedia.org/wiki/Wikipedia:Link_rot" class="extiw" title="wikipedia:Wikipedia:Link rot">dead link</a> 2020-08-04 ⓘ]</sup>
</li>
<li><a rel="nofollow" class="external text" href="https://techgage.com/article/enabling_and_testing_ssd_trim_support_under_linux/">使用與測試 SSD TRIM 在 Linux 底下的支援性</a></li>
</ul>
<h2><span class="mw-headline" id="Tips_for_Maximizing_SSD_Performance">Tips for Maximizing SSD Performance</span></h2>
<h3><span class="mw-headline" id="Partition_Alignment">Partition Alignment</span></h3>
<p>Using partitions that are aligned with the erase block size is highly recommended.  In past, this required manual calculation and intervention when partitioning.  Many of the common partition tools handle partition alignment automatically (assuming users are using an up-to-date version):
</p>
<ul>
<li>fdisk</li>
<li>gdisk</li>
<li>gparted</li>
<li>parted</li>
</ul>
<p>To verify a partition is aligned, query it using <code>/usr/bin/blockdev</code> as shown below, if a '0' is returned, the partition is aligned:
</p>
<pre># blockdev --getalignoff /dev/&lt;partition&gt;
0
</pre>
<h3><span class="mw-headline" id="TRIM">TRIM</span></h3>
<p>Most SSDs support the <a href="https://en.wikipedia.org/wiki/TRIM" class="extiw" title="wikipedia:TRIM">ATA_TRIM command</a> for sustained long-term performance and wear-leveling.  For more including some before and after benchmark, see <a rel="nofollow" class="external text" href="https://sites.google.com/site/lightrush/random-1/howtoconfigureext4toenabletrimforssdsonubuntu">this</a> tutorial.  
</p>
<p>As of linux kernel version 3.7, the following filesystems support TRIM: <a href="/title/Ext4" title="Ext4">Ext4</a>, <a href="/title/Btrfs" title="Btrfs">Btrfs</a>, <a href="/title/JFS" title="JFS">JFS</a>, and <a href="/title/XFS" title="XFS">XFS</a>.
</p>
<p>The <a href="#Choice_of_Filesystem">Choice of Filesystem</a> section of this article offers more details.
</p>
<h4><span class="mw-headline" id="Verify_TRIM_Support">Verify TRIM Support</span></h4>
<pre># hdparm -I /dev/sda |grep TRIM
        *    Data Set Management TRIM supported (limit 1 block)
        *    Deterministic read data after TRIM
</pre>
<p>To have a better understanding of "limit 1 block" or "limit 8 block", see <a href="https://en.wikipedia.org/wiki/TRIM#ATA" class="extiw" title="wikipedia:TRIM">wikipedia:TRIM#ATA</a>
</p>
<h4><span class="mw-headline" id="Enable_TRIM_by_Mount_Flags">Enable TRIM by Mount Flags</span></h4>
<p>Using this flag in one's <code>/etc/fstab</code> enables the benefits of the TRIM command stated above.
</p>
<pre>/dev/sda1  /       ext4   defaults,noatime,<b>discard</b>   0  1
/dev/sda2  /home   ext4   defaults,noatime,<b>discard</b>   0  2
</pre>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> Using the <code>discard</code> flag for an ext3 root partition will result in it being mounted read-only.</div>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>Warning:</strong> Users need to be certain that kernel version 2.6.33 or above is being used AND that their SSD supports TRIM before attempting to mount a partition with the <code>discard</code> flag. Data loss can occur otherwise!</div>
<h4><span class="mw-headline" id="Apply_TRIM_via_cron">Apply TRIM via cron</span></h4>
<p>Enabling TRIM on supported SSDs is definitely recommended.  But sometimes it may cause some SSDs to <a rel="nofollow" class="external text" href="https://patrick-nagel.net/blog/archives/337">perform slowly</a> during deletion of files.  If this is the case, one may choose to use fstrim as an alternative.
</p>
<pre># fstrim -v /
</pre>
<p>The partition for which fstrim is to be applied must be mounted, and must be indicated by the mount point.  
</p>
<p>If this method seems like a better alternative, it might be a good idea to have this run from time to time using cron.  To have this run daily, the default cron package (<span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=cronie">cronie</a></span>) includes an anacron implementation which, by default, is set up for hourly, daily, weekly, and monthly jobs.  To add to the list of daily cron tasks, simply create a script that takes care of the desired actions and put it in <code>/etc/cron.daily</code>, <code>/etc/cron.weekly</code>, etc.  Appropriate nice and ionice values are recommended if this method is chosen.  If implemented, remove the <code>discard</code> option from <code>/etc/fstab</code>.
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> Use the <code>discard</code> mount option as a first choice.  This method should be considered second to the normal implementation of TRIM.</div>
<h4><span class="mw-headline" id="Apply_TRIM_via_a_systemd_service">Apply TRIM via a systemd service</span></h4>
<p>See <a rel="nofollow" class="external text" href="http://mjanja.co.ke/2013/04/systemd-service-to-trim-free-ssd-cells-at-boot/">this blog post</a><sup title="Last check status: domain name not resolved">[<a href="https://en.wikipedia.org/wiki/Wikipedia:Link_rot" class="extiw" title="wikipedia:Wikipedia:Link rot">dead link</a> 2020-08-04 ⓘ]</sup>.
</p>
<h5><span class="mw-headline" id="Enable_TRIM_for_LVM">Enable TRIM for LVM</span></h5>
<p>Enable <code>issue_discards</code> option in <code>/etc/lvm/lvm.conf</code>.
</p>
<h4>
<span id="Enable_TRIM_With_mkfs.ext4_or_tune2fs_.28Discouraged.29"></span><span class="mw-headline" id="Enable_TRIM_With_mkfs.ext4_or_tune2fs_(Discouraged)">Enable TRIM With mkfs.ext4 or tune2fs (Discouraged)</span>
</h4>
<p>One can set the trim flag statically with tune2fs or when the filesystem is created:
</p>
<pre># tune2fs -o discard /dev/sd<b>XY</b>
</pre>
<p>or:
</p>
<pre># mkfs.ext4 -E discard /dev/sd<b>XY</b>
</pre>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>Warning:</strong> This method will cause the <code>discard</code> option to <a rel="nofollow" class="external text" href="https://bbs.archlinux.org/viewtopic.php?id=137314">not show up</a> with <code>mount</code>.</div>
<h3>
<span id="I.2FO_Scheduler"></span><span class="mw-headline" id="I/O_Scheduler">I/O Scheduler</span>
</h3>
<div class="noprint archwiki-template-message">
<p><a href="/title/File:Tango-view-refresh-red.png" class="image"><img alt="Tango-view-refresh-red.png" src="../File:Tango-view-refresh-red.png" decoding="async" width="48" height="48"></a><b>This article or section is out of date.</b><a href="/title/File:Tango-view-refresh-red.png" class="image"><img alt="Tango-view-refresh-red.png" src="../File:Tango-view-refresh-red.png" decoding="async" width="48" height="48"></a></p>
<div>
<b>Reason:</b> According to the discussion page, the CFQ scheduler can detect SSDs and modifies its behavior appropriately, so there is no need to change the I/O scheduler. (Discuss in <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/title/Talk:Solid_state_drive_(%E6%AD%A3%E9%AB%94%E4%B8%AD%E6%96%87)">Talk:Solid state drive (正體中文)#</a>)</div>
</div>
<p>Consider switching from the default <a href="https://en.wikipedia.org/wiki/CFQ" class="extiw" title="wikipedia:CFQ">CFQ</a> scheduler (Completely Fair Queuing) to <a href="https://en.wikipedia.org/wiki/NOOP_scheduler" class="extiw" title="wikipedia:NOOP scheduler">NOOP</a> or <a href="https://en.wikipedia.org/wiki/Deadline_scheduler" class="extiw" title="wikipedia:Deadline scheduler">Deadline</a>. The latter two offer performance boosts for SSDs. The NOOP scheduler, for example, implements a simple queue for all incoming I/O requests, without re-ordering and grouping the ones that are physically closer on the disk. On SSDs seek times are identical for all sectors, thus invalidating the need to re-order I/O queues based on them.
</p>
<p>The CFQ scheduler is enabled by default on Arch. Verify this by viewing the contents <code>/sys/block/sd<b>X</b>/queue/scheduler</code>:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ cat /sys/block/sd<b>X</b>/queue/scheduler</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">noop deadline [cfq]
</pre>
<p>The scheduler currently in use is denoted from the available schedulers by the brackets. 
</p>
<p>Users can change this on the fly without the need to reboot with:
</p>
<pre># echo noop &gt; /sys/block/sd<b>X</b>/queue/scheduler
</pre>
<p>or:
</p>
<pre>$ sudo tee /sys/block/sd<b>X</b>/queue/scheduler &lt;&lt;&lt; noop
</pre>
<p>This method is non-persistent (eg. change will be lost upon rebooting).  Confirm the change was made by viewing the contents of the file again and ensuring "noop" is between brackets.
</p>
<h4>
<span id="Kernel_parameter_.28for_a_single_device.29"></span><span class="mw-headline" id="Kernel_parameter_(for_a_single_device)">Kernel parameter (for a single device)</span>
</h4>
<p>If the sole storage device in the system is an SSD, consider setting the I/O scheduler for the entire system via the <code>elevator=noop</code> <a href="/title/Kernel_parameters" title="Kernel parameters">kernel parameter</a>.
</p>
<h4>
<span id="Using_the_sys_virtual_filesystem_.28for_multiple_devices.29"></span><span class="mw-headline" id="Using_the_sys_virtual_filesystem_(for_multiple_devices)">Using the sys virtual filesystem (for multiple devices)</span>
</h4>
<div class="noprint archwiki-template-message">
<p><a href="/title/File:Tango-view-refresh-red.png" class="image"><img alt="Tango-view-refresh-red.png" src="../File:Tango-view-refresh-red.png" decoding="async" width="48" height="48"></a><b>This article or section is out of date.</b><a href="/title/File:Tango-view-refresh-red.png" class="image"><img alt="Tango-view-refresh-red.png" src="../File:Tango-view-refresh-red.png" decoding="async" width="48" height="48"></a></p>
<div>
<b>Reason:</b> Using <code>tmpfiles.d</code> to set the scheduler does not appear to work on current versions of Arch; The udev method below works perfectly. (Discuss in <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/title/Talk:Solid_state_drive_(%E6%AD%A3%E9%AB%94%E4%B8%AD%E6%96%87)">Talk:Solid state drive (正體中文)#</a>)</div>
</div>
<div class="noprint archwiki-template-message">
<p><a href="/title/File:Tango-view-refresh-red.png" class="image"><img alt="Tango-view-refresh-red.png" src="../File:Tango-view-refresh-red.png" decoding="async" width="48" height="48"></a><b>This article or section is out of date.</b><a href="/title/File:Tango-view-refresh-red.png" class="image"><img alt="Tango-view-refresh-red.png" src="../File:Tango-view-refresh-red.png" decoding="async" width="48" height="48"></a></p>
<div>
<b>Reason:</b> rc.local has been deprecated for some time now; recommend using a custom service. (Discuss in <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/title/Talk:Solid_state_drive_(%E6%AD%A3%E9%AB%94%E4%B8%AD%E6%96%87)">Talk:Solid state drive (正體中文)#</a>)</div>
</div>
<p>This method is preferred when the system has several physical storage devices (for example an SSD and an HDD).
</p>
<p>Create the following tmpfile where <b>X</b> is the letter for the SSD device.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/tmpfiles.d/set_IO_scheduler.conf </pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">w /sys/block/sd<b>X</b>/queue/scheduler - - - - noop
</pre>
<p>Because of the potential for udev to assign different <code>/dev/</code> nodes to drives before and after a kernel update, users must take care that the NOOP scheduler is applied to the correct device upon boot. One way to do this is by using the SSD's device ID to determine its <code>/dev/</code> node. To do this automatically, use the following snippet instead of the line above and add it to <code>/etc/rc.local</code>:
</p>
<pre>declare -ar SSDS=(
  'scsi-SATA_SAMSUNG_SSD_PM8_S0NUNEAB861972'
  'ata-SAMSUNG_SSD_PM810_2.5__7mm_256GB_S0NUNEAB861972'
)

for SSD in "${SSDS[@]}" ; do
  BY_ID=/dev/disk/by-id/$SSD

  if [[ -e $BY_ID ]] ; then
    DEV_NAME=`ls -l $BY_ID | awk '{ print $NF }' | sed -e 's/[/\.]//g'`
    SCHED=/sys/block/$DEV_NAME/queue/scheduler

    if [[ -w $SCHED ]] ; then
      echo noop &gt; $SCHED
    fi
  fi
done
</pre>
<p>where <code>SSDS</code> is a Bash array containing the device IDs of all SSD devices. Device IDs are listed in <code>/dev/disk/by-id/</code> as symbolic links pointing to their corresponding <code>/dev/</code> nodes. To view the links listed with their targets, issue the following command:
</p>
<pre>$ ls -l /dev/disk/by-id/
</pre>
<h4>
<span id="Using_udev_for_one_device_or_HDD.2FSSD_mixed_environment"></span><span class="mw-headline" id="Using_udev_for_one_device_or_HDD/SSD_mixed_environment">Using udev for one device or HDD/SSD mixed environment</span>
</h4>
<p>Though the above will undoubtedly work, it is probably considered a reliable workaround.  Ergo, it would be preferred to use the system that is responsible for the devices in the first place to implement the scheduler.  In this case it is udev, and to do this, all one needs is a simple <a href="/title/Udev" title="Udev">udev</a> rule.
</p>
<p>To do this, create the following:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/udev/rules.d/60-schedulers.rules</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;"># set deadline scheduler for non-rotating disks
ACTION=="add|change", KERNEL=="sd[a-z]", TEST!="queue/rotational", ATTR{queue/scheduler}="deadline"
ACTION=="add|change", KERNEL=="sd[a-z]", ATTR{queue/rotational}=="0", ATTR{queue/scheduler}="deadline"

# set cfq scheduler for rotating disks
ACTION=="add|change", KERNEL=="sd[a-z]", ATTR{queue/rotational}=="1", ATTR{queue/scheduler}="cfq"
</pre>
<p>Of course, set Deadline/CFQ to the desired schedulers.  Changes should occur upon next boot.  To check success of the new rule:
</p>
<pre>$ cat /sys/block/sd<b>X</b>/queue/scheduler  # where <b>X</b> is the device in question
</pre>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> Keep in mind CFQ is the default scheduler, so the second rule with the standard kernel is not actually necessary. Also, in the example sixty is chosen because that is the number udev uses for its own persistent naming rules. Thus, it would seem that block devices are at this point able to be modified and this is a safe position for this particular rule. But the rule can be named anything so long as it ends in <code>.rules</code>.)</div>
<h3><span class="mw-headline" id="Swap_Space_on_SSDs">Swap Space on SSDs</span></h3>
<p>One can place a swap partition on an SSD. Most modern desktops with an excess of 2 Gigs of memory rarely use swap at all. The notable exception is systems which make use of the hibernate feature. The following is a recommended tweak for SSDs using a swap partition that will reduce the "swappiness" of the system thus avoiding writes to swap:
</p>
<pre># echo 1 &gt; /proc/sys/vm/swappiness
</pre>
<p>Or one can simply do as recommended in the <a href="/title/Improving_performance#Swappiness" title="Improving performance">Maximizing Performance</a><sup>[<a href="/title/Help:Procedures#Fix_broken_section_links" title="Help:Procedures">broken link</a>: invalid section]</sup> article:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/sysctl.d/99-sysctl.conf</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">vm.swappiness=1
vm.vfs_cache_pressure=50</pre>
<h3><span class="mw-headline" id="SSD_Memory_Cell_Clearing">SSD Memory Cell Clearing</span></h3>
<p>On occasion, users may wish to completely reset an SSD's cells to the same virgin state they were at the time the device was installed thus restoring it to its <a rel="nofollow" class="external text" href="https://www.anandtech.com/storage/showdoc.aspx?i=3531&amp;p=8">factory default write performance</a>. Write performance is known to degrade over time even on SSDs with native TRIM support. TRIM only safeguards against file deletes, not replacements such as an incremental save.
</p>
<p>The reset is easily accomplished in a three step procedure denoted on the <a href="/title/SSD_memory_cell_clearing" class="mw-redirect" title="SSD memory cell clearing">SSD memory cell clearing</a> wiki article.
</p>
<h2>
<span id="Tips_for_Minimizing_SSD_Read.2FWrites"></span><span class="mw-headline" id="Tips_for_Minimizing_SSD_Read/Writes">Tips for Minimizing SSD Read/Writes</span>
</h2>
<p>An overarching theme for SSD usage should be 'simplicity' in terms of locating high-read/write operations either in RAM (Random Access Memory) or on a physical HDD rather than on an SSD. Doing so will add longevity to an SSD. This is primarily due to the large erase block size (512 KiB in some cases); a lot of small writes result in huge effective writes.
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> A 32GB SSD with a mediocre 10x write amplification factor, a standard 10000 write/erase cycle, and <b>10GB of data written per day</b>, would get an <b>8 years life expectancy</b>. It gets better with bigger SSDs and modern controllers with less write amplification.</div>
<p>Use <code>$ iotop -oPa</code> and sort by disk writes to see how much programs are writing to disk.
</p>
<h3><span class="mw-headline" id="Intelligent_Partition_Scheme">Intelligent Partition Scheme</span></h3>
<ul><li>For systems with both an SSD and an HDD, consider relocating the <code>/var</code> partition to a magnetic disc on the system rather than on the SSD itself to avoid read/write wear.</li></ul>
<h3><span class="mw-headline" id="noatime_Mount_Flag">noatime Mount Flag</span></h3>
<p>Using this flag in one's <code>/etc/fstab</code> halts the logging of read accesses to the file system via an update to the atime information associated with the file.  The importance of the <code>noatime</code> setting is that it eliminates the need by the system to make writes to the file system for files which are simply being read.  Since writes can be somewhat expensive as mentioned in previous section, this can result in measurable performance gains.
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> The write time information to a file will continue to be updated anytime the file is written to with this option enabled.</div>
<pre>/dev/sda1  /       ext4   defaults,<b>noatime</b>   0  1
/dev/sda2  /home   ext4   defaults,<b>noatime</b>   0  2
</pre>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> This setting will cause issues with some programs such as <a href="/title/Mutt" title="Mutt">Mutt</a>, as the access time of the file will eventually be previous than the modification time, which would make no sense. Using the <code>relatime</code> option instead of <code>noatime</code> will ensure that the atime field will never be prior to the last modification time of a file.  Alternatively, using the maildir storage format also solves this mutt issue.</div>
<h3><span class="mw-headline" id="Locate_High-Use_Files_to_RAM">Locate High-Use Files to RAM</span></h3>
<h4><span class="mw-headline" id="Browser_Profiles">Browser Profiles</span></h4>
<p>One can <i>easily</i> mount browser profile(s) such as chromium, firefox, opera, etc. into RAM via tmpfs and also use rsync to keep them synced with HDD-based backups. In addition to the obvious speed enhancements, users will also save read/write cycles on their SSD by doing so.
</p>
<p>The AUR contains several packages to automate this process, for example <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=profile-sync-daemon">profile-sync-daemon</a></span>.
</p>
<h4><span class="mw-headline" id="Others">Others</span></h4>
<p>For the same reasons a browser's profile can be relocated to RAM, so can highly used directories such as <code>/srv/http</code> (if running a web server). A sister project to <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=profile-sync-daemon">profile-sync-daemon</a></span> is <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=anything-sync-daemon">anything-sync-daemon</a></span>, which allows users to define <b>any</b> directory to sync to RAM using the same underlying logic and safe guards.
</p>
<h3><span class="mw-headline" id="Compiling_in_tmpfs">Compiling in tmpfs</span></h3>
<p>Intentionally compiling in <code>/tmp</code> is a great idea to minimize this problem. Arch Linux defaults <code>/tmp</code> to 50 % of the physical memory.  For systems with &gt;4 GB of memory, one can create a <code>/scratch</code> and mount it to tmpfs set to use more than 50 % of the physical memory.
</p>
<p>Example of a machine with 8 GB of physical memory:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ mount | grep tmpfs</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">tmpfs     /scratch     tmpfs     nodev,nosuid,size=7G     0     0</pre>
<h3><span class="mw-headline" id="Disabling_Journaling_on_the_filesystem">Disabling Journaling on the filesystem</span></h3>
<p>Using a journaling filesystem such as ext4 on an SSD WITHOUT a journal is an option to decrease read/writes. The obvious drawback of using a filesystem with journaling disabled is data loss as a result of an ungraceful dismount (i.e. post power failure, kernel lockup, etc.). With modern SSDs, <a rel="nofollow" class="external text" href="https://tytso.livejournal.com/61830.html">Ted Tso</a> advocates that journaling can be enabled with minimal extraneous read/write cycles under most circumstances:
</p>
<p><b>Amount of data written (in megabytes) on an ext4 file system mounted with <code>noatime</code>.</b>
</p>
<table class="wikitable">
<tbody>
<tr>
<th>operation</th>
<th>journal</th>
<th>w/o journal</th>
<th>percent change
</th>
</tr>
<tr>
<th>git clone
</th>
<td>367.0
</td>
<td>353.0
</td>
<td>3.81 %
</td>
</tr>
<tr>
<th>make
</th>
<td>207.6
</td>
<td>199.4
</td>
<td>3.95 %
</td>
</tr>
<tr>
<th>make clean
</th>
<td>6.45
</td>
<td>3.73
</td>
<td>42.17 %
</td>
</tr>
</tbody>
</table>
<p><i>"What the results show is that metadata-heavy workloads, such as make clean, do result in almost twice the amount data written to disk. This is to be expected, since all changes to metadata blocks are first written to the journal and the journal transaction committed before the metadata is written to their final location on disk. However, for more common workloads where we are writing data as well as modifying filesystem metadata blocks, the difference is much smaller."</i>
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> The make clean example from the table above typifies the importance of intentionally doing compiling in tmpfs as recommended in the <a href="/title/Solid_State_Drives#Compiling_in_tmpfs" class="mw-redirect" title="Solid State Drives">preceding section</a><sup>[<a href="/title/Help:Procedures#Fix_broken_section_links" title="Help:Procedures">broken link</a>: invalid section]</sup> of this article!</div>
<h2><span class="mw-headline" id="Choice_of_Filesystem">Choice of Filesystem</span></h2>
<h3><span class="mw-headline" id="Btrfs">Btrfs</span></h3>
<p><a href="https://en.wikipedia.org/wiki/Btrfs" class="extiw" title="wikipedia:Btrfs">Btrfs</a> support has been included with the mainline 2.6.29 release of the Linux kernel. Some feel that it is not mature enough for production use while there are also early adopters of this potential successor to ext4. Users are encouraged to read the <a href="/title/Btrfs" title="Btrfs">Btrfs</a> article for more info.
</p>
<h3><span class="mw-headline" id="Ext4">Ext4</span></h3>
<p><a href="https://en.wikipedia.org/wiki/Ext4" class="extiw" title="wikipedia:Ext4">Ext4</a> is another filesystem that has support for SSD. It is considered as stable since 2.6.28 and is mature enough for daily use. ext4 users must explicitly enable the TRIM command support using the <code>discard</code> mount option in <a href="/title/Fstab" title="Fstab">fstab</a> (or with <code>tune2fs -o discard /dev/sdaX</code>).
See the <a rel="nofollow" class="external text" href="http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=blob;f=Documentation/filesystems/ext4.txt">official in kernel tree documentation</a><sup title="Last check status: 404">[<a href="https://en.wikipedia.org/wiki/Wikipedia:Link_rot" class="extiw" title="wikipedia:Wikipedia:Link rot">dead link</a> 2020-08-04 ⓘ]</sup> for further information on ext4.
</p>
<h3><span class="mw-headline" id="XFS">XFS</span></h3>
<p>Many users do not realize that in addition to ext4 and btrfs, <a href="https://en.wikipedia.org/wiki/XFS" class="extiw" title="wikipedia:XFS">XFS</a> has TRIM support as well.  This can be enabled in the usual ways.  That is, the choice may be made of either using the discard option mentioned above, or by using the fstrim command.  More information can be found on the <a rel="nofollow" class="external text" href="http://xfs.org/index.php/FITRIM/discard">XFS wiki</a>.
</p>
<h3><span class="mw-headline" id="JFS">JFS</span></h3>
<p>As of Linux kernel version 3.7, proper TRIM support has been added.  So far, there is not a great wealth of information of the topic but it has certainly been picked up by <a rel="nofollow" class="external text" href="https://www.phoronix.com/scan.php?page=news_item&amp;px=MTE5ODY">Linux news sites.</a>  It is apparent that it can be enabled via the <code>discard</code> mount option, or by using the method of batch TRIMs with fstrim.
</p>
<h2><span class="mw-headline" id="Firmware_Updates">Firmware Updates</span></h2>
<h3><span class="mw-headline" id="ADATA">ADATA</span></h3>
<p>ADATA has a utility available for Linux (i686) on their support page <a rel="nofollow" class="external text" href="http://www.adata.com.tw/index.php?action=ss_main&amp;page=ss_content_driver&amp;lan=en">here</a>. The link to the utility will appear after selecting the model.
</p>
<h3><span class="mw-headline" id="Crucial">Crucial</span></h3>
<p>Crucial provides an option for updating the firmware with an ISO image. These images can be found after selecting the product <a rel="nofollow" class="external text" href="http://www.crucial.com/support/firmware.aspx">here</a><sup title="Last check status: 404">[<a href="https://en.wikipedia.org/wiki/Wikipedia:Link_rot" class="extiw" title="wikipedia:Wikipedia:Link rot">dead link</a> 2020-08-04 ⓘ]</sup> and downloading the "Manual Boot File."  Owners of an M4 Crucial model, may check if a firmware upgrade is needed with <code>smartctl</code>.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ smartctl --all /dev/sd<b>X</b></pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">==&gt; WARNING: This drive may hang after 5184 hours of power-on time:
<a rel="nofollow" class="external free" href="https://www.tomshardware.com/news/Crucial-m4-Firmware-BSOD,14544.html">https://www.tomshardware.com/news/Crucial-m4-Firmware-BSOD,14544.html</a>
See the following web pages for firmware updates:
<a rel="nofollow" class="external free" href="http://www.crucial.com/support/firmware.aspx">http://www.crucial.com/support/firmware.aspx</a><sup title="Last check status: 404">[<a href="https://en.wikipedia.org/wiki/Wikipedia:Link_rot" class="extiw" title="wikipedia:Wikipedia:Link rot">dead link</a> 2020-08-04 ⓘ]</sup>
<a rel="nofollow" class="external free" href="http://www.micron.com/products/solid-state-storage/client-ssd#software">http://www.micron.com/products/solid-state-storage/client-ssd#software</a><sup title="Last check status: 404">[<a href="https://en.wikipedia.org/wiki/Wikipedia:Link_rot" class="extiw" title="wikipedia:Wikipedia:Link rot">dead link</a> 2020-08-04 ⓘ]</sup>
</pre>
<p>Users seeing this warning are advised to backup all sensible data and <b>consider upgrading immediately</b>.
</p>
<h3><span class="mw-headline" id="Kingston">Kingston</span></h3>
<p>Kingston has a Linux utilty to update the firmware of their Sandforce based drives.  It can be found on their <a rel="nofollow" class="external text" href="https://www.kingston.com/us/support">support page</a>.
</p>
<h3><span class="mw-headline" id="Mushkin">Mushkin</span></h3>
<p>The lesser known Mushkin brand Solid State drives also use Sandforce controllers, and have a Linux utility (nearly identical to Kingston's) to update the firmware.
</p>
<h3><span class="mw-headline" id="OCZ">OCZ</span></h3>
<p>OCZ has a command line utility available for Linux (i686 and x86_64) on their forum <a rel="nofollow" class="external text" href="https://www.ocztechnology.com/ssd_tools/">here</a>.
</p>
<h3><span class="mw-headline" id="Samsung">Samsung</span></h3>
<p>Samsung notes that update methods other than by using their Magician Software is "not supported", but it is possible. Apparently the Magician Software can be used to make a USB drive bootable with the firmware update.  The easiest method, though, is to use the bootable ISO images they provide for updating the firmware. They can be grabbed from <a rel="nofollow" class="external text" href="https://www.samsung.com/global/business/semiconductor/samsungssd/downloads.html">here</a>.
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> Samsung does not make it obvious at all that they actually provide these. They seem to have 4 different firmware update pages each referencing different ways of doing things.</div>
<h3><span class="mw-headline" id="SanDisk">SanDisk</span></h3>
<p>SanDisk makes <b>ISO firmware images</b> to allow SSD firmware update on operating systems that are unsupported by their SanDisk SSD Toolkit. One must choose the firmware for the right <i>SSD model</i>, as well as for the <i>capacity</i> that it has (e.g. 60GB, <b>or</b> 256GB). After burning the adequate ISO firmware image, simply restart the PC to boot with the newly created CD/DVD boot disk (may work from a USB stick.
</p>
<p>The iso images just contain a linux kernel and an initrd. Extract them to <code>/boot</code> partition and boot them with <a href="/title/GRUB" title="GRUB">GRUB</a> or <a href="/title/Syslinux" title="Syslinux">Syslinux</a> to update the firmware.
</p>
<p>I could not find a single page listing the firmware updates yet (site is a mess IMHO), but here are some relevant links:
</p>
<p>SanDisk Extreme SSD <a rel="nofollow" class="external text" href="https://kb.sandisk.com/app/answers/detail/a_id/10127">Firmware Release notes</a> and <a rel="nofollow" class="external text" href="https://kb.sandisk.com/app/answers/detail/a_id/10476">Manual Firmware update version R211</a> 
</p>
<p>SanDisk Ultra SSD <a rel="nofollow" class="external text" href="https://kb.sandisk.com/app/answers/detail/a_id/10192">Firmware release notes</a> and <a rel="nofollow" class="external text" href="https://kb.sandisk.com/app/answers/detail/a_id/10477">Manual Firmware update version 365A13F0</a>
</p>
<h2><span class="mw-headline" id="See_also">See also</span></h2>
<ul>
<li><a rel="nofollow" class="external text" href="https://www.reddit.com/r/archlinux/comments/rkwjm/what_should_i_keep_in_mind_when_installing_on_ssd/">Discussion on Reddit about installing Arch on an SSD</a></li>
<li>See the <a href="/title/Flashcache" title="Flashcache">Flashcache</a> article for advanced information on using solid-state with rotational drives for top performance.</li>
<li>
<a rel="nofollow" class="external text" href="https://lifehacker.com/5837769/make-sure-your-partitions-are-correctly-aligned-for-optimal-solid-state-drive-performance">Speed Up Your SSD By Correctly Aligning Your Partitions</a> (using GParted)</li>
<li><a rel="nofollow" class="external text" href="http://permalink.gmane.org/gmane.comp.file-systems.btrfs/19446">Re: Varying Leafsize and Nodesize in Btrfs</a></li>
<li><a rel="nofollow" class="external text" href="http://thread.gmane.org/gmane.comp.file-systems.btrfs/19650/focus=19667">Re: SSD alignment and Btrfs sector size</a></li>
<li>
<a rel="nofollow" class="external text" href="http://forums.anandtech.com/showthread.php?t=2266113">Erase Block (Alignment) Misinformation?</a><sup title="Last check status: 404">[<a href="https://en.wikipedia.org/wiki/Wikipedia:Link_rot" class="extiw" title="wikipedia:Wikipedia:Link rot">dead link</a> 2020-08-04 ⓘ]</sup>
</li>
<li><a rel="nofollow" class="external text" href="https://superuser.com/questions/492084/is-alignment-to-erase-block-size-needed-for-modern-ssds">Is alignment to erase block size needed for modern SSD's?</a></li>
<li><a rel="nofollow" class="external text" href="http://thread.gmane.org/gmane.comp.file-systems.btrfs/15646">Btrfs support for efficient SSD operation (data blocks alignment)</a></li>
<li><a rel="nofollow" class="external text" href="https://serverfault.com/questions/356534/ssd-erase-block-size-lvm-pv-on-raw-device-alignment">SSD, Erase Block Size &amp; LVM: PV on raw device, Alignment</a></li>
</ul>
</div>
</div>
<div id="catlinks" class="catlinks" data-mw="interface">
<div id="mw-normal-catlinks" class="mw-normal-catlinks">
<a href="/title/Special:Categories" title="Special:Categories">Category</a>: <ul><li><a href="/title/Category:Storage_(%E6%AD%A3%E9%AB%94%E4%B8%AD%E6%96%87)" title="Category:Storage (正體中文)">Storage (正體中文)</a></li></ul>
</div>
<div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul>
<li><a href="/title/Category:Pages_with_dead_links" title="Category:Pages with dead links">Pages with dead links</a></li>
<li><a href="/title/Category:Pages_or_sections_flagged_with_Template:Out_of_date" title="Category:Pages or sections flagged with Template:Out of date">Pages or sections flagged with Template:Out of date</a></li>
<li><a href="/title/Category:Pages_with_broken_section_links" title="Category:Pages with broken section links">Pages with broken section links</a></li>
</ul>
</div>
</div>
	</div>
</div>

<footer id="footer" class="mw-footer" role="contentinfo" style="margin: 0">
	<ul id="footer-info">
		<li>Retrieved from "<a dir="ltr" href="https://wiki.archlinux.org/index.php?title=Solid_state_drive_(%E6%AD%A3%E9%AB%94%E4%B8%AD%E6%96%87)&amp;oldid=669390">https://wiki.archlinux.org/index.php?title=Solid_state_drive_(正體中文)&amp;oldid=669390</a>"</li>
		<li id="footer-info-lastmod"> This page was last edited on 8 May 2021, at 11:46.</li>
		<li id="footer-info-copyright">Content is available under <a class="external" rel="nofollow" href="http://www.gnu.org/copyleft/fdl.html">GNU Free Documentation License 1.3 or later</a> unless otherwise noted.</li>
	<br>
</ul>
	<ul id="footer-places">
		<li id="footer-places-privacy"><a href="/title/ArchWiki:Privacy_policy" title="ArchWiki:Privacy policy">Privacy policy</a></li>
		<li id="footer-places-about"><a href="/title/ArchWiki:About" title="ArchWiki:About">About ArchWiki</a></li>
		<li id="footer-places-disclaimer"><a href="/title/ArchWiki:General_disclaimer" title="ArchWiki:General disclaimer">Disclaimers</a></li>
	</ul>
	<ul id="footer-icons" class="noprint">
		<li id="footer-copyrightico">
	</ul>
	<div style="clear: both;"></div>
</footer>



</body>
</html>
