<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<title>LVM - ArchWiki</title>
<link rel="stylesheet" href="../ArchWikiOffline.css">
<meta name="ResourceLoaderDynamicStyles" content="">
<meta name="generator" content="MediaWiki 1.35.0">
<meta name="referrer" content="no-referrer-when-downgrade">
<meta name="robots" content="noindex,follow">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="shortcut icon" href="/favicon.ico">
<link rel="search" type="application/opensearchdescription+xml" href="/opensearch_desc.php" title="ArchWiki (en)">
<link rel="EditURI" type="application/rsd+xml" href="https://wiki.archlinux.org/api.php?action=rsd">
<link rel="license" href="http://www.gnu.org/copyleft/fdl.html">
<link rel="alternate" type="application/atom+xml" title="ArchWiki Atom feed" href="/index.php?title=Special:RecentChanges&amp;feed=atom">
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-LVM rootpage-LVM skin-vector action-view skin-vector-legacy">
<div id="content" class="mw-body" role="main" style="margin: 0">
	<a id="top"></a>
	<div id="siteNotice" class="mw-body-content"></div>
	<div class="mw-indicators mw-body-content">
	</div>
	<h1 id="firstHeading" class="firstHeading" lang="en">LVM</h1>
	<div id="bodyContent" class="mw-body-content">
		<div id="siteSub" class="noprint">From ArchWiki</div>
		<div id="contentSub"></div>
		<div id="contentSub2"></div>
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#searchInput">Jump to search</a>
		<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr">
<div class="warningbox">The printable version is no longer supported and may have rendering errors. Please update your browser bookmarks and please use the default browser print function instead.</div>
<div class="mw-parser-output">
<div class="archwiki-template-meta-related-articles-start">
<p>Related articles</p>
<ul>
<li><a href="/title/Install_Arch_Linux_on_LVM" title="Install Arch Linux on LVM">Install Arch Linux on LVM</a></li>
<li><a href="/title/LVM_on_software_RAID" title="LVM on software RAID">LVM on software RAID</a></li>
<li><a href="/title/Dm-crypt/Encrypting_an_entire_system#LVM_on_LUKS" title="Dm-crypt/Encrypting an entire system">dm-crypt/Encrypting an entire system#LVM on LUKS</a></li>
<li><a href="/title/Dm-crypt/Encrypting_an_entire_system#LUKS_on_LVM" title="Dm-crypt/Encrypting an entire system">dm-crypt/Encrypting an entire system#LUKS on LVM</a></li>
<li><a href="/title/Resizing_LVM-on-LUKS" title="Resizing LVM-on-LUKS">Resizing LVM-on-LUKS</a></li>
<li><a href="/title/Create_root_filesystem_snapshots_with_LVM" title="Create root filesystem snapshots with LVM">Create root filesystem snapshots with LVM</a></li>
</ul>
</div>
<p>From <a href="https://en.wikipedia.org/wiki/Logical_Volume_Manager_(Linux)" class="extiw" title="wikipedia:Logical Volume Manager (Linux)">Wikipedia:Logical Volume Manager (Linux)</a>:
</p>
<dl><dd>LVM is a <a href="https://en.wikipedia.org/wiki/logical_volume_management" class="extiw" title="wikipedia:logical volume management">logical volume manager</a> for the <a href="https://en.wikipedia.org/wiki/Linux_kernel" class="extiw" title="wikipedia:Linux kernel">Linux kernel</a>; it manages disk drives and similar mass-storage devices.</dd></dl>
<div id="toc" class="toc" role="navigation" aria-labelledby="mw-toc-heading">
<input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none"><div class="toctitle" lang="en" dir="ltr">
<h2 id="mw-toc-heading">Contents</h2>
<span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span>
</div>
<ul>
<li class="toclevel-1 tocsection-1">
<a href="#Background"><span class="tocnumber">1</span> <span class="toctext">Background</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#LVM_building_blocks"><span class="tocnumber">1.1</span> <span class="toctext">LVM building blocks</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="#Advantages"><span class="tocnumber">1.2</span> <span class="toctext">Advantages</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#Disadvantages"><span class="tocnumber">1.3</span> <span class="toctext">Disadvantages</span></a></li>
<li class="toclevel-2 tocsection-5"><a href="#Getting_started"><span class="tocnumber">1.4</span> <span class="toctext">Getting started</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-6">
<a href="#Volume_operations"><span class="tocnumber">2</span> <span class="toctext">Volume operations</span></a>
<ul>
<li class="toclevel-2 tocsection-7">
<a href="#Physical_volumes"><span class="tocnumber">2.1</span> <span class="toctext">Physical volumes</span></a>
<ul>
<li class="toclevel-3 tocsection-8"><a href="#Creating"><span class="tocnumber">2.1.1</span> <span class="toctext">Creating</span></a></li>
<li class="toclevel-3 tocsection-9"><a href="#Growing"><span class="tocnumber">2.1.2</span> <span class="toctext">Growing</span></a></li>
<li class="toclevel-3 tocsection-10">
<a href="#Shrinking"><span class="tocnumber">2.1.3</span> <span class="toctext">Shrinking</span></a>
<ul>
<li class="toclevel-4 tocsection-11"><a href="#Move_physical_extents"><span class="tocnumber">2.1.3.1</span> <span class="toctext">Move physical extents</span></a></li>
<li class="toclevel-4 tocsection-12"><a href="#Resize_physical_volume"><span class="tocnumber">2.1.3.2</span> <span class="toctext">Resize physical volume</span></a></li>
<li class="toclevel-4 tocsection-13"><a href="#Resize_partition"><span class="tocnumber">2.1.3.3</span> <span class="toctext">Resize partition</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-2 tocsection-14">
<a href="#Volume_groups"><span class="tocnumber">2.2</span> <span class="toctext">Volume groups</span></a>
<ul>
<li class="toclevel-3 tocsection-15"><a href="#Creating_a_volume_group"><span class="tocnumber">2.2.1</span> <span class="toctext">Creating a volume group</span></a></li>
<li class="toclevel-3 tocsection-16"><a href="#Activating_a_volume_group"><span class="tocnumber">2.2.2</span> <span class="toctext">Activating a volume group</span></a></li>
<li class="toclevel-3 tocsection-17"><a href="#Repairing_a_volume_group"><span class="tocnumber">2.2.3</span> <span class="toctext">Repairing a volume group</span></a></li>
<li class="toclevel-3 tocsection-18"><a href="#Deactivating_a_volume_group"><span class="tocnumber">2.2.4</span> <span class="toctext">Deactivating a volume group</span></a></li>
<li class="toclevel-3 tocsection-19"><a href="#Renaming_a_volume_group"><span class="tocnumber">2.2.5</span> <span class="toctext">Renaming a volume group</span></a></li>
<li class="toclevel-3 tocsection-20"><a href="#Add_physical_volume_to_a_volume_group"><span class="tocnumber">2.2.6</span> <span class="toctext">Add physical volume to a volume group</span></a></li>
<li class="toclevel-3 tocsection-21"><a href="#Remove_partition_from_a_volume_group"><span class="tocnumber">2.2.7</span> <span class="toctext">Remove partition from a volume group</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-22">
<a href="#Logical_volumes"><span class="tocnumber">2.3</span> <span class="toctext">Logical volumes</span></a>
<ul>
<li class="toclevel-3 tocsection-23"><a href="#Creating_a_logical_volume"><span class="tocnumber">2.3.1</span> <span class="toctext">Creating a logical volume</span></a></li>
<li class="toclevel-3 tocsection-24"><a href="#Renaming_a_logical_volume"><span class="tocnumber">2.3.2</span> <span class="toctext">Renaming a logical volume</span></a></li>
<li class="toclevel-3 tocsection-25"><a href="#Resizing_the_logical_volume_and_file_system_in_one_go"><span class="tocnumber">2.3.3</span> <span class="toctext">Resizing the logical volume and file system in one go</span></a></li>
<li class="toclevel-3 tocsection-26"><a href="#Resizing_the_logical_volume_and_file_system_separately"><span class="tocnumber">2.3.4</span> <span class="toctext">Resizing the logical volume and file system separately</span></a></li>
<li class="toclevel-3 tocsection-27"><a href="#Removing_a_logical_volume"><span class="tocnumber">2.3.5</span> <span class="toctext">Removing a logical volume</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-28">
<a href="#Logical_volume_types"><span class="tocnumber">3</span> <span class="toctext">Logical volume types</span></a>
<ul>
<li class="toclevel-2 tocsection-29">
<a href="#Snapshots"><span class="tocnumber">3.1</span> <span class="toctext">Snapshots</span></a>
<ul>
<li class="toclevel-3 tocsection-30"><a href="#Configuration"><span class="tocnumber">3.1.1</span> <span class="toctext">Configuration</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-31">
<a href="#Cache"><span class="tocnumber">3.2</span> <span class="toctext">Cache</span></a>
<ul>
<li class="toclevel-3 tocsection-32"><a href="#Create_cache"><span class="tocnumber">3.2.1</span> <span class="toctext">Create cache</span></a></li>
<li class="toclevel-3 tocsection-33"><a href="#Remove_cache"><span class="tocnumber">3.2.2</span> <span class="toctext">Remove cache</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-34">
<a href="#RAID"><span class="tocnumber">3.3</span> <span class="toctext">RAID</span></a>
<ul>
<li class="toclevel-3 tocsection-35"><a href="#Setup_RAID"><span class="tocnumber">3.3.1</span> <span class="toctext">Setup RAID</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-36">
<a href="#Thin_provisioning"><span class="tocnumber">4</span> <span class="toctext">Thin provisioning</span></a>
<ul>
<li class="toclevel-2 tocsection-37">
<a href="#Example:_implementing_virtual_private_servers"><span class="tocnumber">4.1</span> <span class="toctext">Example: implementing virtual private servers</span></a>
<ul>
<li class="toclevel-3 tocsection-38"><a href="#Use_thin_snapshots_to_save_more_space"><span class="tocnumber">4.1.1</span> <span class="toctext">Use thin snapshots to save more space</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-39"><a href="#Example:_zero-downtime_storage_upgrade"><span class="tocnumber">4.2</span> <span class="toctext">Example: zero-downtime storage upgrade</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-40">
<a href="#Troubleshooting"><span class="tocnumber">5</span> <span class="toctext">Troubleshooting</span></a>
<ul>
<li class="toclevel-2 tocsection-41"><a href="#LVM_commands_do_not_work"><span class="tocnumber">5.1</span> <span class="toctext">LVM commands do not work</span></a></li>
<li class="toclevel-2 tocsection-42"><a href="#Logical_Volumes_do_not_show_up"><span class="tocnumber">5.2</span> <span class="toctext">Logical Volumes do not show up</span></a></li>
<li class="toclevel-2 tocsection-43">
<a href="#LVM_on_removable_media"><span class="tocnumber">5.3</span> <span class="toctext">LVM on removable media</span></a>
<ul>
<li class="toclevel-3 tocsection-44"><a href="#Suspend/resume_with_LVM_and_removable_media"><span class="tocnumber">5.3.1</span> <span class="toctext">Suspend/resume with LVM and removable media</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-45"><a href="#Resizing_a_contiguous_logical_volume_fails"><span class="tocnumber">5.4</span> <span class="toctext">Resizing a contiguous logical volume fails</span></a></li>
<li class="toclevel-2 tocsection-46"><a href="#Command_%22grub-mkconfig%22_reports_%22unknown_filesystem%22_errors"><span class="tocnumber">5.5</span> <span class="toctext">Command "grub-mkconfig" reports "unknown filesystem" errors</span></a></li>
<li class="toclevel-2 tocsection-47"><a href="#Thinly-provisioned_root_volume_device_times_out"><span class="tocnumber">5.6</span> <span class="toctext">Thinly-provisioned root volume device times out</span></a></li>
<li class="toclevel-2 tocsection-48"><a href="#Delay_on_shutdown"><span class="tocnumber">5.7</span> <span class="toctext">Delay on shutdown</span></a></li>
<li class="toclevel-2 tocsection-49"><a href="#Hibernating_into_a_thinly-provisioned_swap_volume"><span class="tocnumber">5.8</span> <span class="toctext">Hibernating into a thinly-provisioned swap volume</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-50"><a href="#See_also"><span class="tocnumber">6</span> <span class="toctext">See also</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Background">Background</span></h2>
<h3><span class="mw-headline" id="LVM_building_blocks">LVM building blocks</span></h3>
<p>Logical Volume Management utilizes the kernel's <a rel="nofollow" class="external text" href="http://sources.redhat.com/dm/">device-mapper</a> feature to provide a system of <a href="/title/Partition" class="mw-redirect" title="Partition">partitions</a> independent of underlying disk layout. With LVM you abstract your storage and have "virtual partitions", making <a href="#Resizing_the_logical_volume_and_file_system_separately">extending/shrinking</a> easier (subject to potential filesystem limitations).
</p>
<p>Virtual partitions allow addition and removal without worry of whether you have enough contiguous space on a particular disk, getting caught up fdisking a disk in use (and wondering whether the kernel is using the old or new partition table), or, having to move other partitions out of the way.
</p>
<p>Basic building blocks of LVM:
</p>
<dl>
<dt>Physical volume (PV)</dt>
<dd>Unix block device node, usable for storage by LVM. Examples: a hard disk, an <a href="/title/MBR" class="mw-redirect" title="MBR">MBR</a> or <a href="/title/GPT" class="mw-redirect" title="GPT">GPT</a> partition, a loopback file, a device mapper device (e.g. <a href="/title/Dm-crypt" title="Dm-crypt">dm-crypt</a>). It hosts an LVM header.</dd>
<dt>Volume group (VG)</dt>
<dd>Group of PVs that serves as a container for LVs. PEs are allocated from a VG for a LV.</dd>
<dt>Logical volume (LV)</dt>
<dd>"Virtual/logical partition" that resides in a VG and is composed of PEs. LVs are Unix block devices analogous to physical partitions, e.g. they can be directly formatted with a <a href="/title/File_system" class="mw-redirect" title="File system">file system</a>.</dd>
<dt>Physical extent (PE)</dt>
<dd>The smallest contiguous extent (default 4 MiB) in the PV that can be assigned to a LV. Think of PEs as parts of PVs that can be allocated to any LV.</dd>
</dl>
<p>Example:
</p>
<pre style="white-space: pre !important; font-variant-ligatures: no-common-ligatures;">Physical disks

  Disk1 (/dev/sda):
     _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
    |Partition1 50 GiB (Physical volume) |Partition2 80 GiB (Physical volume)     |
    |/dev/sda1                           |/dev/sda2                               |
    |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ |

  Disk2 (/dev/sdb):
     _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
    |Partition1 120 GiB (Physical volume)                 |
    |/dev/sdb1                                            |
    |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _|
</pre>
<pre style="white-space: pre !important; font-variant-ligatures: no-common-ligatures;">LVM logical volumes

  Volume Group1 (/dev/MyVolGroup/ = /dev/sda1 + /dev/sda2 + /dev/sdb1):
     _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
    |Logical volume1 15 GiB  |Logical volume2 35 GiB      |Logical volume3 200 GiB              |
    |/dev/MyVolGroup/rootvol |/dev/MyVolGroup/homevol     |/dev/MyVolGroup/mediavol             |
    |_ _ _ _ _ _ _ _ _ _ _ _ |_ _ _ _ _ _ _ _ _ _ _ _ _ _ |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _|
</pre>
<h3><span class="mw-headline" id="Advantages">Advantages</span></h3>
<p>LVM gives you more flexibility than just using normal hard drive partitions:
</p>
<ul>
<li>Use any number of disks as one big disk.</li>
<li>Have logical volumes stretched over several disks.</li>
<li>Create small logical volumes and resize them "dynamically" as they get filled up.</li>
<li>Resize logical volumes regardless of their order on disk. It does not depend on the position of the LV within VG, there is no need to ensure surrounding available space.</li>
<li>Resize/create/delete logical and physical volumes online. File systems on them still need to be resized, but some (such as ext4) support online resizing.</li>
<li>Online/live migration of LV being used by services to different disks without having to restart services.</li>
<li>Snapshots allow you to backup a frozen copy of the file system, while keeping service downtime to a minimum.</li>
<li>Support for various device-mapper targets, including transparent filesystem encryption and caching of frequently used data. This allows creating a system with (one or more) physical disks (encrypted with LUKS) and <a href="/title/Dm-crypt/Encrypting_an_entire_system#LVM_on_LUKS" title="Dm-crypt/Encrypting an entire system">LVM on top</a> to allow for easy resizing and management of separate volumes (e.g. for <code>/</code>, <code>/home</code>, <code>/backup</code>, etc.) without the hassle of entering a key multiple times on boot.</li>
</ul>
<h3><span class="mw-headline" id="Disadvantages">Disadvantages</span></h3>
<ul>
<li>Additional steps in setting up the system, more complicated. Requires (multiple) daemons to constantly run.</li>
<li>If dual-booting, note that Windows does not support LVM; you will be unable to access any LVM partitions from Windows.</li>
<li>If your physical volumes are not on a RAID-1, RAID-5 or RAID-6 losing one disk <i>can</i> lose one or more logical volumes if you span (or extend) your logical volumes across multiple non-redundant disks.</li>
</ul>
<h3><span class="mw-headline" id="Getting_started">Getting started</span></h3>
<p>Make sure the <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=lvm2">lvm2</a></span> package is <a href="/title/Install" class="mw-redirect" title="Install">installed</a>.
</p>
<h2><span class="mw-headline" id="Volume_operations">Volume operations</span></h2>
<h3><span class="mw-headline" id="Physical_volumes">Physical volumes</span></h3>
<h4><span class="mw-headline" id="Creating">Creating</span></h4>
<p>To create a PV on <code>/dev/sda1</code>, run:
</p>
<pre># pvcreate /dev/sda1
</pre>
<p>You can check the PV is created using the following command:
</p>
<pre># pvs
</pre>
<h4><span class="mw-headline" id="Growing">Growing</span></h4>
<p>After extending or prior to reducing the size of a device that has a physical volume on it, you need to grow or shrink the PV using <code>pvresize</code>.
</p>
<p>To expand the PV on <code>/dev/sda1</code> after enlarging the <a href="/title/Partition" class="mw-redirect" title="Partition">partition</a>, run:
</p>
<pre># pvresize /dev/sda1
</pre>
<p>This will automatically detect the new size of the device and extend the PV to its maximum.
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> This command can be done while the volume is online.</div>
<h4><span class="mw-headline" id="Shrinking">Shrinking</span></h4>
<p>To shrink a physical volume prior to reducing its underlying device, add the <code>--setphysicalvolumesize <i>size</i></code> parameters to the command, <i>e.g.</i>:
</p>
<pre># pvresize --setphysicalvolumesize 40G /dev/sda1
</pre>
<p>The above command may leave you with this error:
</p>
<pre> /dev/sda1: cannot resize to 25599 extents as later ones are allocated.
 0 physical volume(s) resized / 1 physical volume(s) not resized
</pre>
<p>Indeed <code>pvresize</code> will refuse to shrink a PV if it has allocated extents after where its new end would be. One needs to run <a href="#Move_physical_extents">pvmove</a> beforehand to relocate these elsewhere in the volume group if there is sufficient free space.
</p>
<h5><span class="mw-headline" id="Move_physical_extents">Move physical extents</span></h5>
<p>Before moving free extents to the end of the volume, one must run <code>pvdisplay -v -m</code> to see physical segments. In the below example, there is one physical volume on <code>/dev/sdd1</code>, one volume group <code>vg1</code> and one logical volume <code>backup</code>.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># pvdisplay -v -m</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">    Finding all volume groups.
    Using physical volume(s) on command line.
  --- Physical volume ---
  PV Name               /dev/sdd1
  VG Name               vg1
  PV Size               1.52 TiB / not usable 1.97 MiB
  Allocatable           yes 
  PE Size               4.00 MiB
  Total PE              399669
  Free PE               153600
  Allocated PE          246069
  PV UUID               MR9J0X-zQB4-wi3k-EnaV-5ksf-hN1P-Jkm5mW
   
  --- Physical Segments ---
  Physical extent 0 to 153600:
    FREE
  Physical extent 153601 to 307199:
    Logical volume	/dev/vg1/backup
    Logical extents	1 to 153599
  Physical extent 307200 to 307200:
    FREE
  Physical extent 307201 to 399668:
    Logical volume	/dev/vg1/backup
    Logical extents	153601 to 246068
</pre>
<p>One can observe FREE space are split across the volume. To shrink the physical volume, we must first move all used segments to the beginning.
</p>
<p>Here, the first free segment is from 0 to 153600 and leaves us with 153601 free extents. We can now move this segment number from the last physical extent to the first extent. The command will thus be:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># pvmove --alloc anywhere /dev/sdd1:307201-399668 /dev/sdd1:0-92467</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">/dev/sdd1: Moved: 0.1 %
/dev/sdd1: Moved: 0.2 %
...
/dev/sdd1: Moved: 99.9 %
/dev/sdd1: Moved: 100.0 %
</pre>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> 
<ul>
<li>this command moves 399668 - 307201 + 1 = 92468 PEs <b>from</b> the last segment <b>to</b> the first segment. This is possible as the first segment encloses 153600 free PEs, which can contain the 92467 - 0 + 1 = 92468 moved PEs.</li>
<li>the <code>--alloc anywhere</code> option is used as we move PEs inside the same partition. In case of different partitions, the command would look something like this: <pre># pvmove /dev/sdb1:1000-1999 /dev/sdc1:0-999</pre>
</li>
<li>this command may take a long time (one to two hours) in case of large volumes. It might be a good idea to run this command in a <a href="/title/Tmux" title="Tmux">Tmux</a> or <a href="/title/GNU_Screen" title="GNU Screen">GNU Screen</a> session. Any unwanted stop of the process could be fatal.</li>
<li>once the operation is complete, run <a href="/title/Fsck" title="Fsck">fsck</a> to make sure your file system is valid.</li>
</ul>
</div>
<h5><span class="mw-headline" id="Resize_physical_volume">Resize physical volume</span></h5>
<p>Once all your free physical segments are on the last physical extents, run <code>vgdisplay</code> and see your free PE.
</p>
<p>Then you can now run again the command:
</p>
<pre># pvresize --setphysicalvolumesize <i>size</i> <i>PhysicalVolume</i>
</pre>
<p>See the result:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># pvs</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">  PV         VG   Fmt  Attr PSize    PFree 
  /dev/sdd1  vg1  lvm2 a--     1t     500g
</pre>
<h5><span class="mw-headline" id="Resize_partition">Resize partition</span></h5>
<p>Last, you need to shrink the partition with your favorite <a href="/title/Partitioning#Partitioning_tools" title="Partitioning">partitioning tool</a>.
</p>
<h3><span class="mw-headline" id="Volume_groups">Volume groups</span></h3>
<h4><span class="mw-headline" id="Creating_a_volume_group">Creating a volume group</span></h4>
<p>To create a VG <code>MyVolGroup</code> with an associated PV <code>/dev/sdb1</code>, run:
</p>
<pre># vgcreate MyVolGroup /dev/sdb1
</pre>
<p>You can check the VG <code>MyVolGroup</code> is created using the following command:
</p>
<pre># vgs
</pre>
<p>You can bind multiple PVs when creating a VG like this:
</p>
<pre># vgcreate MyVolGroup /dev/sdb1 /dev/sdb2
</pre>
<h4><span class="mw-headline" id="Activating_a_volume_group">Activating a volume group</span></h4>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> You can restrict the volumes that are activated automatically by setting the <code>auto_activation_volume_list</code> in <code>/etc/lvm/lvm.conf</code>. If in doubt, leave this option commented out.</div>
<pre># vgchange -a y MyVolGroup
</pre>
<p>This will reactivate the volume group if for example you had a drive failure in a mirror and you swapped the drive, ran <code>pvcreate</code>, <code>vgextend</code> and <code>vgreduce --removemissing --force</code>.
</p>
<h4><span class="mw-headline" id="Repairing_a_volume_group">Repairing a volume group</span></h4>
<p>To start the rebuilding process of the degraded mirror array in this example, you would run:
</p>
<pre># lvconvert --repair /dev/MyVolGroup/mirror
</pre>
<p>You can monitor the rebuilding process (Cpy%Sync Column output) with:
</p>
<pre># lvs -a -o +devices
</pre>
<h4><span class="mw-headline" id="Deactivating_a_volume_group">Deactivating a volume group</span></h4>
<p>Just invoke 
</p>
<pre># vgchange -a n MyVolGroup
</pre>
<p>This will deactivate the volume group and allow you to unmount the container it is stored in.
</p>
<h4><span class="mw-headline" id="Renaming_a_volume_group">Renaming a volume group</span></h4>
<p>Use the <span class="plainlinks archwiki-template-man" title="$ man 8 vgrename"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/vgrename.8">vgrename(8)</a></span> command to rename an existing volume group.
</p>
<p>Either of the following commands renames the existing volume group <code>MyVolGroup</code> to <code>my_volume_group</code>
</p>
<pre># vgrename /dev/MyVolGroup /dev/my_volume_group
</pre>
<pre># vgrename MyVolGroup my_volume_group
</pre>
<p>Make sure to update all configuration files (e.g. <code>/etc/fstab</code> or <code>/etc/crypttab</code>) that reference the renamed volume group.
</p>
<h4><span class="mw-headline" id="Add_physical_volume_to_a_volume_group">Add physical volume to a volume group</span></h4>
<p>You first create a new physical volume on the block device you wish to use, then extend your volume group
</p>
<pre># pvcreate /dev/sdb1
# vgextend MyVolGroup /dev/sdb1
</pre>
<p>This of course will increase the total number of physical extents on your volume group, which can be allocated by logical volumes as you see fit.
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> It is considered good form to have a <a href="/title/Partition_table" class="mw-redirect" title="Partition table">partition table</a> on your storage medium below LVM. Use the appropriate partition type: <code>8e</code> for MBR, and <code>E6D6D379-F507-44C2-A23C-238F2A3DF928</code> for GPT partitions.</div>
<h4><span class="mw-headline" id="Remove_partition_from_a_volume_group">Remove partition from a volume group</span></h4>
<p>If you created a logical volume on the partition, <a href="#Removing_a_logical_volume">remove</a> it first.
</p>
<p>All of the data on that partition needs to be moved to another partition. Fortunately, LVM makes this easy:
</p>
<pre># pvmove /dev/sdb1
</pre>
<p>If you want to have the data on a specific physical volume, specify that as the second argument to <code>pvmove</code>:
</p>
<pre># pvmove /dev/sdb1 /dev/sdf1
</pre>
<p>Then the physical volume needs to be removed from the volume group:
</p>
<pre># vgreduce MyVolGroup /dev/sdb1
</pre>
<p>Or remove all empty physical volumes:
</p>
<pre># vgreduce --all MyVolGroup
</pre>
<p>For example: if you have a bad disk in a group that cannot be found because it has been removed or failed:
</p>
<pre># vgreduce --removemissing --force MyVolGroup
</pre>
<p>And lastly, if you want to use the partition for something else, and want to avoid LVM thinking that the partition is a physical volume:
</p>
<pre># pvremove /dev/sdb1
</pre>
<h3><span class="mw-headline" id="Logical_volumes">Logical volumes</span></h3>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> <span class="plainlinks archwiki-template-man" title="$ man 8 lvresize"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/lvresize.8">lvresize(8)</a></span> provides more or less the same options as the specialized <span class="plainlinks archwiki-template-man" title="$ man 8 lvextend"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/lvextend.8">lvextend(8)</a></span> and <span class="plainlinks archwiki-template-man" title="$ man 8 lvreduce"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/lvreduce.8">lvreduce(8)</a></span> commands, while allowing to do both types of operation. Notwithstanding this, all those utilities offer a <code>-r</code>/<code>--resizefs</code> option which allows to resize the file system together with the LV using <span class="plainlinks archwiki-template-man" title="$ man 8 fsadm"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/fsadm.8">fsadm(8)</a></span> (<i>ext2</i>, <a href="/title/Ext3" title="Ext3">ext3</a>, <a href="/title/Ext4" title="Ext4">ext4</a>, <i>ReiserFS</i> and <a href="/title/XFS" title="XFS">XFS</a> supported). Therefore it may be easier to simply use <code>lvresize</code> for both operations and use <code>--resizefs</code> to simplify things a bit, except if you have specific needs or want full control over the process.</div>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>Warning:</strong> While enlarging a file system can often be done on-line (<i>i.e.</i> while it is mounted), even for the root partition, shrinking will nearly always require to first unmount the file system so as to prevent data loss. Make sure your file system supports what you are trying to do.</div>
<h4><span class="mw-headline" id="Creating_a_logical_volume">Creating a logical volume</span></h4>
<p>To create a LV <code>homevol</code> in a VG <code>MyVolGroup</code> with 300GB of capacity, run:
</p>
<pre># lvcreate -L 300G MyVolGroup -n homevol
</pre>
<p>or, to create a LV <code>homevol</code> in a VG <code>MyVolGroup</code> with the rest of capacity, run:
</p>
<pre># lvcreate -l +100%FREE MyVolGroup -n homevol
</pre>
<p>The new LV will appear as <code>/dev/MyVolGroup/homevol</code>. Now you can <a href="/title/Format" class="mw-redirect" title="Format">format</a> the LV with an appropriate file system.
</p>
<p>You can check the LV is created using the following command:
</p>
<pre># lvs
</pre>
<h4><span class="mw-headline" id="Renaming_a_logical_volume">Renaming a logical volume</span></h4>
<p>To rename an existing logical volume, use the <span class="plainlinks archwiki-template-man" title="$ man 8 lvrename"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/lvrename.8">lvrename(8)</a></span> command.
</p>
<p>Either of the following commands renames logical volume <code>old_vol</code> in volume group <code>MyVolGroup</code> to <code>new_vol</code>.
</p>
<pre># lvrename /dev/MyVolGroup/old_vol /dev/MyVolGroup/new_vol
</pre>
<pre># lvrename MyVolGroup old_vol new_vol
</pre>
<p>Make sure to update all configuration files (e.g. <code>/etc/fstab</code> or <code>/etc/crypttab</code>) that reference the renamed logical volume.
</p>
<h4><span class="mw-headline" id="Resizing_the_logical_volume_and_file_system_in_one_go">Resizing the logical volume and file system in one go</span></h4>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> Only <i>ext2</i>, <a href="/title/Ext3" title="Ext3">ext3</a>, <a href="/title/Ext4" title="Ext4">ext4</a>, <i>ReiserFS</i> and <a href="/title/XFS" title="XFS">XFS</a> <a href="/title/File_systems" title="File systems">file systems</a> are supported. For a different type of file system see <a href="#Resizing_the_logical_volume_and_file_system_separately">#Resizing the logical volume and file system separately</a>.</div>
<p>Extend the logical volume <code>mediavol</code> in <code>MyVolGroup</code> by 10 GiB  and resize its file system <i>all at once</i>:
</p>
<pre># lvresize -L +10G --resizefs MyVolGroup/mediavol
</pre>
<p>Set the size of logical volume <code>mediavol</code> in <code>MyVolGroup</code> to 15 GiB and resize its file system <i>all at once</i>:
</p>
<pre># lvresize -L 15G --resizefs MyVolGroup/mediavol
</pre>
<p>If you want to fill all the free space on a volume group, use the following command:
</p>
<pre># lvresize -l +100%FREE --resizefs MyVolGroup/mediavol
</pre>
<p>See <span class="plainlinks archwiki-template-man" title="$ man 8 lvresize"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/lvresize.8">lvresize(8)</a></span> for more detailed options.
</p>
<h4><span class="mw-headline" id="Resizing_the_logical_volume_and_file_system_separately">Resizing the logical volume and file system separately</span></h4>
<p>For file systems not supported by <span class="plainlinks archwiki-template-man" title="$ man 8 fsadm"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/fsadm.8">fsadm(8)</a></span> will need to use the <a href="/title/File_systems#Types_of_file_systems" title="File systems">appropriate utility</a> to resize the file system before shrinking the logical volume or after expanding it.
</p>
<p>To extend logical volume <code>mediavol</code> within volume group <code>MyVolGroup</code> by 2 GiB <i>without</i> touching its file system:
</p>
<pre># lvresize -L +2G MyVolGroup/mediavol
</pre>
<p>Now expand the file system (<a href="/title/Ext4" title="Ext4">ext4</a> in this example) to the maximum size of the underlying logical volume:
</p>
<pre># resize2fs /dev/MyVolGroup/mediavol
</pre>
<p>To reduce the size of logical volume <code>mediavol</code> in <code>MyVolGroup</code> by 500 MiB, first calculate the resulting file system size and shrink the file system (<a href="/title/Ext4" title="Ext4">ext4</a> in this example) to the new size:
</p>
<pre># resize2fs /dev/MyVolGroup/mediavol <i>NewSize</i>
</pre>
<p>When the file system is shrunk, reduce the size of logical volume:
</p>
<pre># lvresize -L -500M MyVolGroup/mediavol
</pre>
<p>To calculate the exact logical volume size for <i>ext2</i>, <a href="/title/Ext3" title="Ext3">ext3</a>, <a href="/title/Ext4" title="Ext4">ext4</a> file systems, use a simple formula: <code>LVM_EXTENTS = FS_BLOCKS × FS_BLOCKSIZE ÷ LVM_EXTENTSIZE</code>.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># tune2fs -l /dev/MyVolGroup/mediavol | grep Block</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">Block count:              102400000
Block size:               4096
Blocks per group:         32768
</pre>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># vgdisplay MyVolGroup | grep "PE Size"</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">PE Size               4.00 MiB
</pre>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> The file system block size is in bytes. Make sure to use the same units for both block and extent size.</div>
<pre>102400000 blocks × 4096 bytes/block ÷ 4 MiB/extent = 100000 extents
</pre>
<p>Passing <code>--resizefs</code> will confirm that the correctness.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># lvreduce -l 100000 --resizefs /dev/MyVolGroup/mediavol</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
The filesystem is already 102400000 (4k) blocks long.  Nothing to do!
...
Logical volume sysvg/root successfully resized.
</pre>
<p>See <span class="plainlinks archwiki-template-man" title="$ man 8 lvresize"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/lvresize.8">lvresize(8)</a></span> for more detailed options.
</p>
<h4><span class="mw-headline" id="Removing_a_logical_volume">Removing a logical volume</span></h4>
<div class="archwiki-template-box archwiki-template-box-warning">
<strong>Warning:</strong> Before you remove a logical volume, make sure to move all data that you want to keep somewhere else; otherwise, it will be lost!</div>
<p>First, find out the name of the logical volume you want to remove. You can get a list of all logical volumes with:
</p>
<pre># lvs
</pre>
<p>Next, look up the mountpoint of the chosen logical volume:
</p>
<pre>$ lsblk
</pre>
<p>Then unmount the filesystem on the logical volume:
</p>
<pre># umount /<i>mountpoint</i>
</pre>
<p>Finally, remove the logical volume:
</p>
<pre># lvremove <i>volume_group</i>/<i>logical_volume</i>
</pre>
<p>For example:
</p>
<pre># lvremove MyVolGroup/homevol
</pre>
<p>Confirm by typing in <code>y</code>.
</p>
<p>Make sure to update all configuration files (e.g. <code>/etc/fstab</code> or <code>/etc/crypttab</code>) that reference the removed logical volume.
</p>
<p>You can verify the removal of the logical volume by typing <code>lvs</code> as root again (see first step of this section).
</p>
<h2><span class="mw-headline" id="Logical_volume_types">Logical volume types</span></h2>
<p>Besides simple logical volumes, LVM supports snapshots, logical volume caching, thin provisioned logical volumes and RAID.
</p>
<h3><span class="mw-headline" id="Snapshots">Snapshots</span></h3>
<p>LVM allows you to take a snapshot of your system in a much more efficient way than a traditional backup. It does this efficiently by using a COW (copy-on-write) policy. The initial snapshot you take simply contains hard-links to the inodes of your actual data. So long as your data remains unchanged, the snapshot merely contains its inode pointers and not the data itself. Whenever you modify a file or directory that the snapshot points to, LVM automatically clones the data, the old copy referenced by the snapshot, and the new copy referenced by your active system. Thus, you can snapshot a system with 35 GiB of data using just 2 GiB of free space so long as you modify less than 2 GiB (on both the original and snapshot). In order to be able to create snapshots you need to have unallocated space in your volume group. Snapshot like any other volume will take up space in the volume group. So, if you plan to use snapshots for backing up your root partition do not allocate 100% of your volume group for root logical volume.
</p>
<h4><span class="mw-headline" id="Configuration">Configuration</span></h4>
<p>You create snapshot logical volumes just like normal ones.
</p>
<pre># lvcreate --size 100M --snapshot --name snap01vol /dev/MyVolGroup/lvol
</pre>
<p>With that volume, you may modify less than 100 MiB of data, before the snapshot volume fills up.
</p>
<p>Reverting the modified <code>lvol</code> logical volume to the state when the <code>snap01vol</code> snapshot was taken can be done with
</p>
<pre># lvconvert --merge /dev/MyVolGroup/snap01vol
</pre>
<p>In case the origin logical volume is active, merging will occur on the next reboot (merging can be done even from a LiveCD). 
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> The snapshot will no longer exist after merging.</div>
<p>Also multiple snapshots can be taken and each one can be merged with the origin logical volume at will.
</p>
<p>The snapshot can be mounted and backed up with <a href="/title/Dd" title="Dd">dd</a> or <a href="/title/Tar" class="mw-redirect" title="Tar">tar</a>. The size of the backup file done with <i>dd</i> will be the size of the files residing on the snapshot volume. 
To restore just create a snapshot, mount it, and write or extract the backup to it. And then merge it with the origin.
</p>
<div class="noprint archwiki-template-message">
<p><a href="/title/File:Tango-view-fullscreen.png" class="image"><img alt="Tango-view-fullscreen.png" src="../File:Tango-view-fullscreen.png" decoding="async" width="48" height="48"></a><b>This article or section needs expansion.</b><a href="/title/File:Tango-view-fullscreen.png" class="image"><img alt="Tango-view-fullscreen.png" src="../File:Tango-view-fullscreen.png" decoding="async" width="48" height="48"></a></p>
<div>
<b>Reason:</b> scripts to automate snapshots of root before updates, to rollback... updating <code>menu.lst</code> to boot snapshots (separate article?) (Discuss in <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/title/Talk:LVM">Talk:LVM#</a>)</div>
</div>
<p>Snapshots are primarily used to provide a frozen copy of a file system to make backups; a backup taking two hours provides a more consistent image of the file system than directly backing up the partition.
</p>
<p>See <a href="/title/Create_root_filesystem_snapshots_with_LVM" title="Create root filesystem snapshots with LVM">Create root filesystem snapshots with LVM</a> for automating the creation of clean root file system snapshots during system startup for backup and rollback.
</p>
<p><a href="/title/Dm-crypt/Encrypting_an_entire_system#LVM_on_LUKS" title="Dm-crypt/Encrypting an entire system">dm-crypt/Encrypting an entire system#LVM on LUKS</a> and <a href="/title/Dm-crypt/Encrypting_an_entire_system#LUKS_on_LVM" title="Dm-crypt/Encrypting an entire system">dm-crypt/Encrypting an entire system#LUKS on LVM</a>.
</p>
<p>If you have LVM volumes not activated via the <a href="/title/Initramfs" class="mw-redirect" title="Initramfs">initramfs</a>, <a href="/title/Enable" class="mw-redirect" title="Enable">enable</a> <code>lvm-monitoring.service</code>, which is provided by the <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://archlinux.org/packages/?name=lvm2">lvm2</a></span> package.
</p>
<h3><span class="mw-headline" id="Cache">Cache</span></h3>
<p>From <span class="plainlinks archwiki-template-man" title="$ man 7 lvmcache"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/lvmcache.7">lvmcache(7)</a></span>:
</p>
<dl><dd>The cache logical volume type uses a small and fast LV to improve the performance of a large and slow LV. It does this by storing the frequently used blocks on the faster LV. LVM refers to the small fast LV as a cache pool LV. The large slow LV is called the origin LV. Due to requirements from dm-cache (the kernel driver), LVM further splits the cache pool LV into two devices - the cache data LV and cache metadata LV. The cache data LV is where copies of data blocks are kept from the origin LV to increase speed. The cache metadata LV holds the accounting information that specifies where data blocks are stored (e.g. on the origin LV or on the cache data LV).  Users should be familiar with these LVs if they wish to create the best and most robust cached logical volumes. All of these associated LVs must be in the same VG.</dd></dl>
<h4><span class="mw-headline" id="Create_cache">Create cache</span></h4>
<p>Convert your fast disk (<code>/dev/<i>fastdisk</i></code>) to PV and add to your existing VG (<code>MyVolGroup</code>):
</p>
<pre># vgextend MyVolGroup /dev/<i>fastdisk</i>
</pre>
<p>Create a cache pool with automatic meta data on <code>/dev/<i>fastdisk</i></code> and convert the existing LV <code>MyVolGroup/rootvol</code> to a cached volume, all in one step:
</p>
<pre># lvcreate --type cache --cachemode writethrough -l 100%FREE -n root_cachepool MyVolGroup/rootvol /dev/<i>fastdisk</i>
</pre>
<div class="archwiki-template-box archwiki-template-box-tip">
<strong>Tip:</strong> Instead of using <code>-l 100%FREE</code> to allocate 100% of available space from PV <code>/dev/<i>fastdisk</i></code>, you can use <code>-L 20G</code> instead to allocate only 20GB for cachepool.</div>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> Cachemode has two possible options:
<ul>
<li>
<code>writethrough</code> ensures that any data written will be stored both in the cache pool LV and on the origin LV.  The loss of a device associated with the cache pool LV in this case would not mean the loss of any data;</li>
<li>
<code>writeback</code> ensures better performance, but at the cost of a higher risk of data loss in case the drive used for cache fails.</li>
</ul>
<p>If a specific <code>--cachemode</code> is not indicated, the system will assume <code>writethrough</code> as default.
</p>
</div>
<h4><span class="mw-headline" id="Remove_cache">Remove cache</span></h4>
<p>If you ever need to undo the one step creation operation above:
</p>
<pre># lvconvert --uncache MyVolGroup/rootvol
</pre>
<p>This commits any pending writes still in the cache back to the origin LV, then deletes the cache. Other options are available and described in <span class="plainlinks archwiki-template-man" title="$ man 7 lvmcache"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/lvmcache.7">lvmcache(7)</a></span>.
</p>
<h3><span class="mw-headline" id="RAID">RAID</span></h3>
<p>LVM may be used to create a <a href="/title/RAID#Implementation" title="RAID">software RAID</a>. It is a good choice if the user does not have hardware RAID and was planning on using LVM anyway. From <span class="plainlinks archwiki-template-man" title="$ man 7 lvmraid"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/lvmraid.7">lvmraid(7)</a></span>:
</p>
<dl><dd>
<span class="plainlinks archwiki-template-man" title="$ man 8 lvm"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/lvm.8">lvm(8)</a></span> RAID is a way to create a Logical Volume (LV) that uses multiple physical devices to improve performance or tolerate device failures.  In LVM, the physical devices are Physical Volumes (PVs) in a single Volume Group (VG).</dd></dl>
<p>LVM RAID supports RAID 0, RAID 1, RAID 4, RAID 5, RAID 6 and RAID 10. See <a href="https://en.wikipedia.org/wiki/Standard_RAID_levels" class="extiw" title="wikipedia:Standard RAID levels">Wikipedia:Standard RAID levels</a> for details on each level.
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> If your root file system is on LVM RAID, additional configuration for <i>mkinitcpio</i> is needed. See <a href="/title/Install_Arch_Linux_on_LVM#Configure_mkinitcpio_for_RAID" title="Install Arch Linux on LVM">Install Arch Linux on LVM#Configure mkinitcpio for RAID</a>.</div>
<div class="archwiki-template-box archwiki-template-box-tip">
<strong>Tip:</strong> <a href="/title/Mdadm" class="mw-redirect" title="Mdadm">mdadm</a> may also be used to create a software RAID. It is arguably simpler, more popular, and easier to setup.</div>
<h4><span class="mw-headline" id="Setup_RAID">Setup RAID</span></h4>
<p>Create physical volumes:
</p>
<pre># pvcreate /dev/sda2 /dev/sdb2
</pre>
<p>Create volume group on the physical volumes:
</p>
<pre># vgcreate MyVolGroup /dev/sda2 /dev/sdb2
</pre>
<p>Create logical volumes using <code>lvcreate --type <i>raidlevel</i></code>, see <span class="plainlinks archwiki-template-man" title="$ man 7 lvmraid"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/lvmraid.7">lvmraid(7)</a></span> and <span class="plainlinks archwiki-template-man" title="$ man 8 lvcreate"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/lvcreate.8">lvcreate(8)</a></span> for more options.
</p>
<pre># lvcreate --type RaidLevel [OPTIONS] -n Name -L Size VG [PVs]
</pre>
<p>For example:
</p>
<pre># lvcreate --type raid1 --mirrors 1 -L 20G -n myraid1vol MyVolGroup /dev/sda2 /dev/sdb2
</pre>
<p>will create a 20 GiB mirrored logical volume named "myraid1vol" in VolGroup00 on <code>/dev/sda2</code> and <code>/dev/sdb2</code>.
</p>
<h2><span class="mw-headline" id="Thin_provisioning">Thin provisioning</span></h2>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> When mounting a thin LV file system, always remember to use the <code>discard</code> option or to use <a href="/title/Fstrim" class="mw-redirect" title="Fstrim">fstrim</a> regularly, to allow the thin LV to shrink as files are deleted.</div>
<p>From <span class="plainlinks archwiki-template-man" title="$ man 7 lvmthin"><a rel="nofollow" class="external text" href="https://man.archlinux.org/man/lvmthin.7">lvmthin(7)</a></span>:
</p>
<dl><dd>Blocks in a standard lvm(8) Logical Volume (LV) are allocated when the LV is created, but blocks in a thin provisioned LV are allocated as they are written. Because of this, a thin provisioned LV is given a virtual size, and can then be much larger than physically available storage. The amount of physical storage provided for thin provisioned LVs can be increased later as the need arises.</dd></dl>
<h3><span class="mw-headline" id="Example:_implementing_virtual_private_servers">Example: implementing virtual private servers</span></h3>
<p>Here is the classic use case. Suppose you want to start your own VPS service, initially hosting about 100 VPSes on a single PC with a 930 GiB hard drive. Hardly any of the VPSes will actually use all of the storage they are allotted, so rather than allocate 9 GiB to each VPS, you could allow each VPS a maximum of 30 GiB and use thin provisioning to only allocate as much hard drive space to each VPS as they are actually using. Suppose the 930 GiB hard drive is <code>/dev/sdb</code>. Here is the setup.
</p>
<p>Prepare the volume group, <code>MyVolGroup</code>.
</p>
<pre># vgcreate MyVolGroup /dev/sdb
</pre>
<p>Create the thin pool LV, <code>MyThinPool</code>. This LV provides the blocks for storage.
</p>
<pre># lvcreate --type thin-pool -n MyThinPool -l 95%FREE MyVolGroup
</pre>
<p>The thin pool is composed of two sub-volumes, the data LV and the metadata LV. This command creates both automatically. But the thin pool stops working if either fills completely, and LVM currently does not support the shrinking of either of these volumes. This is why the above command allows for 5% of extra space, in case you ever need to expand the data or metadata sub-volumes of the thin pool.
</p>
<p>For each VPS, create a thin LV. This is the block device exposed to the user for their root partition.
</p>
<pre># lvcreate -n SomeClientsRoot -V 30G --thinpool MyThinPool MyVolGroup
</pre>
<p>The block device <code>/dev/mapper/MyVolGroup-SomeClientsRoot</code> may then be used by a <a href="/title/VirtualBox" title="VirtualBox">VirtualBox</a> instance as the root partition.
</p>
<h4><span class="mw-headline" id="Use_thin_snapshots_to_save_more_space">Use thin snapshots to save more space</span></h4>
<p>Thin snapshots are much more powerful than regular snapshots, because they are themselves thin LVs. See Redhat's guide <a rel="nofollow" class="external autonumber" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_logical_volumes/assembly_thinly-provisioned-logical-volumes_configuring-and-managing-logical-volumes#con_thin-snapshot-volumes_thinly-provisioned-logical-volumes">[1]</a> for a complete list of advantages thin snapshots have.
</p>
<p>Instead of installing Linux from scratch every time a VPS is created, it is more space-efficient to start with just one thin LV containing a basic installation of Linux:
</p>
<pre># lvcreate -n GenericRoot -V 30G --thinpool MyThinPool MyVolGroup
*** install Linux at /dev/mapper/MyVolGroup-GenericRoot ***
</pre>
<p>Then create snapshots of it for each VPS:
</p>
<pre># lvcreate -s MyVolGroup/GenericRoot -n SomeClientsRoot
</pre>
<p>This way, in the thin pool there is only one copy the data common to all VPSes, at least initially. As an added bonus, the creation of a new VPS is instantaneous.
</p>
<p>Since these are thin snapshots, a write operation to <code>GenericRoot</code> only causes one COW operation in total, instead of one COW operation per snapshot. This allows you to update <code>GenericRoot</code> more efficiently than if each VPS were a regular snapshot.
</p>
<h3><span class="mw-headline" id="Example:_zero-downtime_storage_upgrade">Example: zero-downtime storage upgrade</span></h3>
<p>There are applications of thin provisioning outside of VPS hosting. Here is how you may use it to grow the effective capacity of an already-mounted file system without having to unmount it. Suppose, again, that the server has a single 930 GiB hard drive. The setup is the same as for VPS hosting, only there is only one thin LV and the LV's size is far larger than the thin pool's size.
</p>
<pre># lvcreate -n MyThinLV -V 16T --thinpool MyThinPool MyVolGroup
</pre>
<p>This extra virtual space can be filled in with actual storage at a later time by extending the thin pool.
</p>
<p>Suppose some time later, a storage upgrade is needed, and a new hard drive, <code>/dev/sdc</code>, is plugged into the server. To upgrade the thin pool's capacity, add the new hard drive to the VG:
</p>
<pre># vgextend MyVolGroup /dev/sdc
</pre>
<p>Now, extend the thin pool:
</p>
<pre># lvextend -l +95%FREE MyVolGroup/MyThinLV
</pre>
<p>Since this thin LV's size is 16 TiB, you could add another 15.09 TiB of hard drive space before finally having to unmount and resize the file system.
</p>
<div class="archwiki-template-box archwiki-template-box-note">
<strong>Note:</strong> You will probably want to use a <a href="/title/Disk_quota" title="Disk quota">disk quota</a> to prevent applications from attempting to use more physical storage than there actually is.</div>
<h2><span class="mw-headline" id="Troubleshooting">Troubleshooting</span></h2>
<h3><span class="mw-headline" id="LVM_commands_do_not_work">LVM commands do not work</span></h3>
<ul><li>Load proper module:</li></ul>
<pre># modprobe dm_mod
</pre>
<p>The <code>dm_mod</code> module should be automatically loaded. In case it does not, you can try:
</p>
<div class="noprint archwiki-template-message">
<p><a href="/title/File:Tango-inaccurate.png" class="image"><img alt="Tango-inaccurate.png" src="../File:Tango-inaccurate.png" decoding="async" width="48" height="48"></a><b>The factual accuracy of this article or section is disputed.</b><a href="/title/File:Tango-inaccurate.png" class="image"><img alt="Tango-inaccurate.png" src="../File:Tango-inaccurate.png" decoding="async" width="48" height="48"></a></p>
<div>
<b>Reason:</b> Should module loading at boot be done using "/etc/modules-load.d" instead? (Discuss in <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/title/Talk:LVM">Talk:LVM#</a>)</div>
</div>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/mkinitcpio.conf</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">MODULES=(dm_mod ...)</pre>
<p>You will need to <a href="/title/Regenerate_the_initramfs" class="mw-redirect" title="Regenerate the initramfs">regenerate the initramfs</a> to commit any changes you made.
</p>
<ul><li>Try preceding commands with <i>lvm</i> like this:</li></ul>
<pre># lvm pvdisplay
</pre>
<h3><span class="mw-headline" id="Logical_Volumes_do_not_show_up">Logical Volumes do not show up</span></h3>
<p>If you are trying to mount existing logical volumes, but they do not show up in <code>lvscan</code>, you can use the following commands to activate them:
</p>
<pre># vgscan
# vgchange -ay
</pre>
<h3><span class="mw-headline" id="LVM_on_removable_media">LVM on removable media</span></h3>
<p>Symptoms:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># vgscan</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">  Reading all physical volumes.  This may take a while...
  /dev/backupdrive1/backup: read failed after 0 of 4096 at 319836585984: Input/output error
  /dev/backupdrive1/backup: read failed after 0 of 4096 at 319836643328: Input/output error
  /dev/backupdrive1/backup: read failed after 0 of 4096 at 0: Input/output error
  /dev/backupdrive1/backup: read failed after 0 of 4096 at 4096: Input/output error
  Found volume group "backupdrive1" using metadata type lvm2
  Found volume group "networkdrive" using metadata type lvm2
</pre>
<p>Cause: removing an external LVM drive without deactivating the volume group(s) first. Before you disconnect, make sure to:
</p>
<pre># vgchange -an <i>volume group name</i>
</pre>
<p>Fix: assuming you already tried to activate the volume group with <code>vgchange -ay <i>vg</i></code>, and are receiving the Input/output errors:
</p>
<pre># vgchange -an <i>volume group name</i>
</pre>
<p>Unplug the external drive and wait a few minutes:
</p>
<pre># vgscan
# vgchange -ay <i>volume group name</i>
</pre>
<h4>
<span id="Suspend.2Fresume_with_LVM_and_removable_media"></span><span class="mw-headline" id="Suspend/resume_with_LVM_and_removable_media">Suspend/resume with LVM and removable media</span>
</h4>
<div class="noprint archwiki-template-message">
<p><a href="/title/File:Tango-inaccurate.png" class="image"><img alt="Tango-inaccurate.png" src="../File:Tango-inaccurate.png" decoding="async" width="48" height="48"></a><b>The factual accuracy of this article or section is disputed.</b><a href="/title/File:Tango-inaccurate.png" class="image"><img alt="Tango-inaccurate.png" src="../File:Tango-inaccurate.png" decoding="async" width="48" height="48"></a></p>
<div>
<b>Reason:</b> Provided solution will not work in more complex setups like LUKS on LVM. (Discuss in <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/title/Talk:LVM#LVM_on_removable_media">Talk:LVM#LVM on removable media</a>)</div>
</div>
<p>In order for LVM to work properly with removable media – like an external USB drive – the volume group of the external drive needs to be deactivated before suspend. If this is not done, you may get 'buffer I/O errors on the dm device (after resume). For this reason, it is not recommended to mix external and internal drives in the same volume group.
</p>
<p>To automatically deactivate the volume groups with external USB drives, tag each volume group with the <code>sleep_umount</code> tag in this way:
</p>
<pre># vgchange --addtag sleep_umount <i>vg_external</i>
</pre>
<p>Once the tag is set, use the following unit file for systemd to properly deactivate the volumes before suspend. On resume, they will be automatically activated by LVM.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/systemd/system/ext_usb_vg_deactivate.service</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">[Unit]
Description=Deactivate external USB volume groups on suspend
Before=sleep.target

[Service]
Type=oneshot
ExecStart=-/etc/systemd/system/deactivate_sleep_vgs.sh

[Install]
WantedBy=sleep.target</pre>
<p>and this script:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/systemd/system/deactivate_sleep_vgs.sh</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">#!/bin/sh

TAG=@sleep_umount
vgs=$(vgs --noheadings -o vg_name $TAG)

echo "Deactivating volume groups with $TAG tag: $vgs"

# Unmount logical volumes belonging to all the volume groups with tag $TAG
for vg in $vgs; do
    for lv_dev_path in $(lvs --noheadings  -o lv_path -S lv_active=active,vg_name=$vg); do
        echo "Unmounting logical volume $lv_dev_path"
        umount $lv_dev_path
    done
done

# Deactivate volume groups tagged with sleep_umount
for vg in $vgs; do
    echo "Deactivating volume group $vg"
    vgchange -an $vg
done</pre>
<p>Finally, <a href="/title/Enable" class="mw-redirect" title="Enable">enable</a> the unit.
</p>
<h3><span class="mw-headline" id="Resizing_a_contiguous_logical_volume_fails">Resizing a contiguous logical volume fails</span></h3>
<p>If trying to extend a logical volume errors with:
</p>
<pre>" Insufficient suitable contiguous allocatable extents for logical volume "
</pre>
<p>The reason is that the logical volume was created with an explicit contiguous allocation policy (options <code>-C y</code> or <code>--alloc contiguous</code>) and no further adjacent contiguous extents are available (see also <a rel="nofollow" class="external text" href="http://www.hostatic.ro/2010/02/15/lvm-inherit-and-contiguous-policies/">reference</a>).
</p>
<p>To fix this, prior to extending the logical volume, change its allocation policy with <code>lvchange --alloc inherit &lt;logical_volume&gt;</code>. If you need to keep the contiguous allocation policy, an alternative approach is to move the volume to a disk area with sufficient free extents (see <a rel="nofollow" class="external autonumber" href="https://superuser.com/questions/435075/how-to-align-logical-volumes-on-contiguous-physical-extents">[2]</a>).
</p>
<h3>
<span id="Command_.22grub-mkconfig.22_reports_.22unknown_filesystem.22_errors"></span><span class="mw-headline" id='Command_"grub-mkconfig"_reports_"unknown_filesystem"_errors'>Command "grub-mkconfig" reports "unknown filesystem" errors</span>
</h3>
<p>Make sure to remove snapshot volumes before <a href="/title/GRUB#Generate_the_main_configuration_file" title="GRUB">generating grub.cfg</a>.
</p>
<h3><span class="mw-headline" id="Thinly-provisioned_root_volume_device_times_out">Thinly-provisioned root volume device times out</span></h3>
<p>With a large number of snapshots, <code>thin_check</code> runs for a long enough time so that waiting for the root device times out. To compensate, add the <code>rootdelay=60</code> kernel boot parameter to your boot loader configuration.  Or, make <code>thin_check</code> skip checking block mappings (see <a rel="nofollow" class="external autonumber" href="https://www.redhat.com/archives/linux-lvm/2016-January/msg00010.html">[3]</a>) and <a href="/title/Regenerate_the_initramfs" class="mw-redirect" title="Regenerate the initramfs">regenerate the initramfs</a>:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/lvm/lvm.conf</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">thin_check_options = [ "-q", "--clear-needs-check-flag", "--skip-mappings" ]</pre>
<h3><span class="mw-headline" id="Delay_on_shutdown">Delay on shutdown</span></h3>
<p>If you use RAID, snapshots or thin provisioning and experience a delay on shutdown, make sure <code>lvm2-monitor.service</code> is <a href="/title/Started" class="mw-redirect" title="Started">started</a>. See <a rel="nofollow" class="external text" href="https://bugs.archlinux.org/task/50420">FS#50420</a>.
</p>
<h3><span class="mw-headline" id="Hibernating_into_a_thinly-provisioned_swap_volume">Hibernating into a thinly-provisioned swap volume</span></h3>
<p>See <a href="/title/Power_management/Suspend_and_hibernate#Hibernation_into_a_thinly-provisioned_LVM_volume" title="Power management/Suspend and hibernate">Power management/Suspend and hibernate#Hibernation into a thinly-provisioned LVM volume</a>.
</p>
<h2><span class="mw-headline" id="See_also">See also</span></h2>
<ul>
<li>
<a rel="nofollow" class="external text" href="https://sourceware.org/lvm2/">LVM2 Resource Page</a> on SourceWare.org</li>
<li><a href="https://wiki.gentoo.org/wiki/LVM" class="extiw" title="gentoo:LVM">Gentoo:LVM</a></li>
<li><a rel="nofollow" class="external text" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/configuring_and_managing_logical_volumes/index">Red Hat Enterprise 8: Configuring and managing logical volumes</a></li>
<li>
<a rel="nofollow" class="external text" href="https://www.tutonics.com/2012/11/ubuntu-lvm-guide-part-1.html">Ubuntu LVM Guide Part 1</a><a rel="nofollow" class="external text" href="https://www.tutonics.com/2012/12/lvm-guide-part-2-snapshots.html">Part 2 details snapshots</a>
</li>
</ul>
</div>
</div>
<div id="catlinks" class="catlinks" data-mw="interface">
<div id="mw-normal-catlinks" class="mw-normal-catlinks">
<a href="/title/Special:Categories" title="Special:Categories">Category</a>: <ul><li><a href="/title/Category:Storage_virtualization" title="Category:Storage virtualization">Storage virtualization</a></li></ul>
</div>
<div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul>
<li><a href="/title/Category:Pages_or_sections_flagged_with_Template:Expansion" title="Category:Pages or sections flagged with Template:Expansion">Pages or sections flagged with Template:Expansion</a></li>
<li><a href="/title/Category:Pages_or_sections_flagged_with_Template:Accuracy" title="Category:Pages or sections flagged with Template:Accuracy">Pages or sections flagged with Template:Accuracy</a></li>
</ul>
</div>
</div>
	</div>
</div>

<footer id="footer" class="mw-footer" role="contentinfo" style="margin: 0">
	<ul id="footer-info">
		<li>Retrieved from "<a dir="ltr" href="https://wiki.archlinux.org/index.php?title=LVM&amp;oldid=668940">https://wiki.archlinux.org/index.php?title=LVM&amp;oldid=668940</a>"</li>
		<li id="footer-info-lastmod"> This page was last edited on 8 May 2021, at 10:56.</li>
		<li id="footer-info-copyright">Content is available under <a class="external" rel="nofollow" href="http://www.gnu.org/copyleft/fdl.html">GNU Free Documentation License 1.3 or later</a> unless otherwise noted.</li>
	<br>
</ul>
	<ul id="footer-places">
		<li id="footer-places-privacy"><a href="/title/ArchWiki:Privacy_policy" title="ArchWiki:Privacy policy">Privacy policy</a></li>
		<li id="footer-places-about"><a href="/title/ArchWiki:About" title="ArchWiki:About">About ArchWiki</a></li>
		<li id="footer-places-disclaimer"><a href="/title/ArchWiki:General_disclaimer" title="ArchWiki:General disclaimer">Disclaimers</a></li>
	</ul>
	<ul id="footer-icons" class="noprint">
		<li id="footer-copyrightico">
	</ul>
	<div style="clear: both;"></div>
</footer>



</body>
</html>
